{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Llm0kIFk4HRC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import csv\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1tYe8q34j87",
        "outputId": "2cc2998b-4512-43f8-e405-a1bda0ca5a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ingredient_QA= pd.read_csv('/content/drive/MyDrive/Ingredient_QA.csv')"
      ],
      "metadata": {
        "id": "uywjMAHaYiqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ingredient_QA.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxHi8fQ3ZCh2",
        "outputId": "84af5fce-708a-44ab-ea89-828cbdf2def7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31264, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = Ingredient_QA['질문'].apply(lambda x: len(x)).max()\n",
        "print(\"max_len:\", max_len)\n",
        "max_len2 = Ingredient_QA['답변'].apply(lambda x: len(x)).max()\n",
        "print(\"max_len:\", max_len2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOwVeTQhZAOA",
        "outputId": "5445f2f2-094c-4a73-fc3b-6156f5092154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_len: 63\n",
            "max_len: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import urllib.request\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "BR3GAF2kb544"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GEzrX09EaEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "2c40899e4d2c42a5af3f53d13d8d5d3a",
            "26f32f4c1ca1469fa178292654036cba",
            "3d9b5e70677a44fc8eb2ea55429d2ba2",
            "de59ec42e26f4dfb8143c88be7943b09",
            "4583632a9fb844c3b40545d61475e1a2",
            "e3c0c4e4c9574b3093717f185d32ebed",
            "e0a460d1bcd847d5aa06da526198f43b",
            "8dad0ae1f0894e7888a42b587d02c37e",
            "dec93d175be2428c8aab75f1c2eb35f5",
            "75e9e74f14b34e3292d56e4c5225a055",
            "7a22c9e4ca154fc984b4caf27558c80e",
            "4b801cc95a804e31a3bdf840e0a634a1",
            "6a379456b7af43959c8c47dc84edbb64",
            "fbe22e2d45ee4640a90f708a4f23686a",
            "aeee0a8c7b58486c9ebd02f86342986d",
            "80e9721513304e02b2f992709483f160",
            "5911210f9a9747aa8dfa7d8a3047c305",
            "391305c082c44104b626e00d97aa7f18",
            "5f7fbc09ffa74e68adef644acd44117a",
            "cd9a5cbdc0614c1a8d360581d1a05e26",
            "48eaf3cc2544462aaffb13e3462f80fe",
            "b0671ca9ec5c48238bfc7786253bbe0e"
          ]
        },
        "outputId": "9891c55a-b8c9-424e-8eca-1e0cb3ee12b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c40899e4d2c42a5af3f53d13d8d5d3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b801cc95a804e31a3bdf840e0a634a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ],
      "source": [
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "BOS = '</s>'\n",
        "EOS = '</s>'\n",
        "MASK = '<unused0>'\n",
        "SENT = '<unused1>'\n",
        "PAD = '<pad>'\n",
        "\n",
        "Max_len = 70\n",
        "\n",
        "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token=BOS, eos_token=EOS, unk_token=\"<unk>\", pad_token=PAD, mask_token=MASK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDZN_tX94dHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64188d48-95e0-4cf0-ecef-86962e4f626a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "         48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 10138,  7660,  7663,  7467, 17605,\n",
            "          7281, 45798,   739,  9407,  8255,  7621,  6853,   739, 10286,  7543,\n",
            "         27632,  9848,  8539,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9114,  9466,  8397,   739,  9226,  7249,  9810,   739, 35494,\n",
            "           739,  9040,  8126,   739,  9025,  7763,  8161,  7741,  9379, 36258,\n",
            "          9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 35796,  8052,  8467, 24831,  7991,  8511,   739,\n",
            "         14330,  6960,  9340, 15475,  7098,  9203, 12438,   739,  9055,  7480,\n",
            "          6958,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 46064, 15832,  8148, 25846,  7770,   739,  9208, 13906,  9855,\n",
            "         16285,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9150,  8365,  7556,  8425,   739, 19673,  7784,  6931,   739,  9181,\n",
            "          7609,  8397,  6863, 17951,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6855,  7584,  8031,  8213,  6953,   739, 34372,  8168,\n",
            "           739,  9110,  8006, 13906,  9695,  9025,  9080, 13815,  8711,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9110,  8006,  7258,\n",
            "          7669,   739,  9110,  8006,  7824,  7532,   739,  9110,  8006,  8263,\n",
            "          7372,  7888,  8381,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 46311,  8754,  7258,  6978,  7760,   739, 14807, 12520,  6958,\n",
            "           739,  9117,  6866,  8599,   739, 31903, 15953,  6860,  7426,  9695,\n",
            "          9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9081,  8006, 10016,\n",
            "         15134,  8456,  8519,   739,  9050,  7652,  8429,  7235, 50252, 25894,\n",
            "          7771,  7281, 45798,   739,  9118,  8756,  6903,  8701,  6853,  8671,\n",
            "          7281,   739,     1,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 18006, 19824,   739,  9338,  8420,   739,  9959, 24855, 16180,\n",
            "          7599,  8240,   739,  9923,  8168,   739,  9046,  8511,  7426,  9695,\n",
            "          9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9338,  8420,  6963,  8420,  8326,\n",
            "          6841,   739,  9338,  8420, 37699, 21332,   739, 43551,  9092, 24242,\n",
            "          7597,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 25846,  6833,  8066,  9132,  7586,  8326,  8066, 14807,\n",
            "         12520,  6958,  8092,  7260,  8066, 26473,  8243,  8702, 15800, 17843,\n",
            "         18101,  8146,  7471,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         23960,  8381,  7605,   739, 41021, 50252,   739,  9164,  8168,  8694,\n",
            "          7079,  8346,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11046,  7352,  7561,   739,  9301,  8431,   739, 48081,  8168,\n",
            "           739,  9719, 10007, 36258,  9242,  9702,  9182, 11909,  9666,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9050,  8093,  9498,\n",
            "         46812,   739,  9170,  7374,  7258,  7669,  8326,  6841,   739,  9105,\n",
            "          8721,  9340, 11029,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7762,  8135, 15800, 17843, 18101,  9666,  8236,  7801,\n",
            "          8084,    10,     4,  9548, 32450, 20600, 18101,   401, 45941, 16318,\n",
            "          7426,  8505,  7556,  7870,   739,  9529,  6893,  7407,  8615, 12438,\n",
            "           739,  9193, 24998,  7188,  8330,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6923, 22092,   739, 10607,  7897,  8091,   739,  9028,\n",
            "          8037,  7621,  8539,   739,  9065,  8403, 19824,   739, 12077, 15800,\n",
            "         17843, 18101, 13815,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         20138,  7889,  9201, 50252,  9664,  8213,  7335,   739, 48060,  8263,\n",
            "         39137, 19594,   739,  9337,  7426,  8119,  8052,  8689,  7621,  6853,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9169,  8040,  7426,  9695,  9025,  9080, 48541,  9242,  9379,\n",
            "         13815, 15084,  7801,  8084,   739,    10,     4, 32450,  9278,  9564,\n",
            "         20600, 18101,   401,  9722,  8335,  6886,  7374,  8168, 21332,   739,\n",
            "         39169,  8000,  7111, 30297,  7965,  8326,   739, 43272,  8006, 19970,\n",
            "          8139,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 16783,   739, 11355,  7760,   739,  9206,  7605,   739,  9673,\n",
            "          8420,  7970,  7470, 36258,  9242,  9702,  9182, 11909,  9666,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9098,  8381,  9072,\n",
            "         43933,   739,  9382, 21987,  8381,  7605,   739,  9170,  7374,  7489,\n",
            "          7258,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 11737,  6932,  8694,   739,  9376,  8381,   739, 23122, 18726,\n",
            "          7621,  8265,  7426,  9695,  9025,  9080, 48541,  9242,  9379, 13815,\n",
            "         15084,  7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9105,  8721,  9719,  7756, 11029,  7605,   739, 11057,  7992,\n",
            "          7556,  8425,   739,  9072,  7697,  7079,  7532,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 15989,   739,  9170,  8038,  8346,   739, 29523,   739, 23911,\n",
            "           739, 24560, 10410,  9695,  9025,  9080, 48541,  9242,  9379, 13815,\n",
            "         15084,  7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 12213, 20551,  8165,  8346,   739,  9181,  8528,   739,  9118,\n",
            "          8381,  6963,  8420,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 35309, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9164,  7609,  8397,  7692,  8599,  7561,\n",
            "          6963,  8420,   739, 33974,  8474,  7692,  8263,  8187,   739, 30070,\n",
            "         12548,  8255, 38270,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 27731,   739, 12980,  8599,   739, 19216,  8652,   739, 35403,\n",
            "          7426,  9695,  9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 21035,  8238, 29523,\n",
            "          8588,  6963,   739, 39137,  8528,  7532,   739,  9301,  7888,  7984,\n",
            "          8426,  7877,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8749, 16146,   739,  9429,  7793,  8528,   739, 14264,\n",
            "          8168, 13906,   739,  7570,  9695,  9025,  9341,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 12753,  6903,   739,  9142,  7374,\n",
            "          7237, 24987,   739, 10907, 14571,  8339,  8652,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8420,  8513, 49033,  8066, 35960,  7983,  8193,  8066,\n",
            "          9132,  7244,  8066, 33489,  7673,  7480,  6860,  8066,  9059, 29975,\n",
            "          7321, 15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9488, 49094,  8643,  8643, 21279,\n",
            "          6866,  8608,   739, 26473, 46998,  9203, 12438,   739, 11141,  8519,\n",
            "          7098, 13420,  9203, 12438,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9319,  8701,  8091,   739, 40276,  8260,  7426,  9695,  9025,\n",
            "          9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 12024,  7488,  8168,   739,  9255,  7079,\n",
            "          7532,   739, 23168,  6905,  8159,  7000,  8420, 38270,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 31973, 40827,  6920,  7561,  8260,  7073,  6860,   739, 24104,\n",
            "           739, 46071,  7470, 36258,  9242,  9702,  9182, 11909,  9666,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 46071, 49051,  7833,\n",
            "          7605,   739, 12213, 20551,  7692, 43933,   739, 24104, 50252,  9039,\n",
            "         40774,  9498, 46812,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 10814,  6978,   739, 20570,  8052,   739, 24724,  6963, 10062,\n",
            "         36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 33974,  7654,  8139,  7605,   739, 47164,\n",
            "          7489,  7258,   739, 46311, 21323,  8236,  7513,  7605,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9059, 11074,   739, 46311,   739,  9026,  8708,   739,  9169,\n",
            "          8187,  7671,  7561,  8187,  7671,   739, 24415,  7470, 36258,  9242,\n",
            "          9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9488,  7407,  8092,  7244,   739,  9356,  7556,  7692,\n",
            "         43933,   739,  9686,  7584,  7605,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8615, 10737,  7706,  6835,  8066, 20013,  7521,  7759,\n",
            "          8420,  8255, 44803,  8066,  9208, 24655,  9488,  7122,  7372, 29708,\n",
            "          9020,   690,   393,  8239, 15473,  9695,  9025,  9080, 18101,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 30613,  7584, 38270,   739,\n",
            "          9174, 23013,   739,  9208, 26473, 44167,  9118,  8425,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7610,  7252,  8168,  8066,  9050,  7652,  8429, 13047,\n",
            "         20618,  9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9050,  7652,  8429,  7235,  7306,  6958,  7772, 36568,   739,  9050,\n",
            "          7652,  8429,  7235,  8588,  6963,   739,  9338, 13730,  7652,  8429,\n",
            "          7235, 35119, 36568,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7022,   739,  9050,  7433, 21878,   739,  9050, 19193,\n",
            "          7372,  6853,  7877, 15473,  9695,  9025,  9080, 18101,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9831,  8690, 22092, 42228,  8456,\n",
            "         13503,   739,  9246,  7889,   739,  9208,  7673, 20479,  8330,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 46064,  7543,  8260,   739, 42228, 22092,   739,  9722,  8708,\n",
            "          7760,   739,  9324,  7605,  8091,  6963,   739, 49218,  7055,  7824,\n",
            "         15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9081,  8006, 10016, 15134,  8456,  8519,   739,  9407,\n",
            "          8513,  7000,  7467,  7244,  7691,  7445,   739, 17366, 20479,  7847,\n",
            "          7763,  7772, 36568,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8570, 21332,  8066, 40276,  7851, 13047, 20618,  9277,\n",
            "         13088,    10,     4,  9548, 32450, 20600, 18101,   401,  9338,  8420,\n",
            "          6963,  8381,  7605,   739,  9259,  7760, 12937, 13503,   739, 13913,\n",
            "          8599,  8469,  8340,  8420,  8187,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,   392,   690,   393,  7198,   739,  9435,  8255,  6841,\n",
            "           739, 17366, 20479,  8126,  7847,   739, 11046,  6920,  7847,  7599,\n",
            "         15473, 22375,  9695,  9025,  9846,  6969,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9118, 12870,  6951,  8146,   739,  9072,\n",
            "          6855, 32367,  7098,  8196,  9203, 12438,   739,  9470,  7258,  7669,\n",
            "         16547,  8528,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8074,  7489,  7258, 15800, 17843, 18101,  8146,  7471,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9103,  7264,  6920,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9407,  8513, 49033,  8066,  9234,  9620, 17494, 18101, 11063,\n",
            "         13815,  8705, 12230,  9199,  9019,  7055,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9072,  8688, 10645,  6958,  7138,\n",
            "           739, 46048,  7847,  8688,   739, 35021,  9203, 12438,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 48170, 46836, 25805,  7290,  7730,  8066, 12218,  7532,  8066,\n",
            "          9036,  7487, 10324,  9427,  7487,  7533,  8420,  8126,  7847, 15800,\n",
            "         17843, 18101,  8146,  7471,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 12218,  8146,  7609,  8403,  6920,   739, 11294,  7244,  7252,\n",
            "         46812,   739,  9098,  7763,  8187,  7653,  7561,  8765,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39102,  8397, 30003,  9669,  8551, 21700,  9059,  8066,  9427,\n",
            "          7487,  7533,  8420,  8126,  7847, 15800, 17843, 18101,  9666,  8236,\n",
            "          7801,  8084,    10,     4,  9548, 32450, 20600, 18101,   401,  9121,\n",
            "         20716,  6835,  8765,   739,   739,  7298,  7795,   739, 50900,  7429,\n",
            "          8688,  7409,  8420,  8563,  9581,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 11737,  6932,  8694,   739, 23330, 33845,  9695,  9025,  9080,\n",
            "          9242,  9620, 48397,  8711,  8084,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9081,  8006, 10016, 15134,  8456,  8519,   739,\n",
            "         50900, 23707,  8420,  8255, 25894,  9319,  9581,   739, 31973, 40827,\n",
            "         20512, 35119, 36568,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 10768,  8747,   739,  9065, 32599,   739,  9546,  7692,\n",
            "         13906,   739,  7570,  9695,  9025,  9341,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 13162,  7501,  8094,  8528,   739,  9170,\n",
            "          7374,  8193,   739, 43272,  8006,  8346,  7654,  8139,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 35309,  8599,  8260,  8066, 37912,  6826,  8168, 13047, 20618,\n",
            "          9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401,  9382,\n",
            "         21987,  9103,  7258,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 10168,  8539, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 10859,\n",
            "          8588,  6963,   739,  9421,  8467,  7991,  7048,   739, 47969,  8715,\n",
            "          7621,  6853,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9297,  7409,  7631,  9379, 31406,  9242,  9379,  9666,  8236,\n",
            "          7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         11949,  7172,  8371,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 38513,  8168, 13047, 20618,  9277, 13088,    10,     4, 32450,\n",
            "          9278,  9564, 20600, 18101,   401,  9674, 29161,  7258,  8420, 22092,\n",
            "           739, 46894,  7532,   739,  9105,  7557,  8187,  6893,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8399,  6932,  8694,   739,  9376,  8381,   739, 23122,\n",
            "         18726,  7621,  8265, 15800, 17843, 18101, 13815,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 12213, 20551,  9121, 20716,  9118,  8425,\n",
            "           739, 26473,  6874,  8159,  8346,   739, 40053,  8679, 10234, 43304,\n",
            "          8397,  7904,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 40796,  7621,  8539,   739, 34280,  7763,  6881,  7760,\n",
            "           739, 48734,   739, 29010, 16180, 15473, 22375,  9695,  9025,  9846,\n",
            "          6969,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 38232,\n",
            "          7258,  6958,  7654,  8139,  7605,   739, 34280,  7763,  6881,  7760,\n",
            "          7252,  8168,  8326,  6841,   739, 34280,  7763,  6881,  7760, 22278,\n",
            "          8168,  8326,  6841,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8340, 19824,   739, 10494,  6920,  7847,   739,  9435,\n",
            "          7182,   739,  9337,  7372,  8694,  7134, 13906,  9695,  9025,  9080,\n",
            "         13815,  8711,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         41345,  8346,   739, 35796,  6826, 10996,  9079,  7262, 16180,  7605,\n",
            "           739,  9338, 20551,  6826,  8168,  7556,  8425,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 24562, 12206,   739,  9129,  8125,   739,  9169,   739,  9091,\n",
            "          7426,  9695,  9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9092,  7847,  6886,\n",
            "          7374, 21323,   739, 48832, 26473,  8588,  6963,   739, 50033, 14330,\n",
            "          6963,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8694,  7497,   739,  9166,  6826,  8168, 13906,  9855,\n",
            "         16285,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9522,  7889,  8052,  8272,  8006,  7654,  8139,   739, 31973, 40827,\n",
            "          8528,  7847,  8126,   739, 43272,  8006,  7759,  8186,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8420,  8513, 49033,   739,  9175,  8189, 42337,  7824,\n",
            "          6953,  7561,   435, 15473, 22375,  9695,  9025,  9846,  6969,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 26473, 46998,  9203,\n",
            "         12438,   739,  9133,  7407,  7865, 10321,  7397,  8690, 21279,  6866,\n",
            "          8608,   739, 16547,  9203, 12438,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8340, 19824,   739, 10494,  6920,  7847,   739,  9435,\n",
            "          7182,   739,  9337,  7372,  8694,  7134, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4,  9548, 32450, 20600, 18101,   401,  9077,  6828,\n",
            "          7692,  9034,  6893,   739, 49375,  7321,  7654,  8146,   739, 48832,\n",
            "          8187,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 26255,  8529,  8474,   739, 28545,  8674,  7470, 36258,  9242,\n",
            "          9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 21826, 11737,  6932,   739,  9215,  8471, 26473,  9230,\n",
            "          8609, 11737,  6932,   739, 26255,  8529,  8474,  6920,  7847,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8420,  8446, 10324, 36211, 21700, 49375,  8066, 31154,\n",
            "          7561, 15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9114,  6890,  7605,  7904,  7605,\n",
            "          8194,  7889,   739,  9079,  7180,  7711, 42228,  7235,  6947,   739,\n",
            "         16547,  7965,  7652,  8429,  7235,  7772, 36568,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 35960, 16146,  8126, 12031, 11355, 14314,  7470, 31406,  9242,\n",
            "          9379,  9666,  8236,  7801,  8084,   739,    10,     4, 32450,  9278,\n",
            "          9564, 20600, 18101,   401, 29523,  7847, 23024,   739, 29523,  8528,\n",
            "           739, 17690,  7489,  7258,  6920,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 20301,  7543,  7281,  7880, 10662,  7877,   739,  9117,  7692,\n",
            "          8503,   739,  9886,  7767,  8397, 13906,  9855, 16285,  9666,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9117,  7692,  8503,\n",
            "          8659,  7483,   739,  9596,  7172,  8420,  8255, 43160,  7172,   739,\n",
            "         50900, 22416,  7656,  7496,  8528,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11762,  6951,  7478,  7865,  7512,  8696,   739, 11046,  7141,\n",
            "          8125,   739, 29580,  8187,  7671,  7426,  9695,  9025,  9080,  9242,\n",
            "          9620, 48397,  8711,  8084,   739,    10,     4, 32450,  9278,  9564,\n",
            "         20600, 18101,   401, 27895,  8006,  8658,  8588,  6963,   739,  9479,\n",
            "          6947, 44797,  7294,  8599,   739,  9741, 12830,  6835,  8194,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9065, 10683,  9695,  9025,  9080,  9242,  9620, 48397,  8711,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 46311,\n",
            "          8519,  8467,   739, 10174,  6889,  7772, 36568,   739, 18013,  9669,\n",
            "          7285,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7182,  8265, 22278,  8066, 40276, 12206,  8704,  7000,\n",
            "          8270, 13047, 20618,  9277, 13088,    10,     4, 32450,  9278,  9564,\n",
            "         20600, 18101,   401, 10056,  7335, 11213,  7188,  7601,   739,  9072,\n",
            "          7697,  7902,  6920,  7847,   739, 17268,  7889,  7970,  7609,  8397,\n",
            "          8330,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9028,  7949,  8052, 24238,  7599,  8066,  9903, 38259,  7609,\n",
            "         32598, 31406,  9242,  9379,  9666,  8236,  7801,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9903, 38259,  8035,  7556,\n",
            "          7561,  6963,  8420,   739,  9903, 38259,  7609,  8397,  9498, 46812,\n",
            "           739,  9214,  7239, 22512,  6863, 17951,  7556,  8425,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7837,  8214,   739, 43304,  8397,  8570, 13906,  9855,\n",
            "         16285,  9666,  8244,    10,     4, 32450,  9278,  9564, 20600, 18101,\n",
            "           401, 13429,  8652,   739, 17366, 20479, 43304,  8397, 48908,   739,\n",
            "         17268,  7889,  9214,  7239, 22512, 14568,  7847,  8159,  8126,  8652,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 49363,  7605, 13906,   739,  7570,  9695,  9025,  9341,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 16547,  6963,  7605,\n",
            "           739,  9299,  6881,  7760,  6963,  7605,   739,  9201,  7824,  7888,\n",
            "          8263,  6963,  7605,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8033,  7258, 10867, 11046,  6920, 12031, 23849, 11734,\n",
            "         49417, 22278,  8066, 22670,  9387, 13047, 20618,  9277, 13088,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9110,  8432,  6920,  7847,\n",
            "           739, 47164,  7489,  7258,   739, 35796,  7252,  8168,  8326,  6841,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 27992,  7172,   739, 28569,  7119,  7469,  8159,   739,  9211,\n",
            "          8615, 10737,   739,  9103, 20885, 36258,  9242,  9702,  9182, 11909,\n",
            "          9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9160,\n",
            "          7405,  8528,   739,  9382, 21987,  9103,  7258,   739,  9117, 36556,\n",
            "         23707,  9474,  8528,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6953,  6946,   739,  9118,  8364,   739, 15275, 41521,\n",
            "           739, 14821, 15800, 17843, 18101, 13815,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9025,  7763, 22289,  7605,   739, 14330,  6963,\n",
            "          7219,  7605,   739, 46311,  6963,  8420, 21323,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 30325,  9086,  6889, 10234, 15275, 41521,  8158,  8066,\n",
            "         12024,  7488, 15800, 17843, 18101,  8146,  7471,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 29755,  6835,  8194,   739,  9103,  7264,\n",
            "          6920,   739, 49375,  6866,  8168,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8710,  7975,  8126, 12031, 26383,  7586, 12206, 15473,\n",
            "         22375,  9695,  9025,  9846,  6969,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 20138,  7889,  9201, 50252,  9664,  8213,\n",
            "          7335,   739,  9246,  8474, 24562,  8237,   739, 26383,  7586,  8721,\n",
            "          9164, 20479, 19970,  8139,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 33017,   739, 20007,  7120,  7258,   739,  9474,  7848,  8563,\n",
            "          7487, 16806, 36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 39137,  7847,  8688,   739,\n",
            "         26473,  8505,  7482,  8429, 35157,  7692,  8429,  7407,   739,  9546,\n",
            "          8420,  7119,  7039,  7824,  6953, 38270,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 20570,  7249,  9810,  6958,  7967,  7894,   739, 28545,   739,\n",
            "         31575,  7426,  9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,\n",
            "          7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         26473,  7489,  7258,   739, 35796,  8263,  8269,   739, 28017,  8187,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 16146,  7487,  7533,  8420,   739, 45576,  8006,  7557,\n",
            "           739, 20512,  6841,   739,  9215,  7892,  8168,  7965,  8326, 15473,\n",
            "          9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9050,  7757, 20512, 11029,  7605,   739, 10859,  7584,  8031,\n",
            "          6920,   739, 12218,  8146,  7609,  8403,  6920,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 48170,  7019,  7584,   739,  9413,  8006, 13906,   739,  7570,\n",
            "          9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9413,  8006,  8000,  7111, 38270,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9145, 18171, 36258,  9242,  9702,  9182, 11909,  9666,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 23763,  8563,  9145,\n",
            "          7487,  9077,  7596,   739,  9285,  8529, 10721,  8330,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11355,  7760,   739,  9470,  7258,  7669,   739, 31260,   739,\n",
            "         35960, 16146,  7487,  8126,  7847,   739, 20570, 43075,  7426,  9695,\n",
            "          9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9114, 28410,  7967,\n",
            "          7521,  7588,  6920,  7847,   739, 10859,  7692,  7501,  8094,  8528,\n",
            "           739,  9255,  6903,  8126,  8399,  8168,  7763,  6881,  7760,  7654,\n",
            "          8139,   739,     1,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8722,  7172,  7512, 11211,  7281,   739,  9755,  7532,\n",
            "         16939,  6897,  8528,   739,  9110,  8006,   739, 36288, 13906,  9695,\n",
            "          9025,  9080, 13815,  8711,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9110,  7336,  7336,  8146,   739,  9098, 23940,  8711,\n",
            "          7561,  7079,  8346,   739,  9741, 12830,  6835,  8194,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 16258, 16182,  7194,  7395,   739, 12443,  7669,  8397,   739,\n",
            "         10855,  6969,  7877, 22092,   739,  9174,  7599,  8168,   739, 14807,\n",
            "          6958, 11276, 36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,\n",
            "             4, 32450,  9278,  9564, 20600, 18101,   401,  9105,  8721,  9077,\n",
            "         20479, 13444,   739, 34303,  9193,  7258,  7669,  8694,   739, 17366,\n",
            "         20262,  7760,   739,  6982,  8158,  8187,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7833,  7605, 13047, 20618,  9277, 13088,    10,     4,\n",
            "         32450,  9278,  9564, 20600, 18101,   401, 43272,  8006,  9105,  7557,\n",
            "         11029,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9142,  8700, 12206,   739, 12303,  7497, 13432,   739, 24366,\n",
            "          6920,  7426,  9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,\n",
            "          7801,  8084,   739,    10,     4, 32450,  9278,  9564, 20600, 18101,\n",
            "           401,  9421,  7467,  8608,  8690, 40107,   739,  9037,  8126,  7652,\n",
            "          7904,   739, 26561,  6889, 19307,  6884,  7185,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8615, 10737,  8615, 21519, 10076,  8148,  7621,  8539,\n",
            "         15800, 17843, 18101,  8146,  7471,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9050,  7652,  8429,  7235,  8588,  6963,   739,  9050,\n",
            "          7652,  8429,  7235, 50252, 25894,  7771,  7281, 45798,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8420,  8513,  8126,  7847,   739,  9091,  8243,  8756,\n",
            "          7532,   739,  9174, 28917, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 46048,  7847,\n",
            "          8688,   739, 11361,  7889, 44167, 19970,  8139,   739, 40053,  8679,\n",
            "         44167, 14330,  6963, 11029,  7605,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9265, 10294,  7426,  9695,  9025,  9080, 48541,  9242,  9379,\n",
            "         13815, 15084,  7801,  8084,   739,    10,     4, 32450,  9278,  9564,\n",
            "         20600, 18101,   401, 29755,  7185, 27467,  6877,  6903,  7461, 35119,\n",
            "         36568,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7777,  7763,  6881,  7760,  8066,  9132,  7405, 15473,\n",
            "          9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9299,  6881,  7760,  6963,  8420, 21323,  8330,   739,  9132,\n",
            "          7405,  7252,  8168,  7904,  7605,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 40276,   739, 30121,  8126,  7847,   739, 10758,  7478, 22092,\n",
            "          7335,   739, 14821,  7561,   739, 16317,  7769, 15805, 36258,  9242,\n",
            "          9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9358,  6963,  8420,   739,  9300,  6884,  8346,  7654,\n",
            "          8139,   739,  9847, 19911,  8528,  7847,  8126,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 12377,  8474,   739, 18006,  7487,  7469,  6860,   739, 50900,\n",
            "           739, 46311,  8092,  7260,  7426,  9695,  9025,  9080,  9242,  9620,\n",
            "         48397,  8711,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 12213,  8159,  7599,   739, 10907, 14571,  8339,  8652,   739,\n",
            "          9215,  8471,  9072,  7697,  9099,  8159,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8367,  6884,  8346,  8704, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4,  9548, 32450, 20600, 18101,   401, 12312, 38311,\n",
            "          8282,  7739,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47063,  7410,  8066, 10632,  7793,  8528,  8066,  9959,  8519,\n",
            "         10324,  9324,  8427,  6920,  7561,  8066,  9117,  6866,  8599, 13047,\n",
            "         20618,  9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         27632,  9024,  8102,  8505,  7482,   739, 50033,  9669,  8551,  7372,\n",
            "          8429,  7055,  8643,   739, 26267, 16180,  7605,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7597, 42251,  8216,  8066,  9091, 10358, 28017, 42251,\n",
            "         13047, 20618,  9277, 13088,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9407,  7372, 16983,  7888,   739,  9297, 16347,  7767, 28093,\n",
            "          8599,   739, 10907, 14571,  8339,  7321,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8367, 18563,  8006,  8168,  8066,  9026, 16123, 13162,\n",
            "          8066, 32367,  8608,  8474, 15473,  9695,  9025,  9080, 18101,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9338,  8420,  6963,  8420,\n",
            "          8326,  6841,   739, 23297,  8618,   739, 48832,  8528,  7847,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194, 19374, 46836,  9114, 15722, 11355,  7851,  8066,  9275,\n",
            "          7588,  7711, 15800, 17843, 18101,  8146,  7471,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 10252,  8563,  9407,  8255,  9230,  8469,\n",
            "           739, 17366, 20262,  7760,  8052,  8599,  7588, 35119, 36568,   739,\n",
            "         16547,  7965,  7652,  8429,  7235,  7772, 36568,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8381,  7777,  6835,  7777,  7393, 24824,  8066, 15253,\n",
            "           421,  7824, 11556,  9091,  8615, 44818, 15800, 17843, 18101,  8146,\n",
            "          7471,    10,     4, 32450,  9278,  9564, 20600, 18101,   401,  9407,\n",
            "          7584, 47922, 16605, 13503,   739, 23031,  7543,  7249,  9810,  6958,\n",
            "          8652,   739, 46311,  7219,  7605,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7182,  8265, 50252,  8193,  8066,  9214,  7239,  7597,\n",
            "          8066, 11513,  8066, 10632,  7889,  8381, 15800, 17843, 18101,  9666,\n",
            "          8236,  7801,  8084,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9214,  7239, 22512,  7848,  8236,  7654,  8139,   739,  9118, 12870,\n",
            "          6951,  8146,   739, 12218,  8146,  9214,  7239, 22512, 33752,  7605,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9271, 27216,  9695,  9025,  9080,  9242,  9620, 48397,  8711,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 10859,\n",
            "          7556,  7605,   739, 12218,  8146,  7605,  6903, 35796,  8168,   739,\n",
            "          9074,  8420,  8186,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194, 20487,  8094,   739, 18328,  6841,  8091,   739,  9358,\n",
            "          7252,  8168,   739, 10509, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 10509,  7252,\n",
            "         46812,   739,  9528,  9301,  8431,  9942, 13529,  9203, 12438,   739,\n",
            "         33974, 45825,  7904,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 22162,  7556,  8260, 36121, 28926, 13729,  9060, 13173, 13719,\n",
            "         17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9498,  8168,\n",
            "          9848,  8539, 29580, 20111,  8285,  6919, 20111,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8643,  8635,  7428,  8420, 35585,  9544,  8066,  9504,\n",
            "          8066,  9091,  8243,  8756,  7532,  8066, 15475, 15800, 17843, 18101,\n",
            "          9666,  8236,  7801,  8084,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9673,  8420,  7970,  9590,  8098,  7596,  9203, 12438,   739,\n",
            "         14330,  6960,  9340, 15475,  7098,  9203, 12438,   739,   739,  8282,\n",
            "          7739,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7258,  7599,  8168,   739,  9731, 22285,   739,  9300,\n",
            "         18563,  7496, 14314,   739,  9206, 50252, 13906,   739,  7570,  9695,\n",
            "          9025,  9341,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9382, 21987,  8381,  7605,   739,  9074,  6947,  9397,   739, 47674,\n",
            "          8381,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 26460,  7763,  8066, 19216,  8066,  9020,   690,   399,  8066,\n",
            "          9338,  6978, 15473, 22375,  9695,  9025,  9846,  6969,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9118,  7493,  8135,\n",
            "          6920,   739, 12663,  8006, 21332,   739, 16314,  7489,  7258,  8187,\n",
            "          6893,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9730,  6857, 10324,  9300, 18563,  7902,  8056,  9885,  7194,\n",
            "          8066, 39137,  7983,  6824, 17494, 18101, 11063, 13815,  8705, 12230,\n",
            "          9199,  9019,  7055,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 14529,  8236,  7966,   739,  9264,  8652,   739, 26561,\n",
            "          6889, 19307,  6884,  7185,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,   392,   690,   395,  7832,   739,  9300,  8694,  7497,\n",
            "           739, 10814,  7605, 15800, 17843, 18101, 13815,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 18006,  7188,  7654,  8139,   739,  9407,\n",
            "          8513,  7220, 31218,  7048,   739, 27268,  7605,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 28035,  8146,  9581,  8066, 17582, 17494, 18101, 11063, 13815,\n",
            "          8705, 12230,  9199,  9019,  7055,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9072,  6855, 13883,  6951,   739, 31823,\n",
            "          7711,   739,  9215,  8471,  9072,  7697,  9099,  8159,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8754,  8708,  7760,  8066, 13522,  7258,  7000,  8270,\n",
            "          8066,  9360,  8066,  9470,  7198, 13047, 20618,  9277, 13088,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 33953,  7849,  7198,  7654,\n",
            "          8139,   739,  9722,  8708,  7848,  8236,  7556,  8425,   739,  9470,\n",
            "          7198,  7654,  8139,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 38297, 12206,  8066, 48276, 15528,  8066, 48060,  8263,\n",
            "         15800, 17843, 18101,  8146,  7471,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,   739,     5,  7870,  8429,   383,  8022,  6947,  8148,\n",
            "          8732,   384,   739, 18983, 19641, 29289, 48060,  8263,  7656,   739,\n",
            "          9072,  6855, 20738,  8326,  6841,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9722, 22278,  8346,   739,  9673,  8474, 19421, 36258,  9242,\n",
            "          9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 12213, 12206,  8022,  7703,  8265,  7944,  6920,   739,\n",
            "         10382,  7605,  8263, 35634,   739, 17366,  8432,  6920,  7847,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7597, 42251,  8216,   739,  9091,  8263,   739, 28017,\n",
            "         42251, 13906,   739,  7570,  9695,  9025,  9341,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9297, 16347,  7767, 28093,  8599,\n",
            "           739,  9407,  7372, 16983,  7888,   739,  9382, 21987,  8381,  7605,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 10221,  7258,  7472,   739, 40053,  7235, 38290,  9695,  9025,\n",
            "          9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9174,  7472,  8168,  7965,\n",
            "          8326,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8807,  8772,  8397,   739,  9324,  7777,  7393, 24824,\n",
            "           739, 28433, 15800, 17843, 18101, 13815,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 19787,  8625,  7700,  7847,   739, 22311, 28433,\n",
            "          9132,  7244,   739, 27980,  7258,  7669,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 40233,  7442,   739,  9203, 10737,   739, 43243,  7669,  8213,\n",
            "          6953,   739,  9746,  8187,  7671,  7426,  9695,  9025,  9080, 48541,\n",
            "          9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 48832,  8528,  7847,   739, 17268,  7889,\n",
            "           739,  7395,  7599,  7258,  7669,  8694,   739,  9164,  7609,  8397,\n",
            "         16605, 13503,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9193,  7533,  8420,   739, 28569, 43075,  7426,  9695,  9025,\n",
            "          9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 22311, 28433,  9132,  7244,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 31969,  7480,  8158,  8346, 13501, 15473, 22375,  9695,  9025,\n",
            "          9846,  6969,  8084,   739,    10,     4, 32450,  9278,  9564, 20600,\n",
            "         18101,   401,  9338,  8420,  8519,  7182,  8511,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7540,  7262, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9098,  8381,\n",
            "          9324,  7605,   739,  9098,  8381,  9072, 43933,   739,  9034,  8326,\n",
            "          6841,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 31969,  7480,  8158,  8346, 13501, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4, 32450,  9278,  9564, 20600, 18101,   401,  9338,\n",
            "          8420,  8519,  7182,  8511,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 38297, 12206,  8066,  9407,  8446, 19763,  8240,  8066,\n",
            "          9407,  8255, 12206,  8066, 14302, 15473,  9695,  9025,  9080, 18101,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 35403, 27467, 27694,\n",
            "          8528,   739, 17690,  7771,  7281, 45798,   739, 39137, 22092, 49010,\n",
            "          7656,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9193,  7584,  8031,   739, 43304,  8397,  8570,   739,  9110,\n",
            "          6920,   739,  9730,  8344,   739, 20074, 21617,  9695,  9025,  9080,\n",
            "         48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9132,  7244,   739, 26473, 33471,\n",
            "          9118,  7469,  7605,   739, 10859,  7584,  8031,  6920,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7769,  7832,  8066,  9297,  7383,  7584, 13047, 20618,\n",
            "          9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401, 12077,\n",
            "         48037,  9299,  6881,  7760, 30951,   739,  9079,  7262,  8187,   739,\n",
            "         15883,  7429,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47061,  6866,  8599,  7711,   739, 31168,   739,  9203,  7880,\n",
            "          9620,  7445,   739, 35403,  7671,  8529,   739, 35753, 16943, 15473,\n",
            "         22375,  9695,  9025,  9846,  6969,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 50900, 23707,  8420,  8255, 25894,  9319,  9581,\n",
            "           739, 39169,  8000,  7111,  8711,  7561,  8615,  8187,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7769, 19911, 16180,  8066,  9065, 32599,  8066,  9110,\n",
            "         21332, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 47729,  8420,  7556, 21332,   739,  9121,  7208,\n",
            "          7209, 12213, 20551, 33753,   739, 13108,  8006, 21332,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 10321,  7397,  8690,  7470, 31406,  9242,  9379,  9666,  8236,\n",
            "          7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         16314,  9664,  8213,  7335,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 13624, 17645,  7471,   739, 26521, 10234,   739, 44167,\n",
            "          8186,   739, 46311, 13906,  9695,  9025,  9080, 13815,  8711,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9718,  6866,  8330,\n",
            "           739,  9356,  7556,  7692, 43933,   739,  9246, 22278,  8168,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8750,  8066,  9046,  8511, 19903,  9244,  8529, 15800,\n",
            "         17843, 18101,  8146,  7471,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9338,  8420,  8519,  7182,  8511,   739,  9072,  6855, 32367,\n",
            "          7098,  8196,  9203, 12438,   739,  9128, 20479,  7771,  7281, 45798,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 43109,  8599,  8469,  8570,  8213,   739, 29580,  8187,\n",
            "          7671,   739, 20905,  7992,  6826,  7777,  7393, 24824,   739,  9117,\n",
            "          7631,  8503, 22092, 13906,  9855, 16285,  9666,  8244,    10,     4,\n",
            "         32450,  9278,  9564, 20600, 18101,   401, 33953, 15975,  7373,  7654,\n",
            "          8139,   739, 11197, 22092,  8528,  7847,  8126,   739, 10307,  7281,\n",
            "          8658,  8505,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8367,  8066,  9121,  7763,  8066, 36288, 15473,  9695,\n",
            "          9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         19857, 31215,  6828,  7692, 38270,   739, 48656,  8263,  8340,  8420,\n",
            "          6963,  7605,   739,  9110,  7336,  7336,  8146,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 33974,  8158,  8066, 46936,  8158,  8066,  9050,  7433,  7756,\n",
            "         18797, 31406,  9242,  9379,  9666,  8236,  7801,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9028,  8117,  7532,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 24694,  8066,  9755,  7532, 16939,  6897,  8528,  6824, 17494,\n",
            "         18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 20512,  7824, 22512,\n",
            "           739, 25805,  7502,  8186, 38270,   739, 23826, 45837,  7772, 36568,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9097, 14737, 35960,  8193,  8066, 46071,  8066, 39011,  8367,\n",
            "          6855,  7208,  8066,  9077, 11001, 17494, 18101, 11063, 13815,  8705,\n",
            "         12230,  9199,  9019,  7055,  8084,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 46071, 49051,  7833,  7605,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7249,  9810,  6958,  7981,  7182, 10324, 48832,  8066,\n",
            "         19216, 13047, 20618,  9277, 13088,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 24155,  8679, 12303,  7467,  7652,  9375,   739,  9118,\n",
            "         12870,  6951,  8146,   739, 29523,  6920,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9959,  8519,  9379, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9092,  7847,\n",
            "          8187,  6893,   739, 33974, 21323,  7258,  7669,  8330,   739, 16314,\n",
            "          7654, 16570,  7285,  6978, 22092,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7182,  8265,  8000, 16123, 20570, 22278,  8066,  9546,\n",
            "          8420,  7760,  8066,  9028,  7949,  8052, 24238,  7599,  8066, 10632,\n",
            "          7793,  8528, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9528,  9301,  8431, 27752,   739, 17690,\n",
            "          6828,  7692,   739,  9246,  7889,  8456, 13503,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9107,  7965,  7543, 12819, 36258,  9242,  9702,  9182, 11909,\n",
            "          9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401, 29755,\n",
            "          7185, 27467,  6877,  6903,  7461, 35119, 36568,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 26206,  6833,  8704,   739,   739,  7845,  8615, 12438,   739,\n",
            "         34372,  8168,   739,  9285,  8529,   739, 37477,  8704,  7470, 36258,\n",
            "          9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9893,  7048,  7824,  7596,   739,  9299,  8420,\n",
            "          6826,  8168, 21332,   739,  9285,  8529, 10721,  8330,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 49363, 12206, 15800, 17843, 18101,  8146,  7471,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 26473,  8588,  6963,  7079,  7521,\n",
            "          7588,   739, 10758,  7478, 50252,   739, 31973, 40827,  8528,  7847,\n",
            "          8126,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8367,  7767,  8397,   739, 16258,   739, 30191,  8125,\n",
            "         13906,  9855, 16285,  9666,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9831,  8690, 22092, 42228,  8456, 13503,   739, 33953,\n",
            "          8006,  7557,  7654,  8139,   739, 16547,  6963,  7605,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 50252, 13906,  9855, 16285,  9666,  8244,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 11197, 50252,  6886,  7374,  8330,\n",
            "           739,  9215, 14701,  8187,   739, 39169,  8000,  7111,  8165,  8346,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8335,  7239,  7597, 12715,  9301, 12438, 15978, 11355,\n",
            "          7760, 15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9214,  7239, 22512,  7321,  7654,\n",
            "          8146,   739, 12218,  8146,  9214,  7239, 22512, 33752,  7605,   739,\n",
            "         15883,  7429,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6908,  8006,   739, 10632,  8152,  9436,  7445, 13906,\n",
            "           739,  7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 29645, 10286,  7543,  9296,  8006, 30951,   739,\n",
            "         23259,  8679,  9296,  8006, 30951,   739, 27746,  6884,  7185,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7597,  7416,  7671,  8213,  6953,  8066,  9164, 19911,\n",
            "         16180,  8066, 10076,  7492,  8066, 11509,  7689,  8091,  8066, 28545,\n",
            "         15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 27746,  7258, 23013,  6893,   739, 26367,  6958,  8669,\n",
            "          6889,  7654,  8139,   739, 44611,  9777, 21280,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9128, 20479,  8091,  7470, 36258,  9242,  9702,  9182, 11909,\n",
            "          9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401, 46311,\n",
            "          6982,  8158, 21323,  8330,   739,  9128, 20479,  9203,  8187,   739,\n",
            "          9128, 20479,  7771,  7281, 45798,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7521, 10234, 37208,  7380,  8006, 30325, 12024,  7488,\n",
            "         15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 10855, 21867,  7219,  7605,   739,  9803,\n",
            "          6958,  7501,  8094,  8528,   739, 49375,  6866,  8168,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 35309, 15800, 17843, 18101, 13815,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 10055,  7652,  8346,   739,  9407,  8513, 37699,\n",
            "          7429,   739, 19275,  9043,  7889, 34243,  9142,  7374,  8381,  7605,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 20570,  8615,  7880,  9620, 17494, 18101, 11063, 13815,  8705,\n",
            "         12230,  9199,  9019,  7055,  8084,   739,    10,     4, 32450,  9278,\n",
            "          9564, 20600, 18101,   401, 43272,  8006,  7849,  7198,   739, 45416,\n",
            "          6824, 40147,  6919, 12715, 46760,  7585, 22092,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 17366,  7730,   739, 12789,  8615,  7599,  8240,   739, 46311,\n",
            "          8754,  7258,  6978,  7760,   739, 28569,  7000,  7488,  7470, 36258,\n",
            "          9242,  9702,  9182, 11909,  9666,  8244,    10,     4, 32450,  9278,\n",
            "          9564, 20600, 18101,   401,  9421,  8467,  7991,  7048,   739, 12024,\n",
            "          7488,  7888, 40774,  7252, 46812,   739, 48270, 10539,  7373,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9084,   739,  9024,  8102,  8505,  7482,  7470, 36258,  9242,\n",
            "          9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 33974, 21323,  7258,  7669,  8330,   739, 39169,  8000,\n",
            "          7111, 30297,  7965,  8326,   739, 33974,  9470,  7258,  7669,  8326,\n",
            "          6841,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7079,  7244,   739,  9499, 20551,  8704, 15473, 22375,\n",
            "          9695,  9025,  9846,  6969,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9230,  8612,  7652,  8599,   739,  9076,  8628, 26473,\n",
            "          9203, 12438,   739,  9338,  8420,  8519,  7182,  8511,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7297, 15473, 22375,  9695,  9025,  9846,  6969,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9081,  8006,  9962,\n",
            "          7753,  8084,  7352,   739, 10286,  7543, 27632,  9848,  8539,   739,\n",
            "          9081,  8006,  9022, 19564,  7373,  7877,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39103,  6946,  8066, 10413,  8066, 17896, 15800, 17843, 18101,\n",
            "          9666,  8236,  7801,  8084,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9097,  6946,  9077,  7596,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9065, 32599,  7888,  8420, 25308,  9719, 10007, 31406,  9242,\n",
            "          9379,  9666,  8236,  7801,  8084,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 27980,  7258,  7669,   739, 29523,  7847,  8688,\n",
            "           739, 10816,  7692,  8432,  6920,  7847,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7182,  8265,  7198,  8615,  8807,   739, 16466,   739,\n",
            "         11576,  7398,   739,  9107,  7777,  6835,   739, 24366,  6828, 13906,\n",
            "           739,  7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9114,  9885,  6958,  8528,   739, 17366,  8432,\n",
            "          6920,  7847,   739,  9429,  8265,  7791,  9077,  6889, 10234, 43304,\n",
            "          8397,  7904,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 38512, 20479,   739,  9546,  8420,  7760,   739, 26473,  7760,\n",
            "           739, 20570,  8615,  7182,  8265,  6860,   739,  9065,  7182,  8420,\n",
            "          8255, 15473, 22375,  9695,  9025,  9846,  6969,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9128, 20479,  7772, 36568,   739,\n",
            "         46311,  6982,  8158, 21323,  8330,   739,  9039, 40774, 10252,  7865,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 42531,  8474, 12771,  8599,   739, 10076,  7258,   739,  9117,\n",
            "          6866,  8599,  7711,   739, 12789,  8615,  7335, 15473, 22375,  9695,\n",
            "          9025,  9846,  6969,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9228,  8652,   739, 31903,  8762,  8529,  7763,  6886,  8528,\n",
            "           739, 10076,  7258,  8187,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7763,  7848,  8066,  9142,  7374,  8263,  7185,  8066,\n",
            "         13522,  8066, 25805,  7290,  7730,  8066,  9339,  8420,  7760, 15800,\n",
            "         17843, 18101,  8146,  7471,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9098,  7561, 19970,  8139,   739,  8282,  7739,   739, 26473,\n",
            "          8237,   739, 24724,  7825,  7204,  6920,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 10409,  8196,  8033,  8006,   739,  9079,  7262,   739, 24104,\n",
            "         50252,   739, 10301,  9439, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9718,  8381,\n",
            "          7605,   739, 10301,  8263,  9081,  8658,  8528,   739,  9098,  8381,\n",
            "          9072, 43933,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8068,  7848,  8066,  9719,  8765,  8091,  8066,  9346,\n",
            "          7208,  7880, 10662,  7877,  8420,  8255, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4,  9548, 32450, 20600, 18101,   401,  9128, 20479,\n",
            "          8495,  7756, 13987,   739, 39137,  7847,  8688,   739,  9065,  7209,\n",
            "          8424,  7079,  7532,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39103,  6946,   739, 10413,   739, 17896, 15473,  9695,  9025,\n",
            "          9080, 18101,    10,     4,  9548, 32450, 20600, 18101,   401,  9097,\n",
            "          6946,  9077,  7596,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 46311,  8126, 12031, 20697,  7561,  8066,  9107, 13777, 31406,\n",
            "          9242,  9379,  9666,  8236,  7801,  8084,   739,    10,     4, 32450,\n",
            "          9278,  9564, 20600, 18101,   401, 12213, 20551,  6920,  7605,   739,\n",
            "          9193, 24998,  8052,  7770,  6884,  7185,   739, 22527,  7188,  8432,\n",
            "          6920,  7847,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 29511, 32599,  8066, 28545,  8243,  7416,  7671,  8066, 10964,\n",
            "          8056, 18693,  8066, 10814,  7605,  8066, 35753, 16943, 15473, 22375,\n",
            "          9695,  9025,  9846,  6969,  8084,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9673,  8420,  7970,  9590,  8098,  7596,  9203,\n",
            "         12438,   739, 23540,  6841,  7904,  8168,  7654,  8139,   739, 12094,\n",
            "          8528,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8437,  7692,   739, 18006,  7487,  7469,  6860, 15800,\n",
            "         17843, 18101, 13815,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9089,  8006, 11093,  7877,  7019,  7877,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 17366,  7967,  7894,  7967,  7894,   739, 33172,   739,  9020,\n",
            "           690,   393,  8239,   739,  9474,  7258,  8474,  7470, 36258,  9242,\n",
            "          9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9050,  7652,  8429,  7235, 50252, 25894,  7771,  7281,\n",
            "         45798,   739,  9474,  7258,  8474,  7605,   739,  9669,  7452,  8263,\n",
            "          8528,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7837, 20479,  8754,  7258,  6978,  7760,   739,  9081,\n",
            "          8066,  7756,  7692,   739,  9301,  8507,  7485,   739, 20570,   739,\n",
            "          9121,  7763, 13906,  9695,  9025,  9080, 13815,  8711,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 10758,  7478,  9340,  8528,\n",
            "          7847,   739, 11141,  8519,  7098, 13420,  9203, 12438,   739,  9128,\n",
            "         20479,  7692, 43933,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9129,  7492,  8126, 12031,  9026, 16123,  9065, 32599,  6924,\n",
            "          8135,  6860,  8066,  9203, 10737, 24655, 10510,  8159,  8158,  7470,\n",
            "         31406,  9242,  9379,  9666,  8236,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 17690,  7489,  7258,  6920,   739,\n",
            "          9214,  7870,  7219,  7605,   739, 43272,  8006,  8570, 38270,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 26460,  7482,  8066, 17690,  7654, 22412,  8066, 10278,  7756,\n",
            "         15153, 26383,  7586, 12206,  8066,  9193, 22278, 15473, 22375,  9695,\n",
            "          9025,  9846,  6969,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9055,  7669,  7584,  8031,  7252, 46812,   739, 48270,\n",
            "         10539,  7373,   739, 46311,  7759,  8186,  7000,  8420,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 19376,  8690, 13047, 20618,  9277, 13088,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9072,  6855, 50033, 12775,  8092,\n",
            "          7172,   739, 50900,  8694,  8159,   739,  9118,  8756,  6903,  8701,\n",
            "          6853,  8671,  7281,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7285,  6978,   739, 35960, 16146,  8126,  7847, 15277,\n",
            "           739, 33869,   739, 21279,  6866,  8608,  7532, 15800, 17843, 18101,\n",
            "         13815,    10,     4,  9548, 32450, 20600, 18101,   401, 35985,  8521,\n",
            "         19193,  6866,  8608,   739, 24155,  8679, 12303,  7467,  7652,  9375,\n",
            "           739,  9096,  6866,  7970,  6903, 25511, 15235, 21279,  6866,  8608,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 12278, 27467,   739,  9142,  8694,   739, 11022,  7870,  7085,\n",
            "         11714,  9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 28017,\n",
            "          8237,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7777,  7540,  8335,  7410,  7372,  8420,  8255,   739,\n",
            "         19216,  8220,   739,  9046,  8511,  7172,   739, 26158, 13906,  9855,\n",
            "         16285,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9755,  7303,  7342,  8146,   739,  9488, 18182,  8196,  7772, 36568,\n",
            "           739,  9039,  7383,  6958,  7252, 46812,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39104,  7586,  8326,   739,  9020,   690,   393, 25336,  8673,\n",
            "         15800, 17843, 18101, 13815,    10,     4, 32450,  9278,  9564, 20600,\n",
            "         18101,   401,  9107, 45852, 16314,  9072, 43933,   739,  9498,  8168,\n",
            "         22092,  9407,  8255,  9340, 38270,   739,  9697,  7426,  9848, 27460,\n",
            "          9164, 19911, 16180,  9230,  8688,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9060,  8189,  7584,   739, 35403,  7426,  9695,  9025,  9080,\n",
            "         48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9163,  8625,  8237,   739, 47957,\n",
            "          6884,  7185,   739, 26561,  6889, 19307,  6884,  7185,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7793,  8528,  8066, 11355,  7760,  8066,  9206,  7605,\n",
            "          8066,  9673,  8420,  7970, 13047, 20618,  9277, 13088,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9079,  7287,  8711, 12272, 45825,\n",
            "          8330,   739, 46311,  8125,  7669,  8381,  7605,   739,  9407,  8513,\n",
            "         37699,  7429,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8658,   739,  9086, 20479,   739, 15275, 41521,  8158,\n",
            "           739, 12024,  7488, 15800, 17843, 18101, 13815,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 26473,  7654,  8139,  7605,   739,  9063,\n",
            "          7561,  7692, 43933,   739, 48656,  8263,  7188,  7654,  8139,  8528,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8340,  8420,  8439,   739,  9755,  8152,   739, 23269,\n",
            "         12206,   739,  9470,  7258,  7669,   739,  9427,  8126,  7847, 15473,\n",
            "          9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9421,  8467,  7991,  7048,   739, 10907, 14571,  8339,  7321,\n",
            "           739,  9037,  8126,  8615, 21323,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  6920,  7533,  8420,   739,  9722,  7258,  6978,   739,\n",
            "         18552,   739, 39169,  8125, 15800, 17843, 18101, 13815,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9039,  7383,  6958,  7252, 46812,\n",
            "           739, 43551,  6920,  7847,   739, 35960,  7556, 21332,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 50380, 12206,  8066, 10286,  7543,  8236, 11556, 11949,  7407,\n",
            "          7281,  8420, 38937, 17494, 18101, 11063, 13815,  8705, 12230,  9199,\n",
            "          9019,  7055,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 10758,  9620,  8263,  8528,  7847,   739, 17366,  6835,  8194,\n",
            "           739,  9831,  8690, 22092, 42228,  8456, 13503,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9300, 18563, 46812,   739,  9339,   739, 26367,  6958,  7967,\n",
            "          7894,  7426,  9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,\n",
            "          7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         10137,  7760, 23707,   739,  7298,  7795,   739, 10409,  8196, 18382,\n",
            "          7556,  7904, 21323,   739, 12077, 48037,  9299,  6881,  7760, 30951,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7777,  7007,  8420,   739,  9077,  7652,   739, 21925,\n",
            "          7524, 13906,   739,  7570,  9695,  9025,  9341,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9299,  7770,  8236,  7513,  7605,\n",
            "           739,  9072,  6855, 50033, 12775,  8092,  7172,   739,  9831,  8690,\n",
            "          9474,  8528,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9211,  8346,  8694,  8507,   739,  9275, 25126,  9695,  9025,\n",
            "          9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9904,  6903,  7461,  7533,\n",
            "          8420,  7654,  8139,   739, 16035,  7426,   739,  9025,  7166, 10539,\n",
            "          7373,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7258,  7472,  8066, 12443, 15800, 17843, 18101,  9666,\n",
            "          8236,  7801,  8084,    10,     4, 32450,  9278,  9564, 20600, 18101,\n",
            "           401,  9174,  7472,  7848,  8765,   739, 17366, 20262,  7760,   739,\n",
            "          6982,  8158,  8187,   739,  9214,  7239, 22512,  6863, 17951,  7556,\n",
            "          8425,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7772, 41521,   739,  9020,   690,   393,   739, 37302,\n",
            "          8213,  6953, 13906,  9695,  9025,  9080, 13815,  8711,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 27562,  7889, 19970,  8139,\n",
            "          7532, 44781,  8148,   739, 39137, 15983,  8615,  8381,   739, 29010,\n",
            "         16180,  9118,  8425,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 50596,  8467,  8420,  7172,  8420, 33833, 21807, 13047, 20618,\n",
            "          9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401,  9070,\n",
            "          8420,  7584,   739, 18983, 19641,  8472,  7772, 36568,   739,  9077,\n",
            "          6828,  7692,  9034,  6893,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7691,  7384,  8066, 48908, 43087,  9719,  7847, 13047,\n",
            "         20618,  9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         28388, 47840,  7673, 20479,   739, 29523,  7258,  7669, 21332,   739,\n",
            "         26206,  6920,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 38514,  8420,   739,  9042,  7549,   739, 12870,  7778,   739,\n",
            "         25005, 13906,  9855, 16285,  9666,  8244,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 14330,  6960,  9340, 15475,  7098,  9203, 12438,\n",
            "           739,  9697,  7426, 46998,  9719,  8765, 21279,  6866,  8608,   739,\n",
            "          9488, 49094,  8643,  8643, 21279,  6866,  8608,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9697, 12287,  9474,  7258,  7979,  6953,  8066, 26367,  6824,\n",
            "         17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9697,  8006,\n",
            "         45825, 21323,   739,  9697,  8006,  7767,  8397,  6969,  7055,  8643,\n",
            "           739,  9060,  8189,  7584,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7559,  8006,  7762,  8135,  6860,   739, 42862,   739,\n",
            "          9174,  7000,  8270,   739,  9022,  7456, 17646,  8420,  8255,   739,\n",
            "          9039, 40774, 13906,  9855, 16285,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9299,  7770,  7588,  7904,   739,  9920,\n",
            "          8187,  7648,   739,  9382, 21987,  9103,  7258,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  6830, 31551,  7671,  8066,  9407,  8513, 49033,  8066,\n",
            "          9300,  8658, 10263,  9625,  6978,  8066, 33017, 15800, 17843, 18101,\n",
            "          8146,  7471,    10,     4,  9548, 32450, 20600, 18101,   401, 18006,\n",
            "          7188,  7654,  8139,   739, 19216,  8474,  7824,  9799,  8711, 12272,\n",
            "         34243,   739, 26473,  8092,  7172,  7991,  7048, 50252,  7799,  6866,\n",
            "         38270,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 44803,  8066,  9193,  8669,  6889, 16180,  8066,  9427,\n",
            "          7561,  6920,  7561,  8091,  8066,  9301,  8431,  8066,  9110,  8006,\n",
            "         15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 30070, 12548,  8255, 38270,   739,  9110,\n",
            "          8006,  6972,  8679,  6958,   739,  9528,  9301,  8431, 27752,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9028,  7949,  8052,  7689,  7888,   739,  9407,  8446, 19763,\n",
            "          8240,   739,  9065, 32599,   739, 11707,  7692,  8171,  8420, 30908,\n",
            "         36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 35960,  7556, 21332,   739,  9741, 12830,\n",
            "          6835,  8194,   739, 26367,  6958,  8092,  8018, 21323, 21332,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47061,  6866,  8599,  7711,   739,  9070,  8420, 24665,  7561,\n",
            "           739, 19216,   739, 31260, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 48832,  9203,\n",
            "         10737, 19970,  8139,   739,  9091, 12305,  7482,   739,  9065,  7285,\n",
            "          7713,  6958,  6963,  8420,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7837,  8214,   739, 43304,  8397,  8570, 15473,  9695,\n",
            "          9025,  9080, 18101,    10,     4, 32450,  9278,  9564, 20600, 18101,\n",
            "           401, 13429,  8652,   739, 17268,  7889,  9214,  7239, 22512, 14568,\n",
            "          7847,  8159,  8126,  8652,   739,  9255,  6903,  8126,  8399,  8168,\n",
            "          7763,  6881,  7760,  7654,  8139,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 22124,  6949,  7470, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4, 32450,  9278,  9564, 20600, 18101,   401, 26473,\n",
            "          8092,  7172,  7991,  7048, 50252,  7799,  6866, 38270,   739,  9546,\n",
            "          8420,  7119,  7039,  7824,  6953, 38270,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9074,  8397,   739,  9546,  7692,  7760,   739, 15275, 46744,\n",
            "         36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 26493, 39476,  9324,  7605,   739, 10623,\n",
            "          7533,  8420,  7252,  8168,  7654,  8139,   739, 21826,  7970,  7605,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8711,  7561,  8066,  9132, 31847, 13047, 20618,  9277,\n",
            "         13088,    10,     4,  9548, 32450, 20600, 18101,   401, 31260, 17366,\n",
            "         20479,  9132,  7244,   739, 20836,  7991,  8511,   739, 19970,  8139,\n",
            "          8092,  7244,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8237,  7849,  8439,   739, 16783,   739, 10252,  7281,\n",
            "          7172,  7694,   739,  9266, 13906,  9855, 16285,  9666,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 35119, 36568,  9203, 12438,\n",
            "           739, 22646,  7880,  7219,  7605,   739,  9133, 40115, 36910,  8539,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8772,  8397,  8213,  6953,   739, 12218,  7532,   739,\n",
            "          9803,  8236,   739,  9488, 12937,  7372, 12206, 15473, 22375,  9695,\n",
            "          9025,  9846,  6969,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9255,  7079,  7532,   739,  9356,  7556,  6963,  8420,  7079,\n",
            "          7532,   739, 43272,  8006,  7556,  8425,  7079,  7532,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7249,  9810,  6958,   739, 20372,   739, 11174,  8701,\n",
            "          8505,   739,  9096,  6866, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 26473,  7489,\n",
            "          7258,   739,  9174, 23013,  6893,   739, 29494, 11737,  6932,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9175,  7533,  8420, 46812, 18688,  9203, 10737,  8066, 23426,\n",
            "          7769, 15576, 17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,\n",
            "          7055,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9050,  7374,  8420,  7172,   739,  9133, 40115, 36910,  8539,   739,\n",
            "         24724, 13444,  9169,  6963,  8420,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194, 22092,   739, 23865,  8470,  7478,   739, 21035,  8635,\n",
            "           739, 12870,  7756,   739,  9230,  8688, 13906,  9855, 16285,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9407,  8513,\n",
            "          7220, 31218,  7048,   739,  9025,  7166, 10539,  7373,   739, 11141,\n",
            "          8519,  7098, 13420,  9203, 12438,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8456,  8341,   739, 42660,  7557, 15473, 22375,  9695,\n",
            "          9025,  9846,  6969,   739,    10,     4, 32450,  9278,  9564, 20600,\n",
            "         18101,   401,  9324, 21323,  8423,  7478,  8528,  7847,   739, 10855,\n",
            "          6969,  7877,   739, 21035,  8238, 29523,  8588,  6963,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 20512, 10358,  9319,  7374,  8066, 22990,  7293,  7865,  8066,\n",
            "          9028,  8037,  7621, 17704, 17494, 18101, 11063, 13815,  8705, 12230,\n",
            "          9199,  9019,  7055,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 23763,  8563,  7487,  7521,  7588,  6920,  7847,   739,\n",
            "          9319,  7374,  7188, 20479,  8330,   739, 10138,  7660,  7663,  7467,\n",
            "         17605,  7281, 45798,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8570,  7777,  6835,   739, 10632, 31215,   739,  9232,\n",
            "          8599,   739, 20372, 24824, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9118,  8756,\n",
            "          6903,  8701,  6853,  8671,  7281,   739,  9358,  6963,  8420,   739,\n",
            "          9174, 12691,  7965,  8326,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 12213,  8159,  8168,  8066,  9338,  7702,  6889,  8094,  8066,\n",
            "          9174,  7472,  8066,  9358,  6963, 15978,  9142,  7374,  7492,  7470,\n",
            "         31406,  9242,  9379,  9666,  8236,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 10859,  8367,  6884,  8346,  7669,\n",
            "          8425,  6841,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8722,  7172,  7512, 11211, 15832, 10814, 10155,  9746,\n",
            "          8187,  7671,  8066, 10607,  7897,  8091, 15800, 17843, 18101,  8146,\n",
            "          7471,    10,     4, 32450,  9278,  9564, 20600, 18101,   401, 26473,\n",
            "          8068, 31551,  6893,   739, 11046, 12206,  9034,  7648,   739, 31973,\n",
            "         40827,  6831,  8052,  8272,  8006,  8588,  6963,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7293,  8658,  7478,   739,  9133,  9620,   739, 17366,\n",
            "         20479,  7967,  7894, 13906,   739,  7570,  9695,  9025,  9341,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9356,  7556,  6963,\n",
            "          8420,   739,  9078,  8599,  8052,  7580,  7413,   739,  9920,  7770,\n",
            "          8236,  7513,  7605,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9079,  8125,   739,  9072,  7697,  8000,  7111,  7470, 36258,\n",
            "          9242,  9702,  9182, 11909,  9666,  8244,    10,     4, 32450,  9278,\n",
            "          9564, 20600, 18101,   401, 44167,  9474,  7258,  8474, 16547,  8330,\n",
            "           739,  9072,  7697,  7079,  7532,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 45096,  8006,  8193,  6828,   739, 35960, 16146,  7487, 13906,\n",
            "           739,  7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9338,  8420,  7258,  7669, 21332,   739,  9095,\n",
            "          7372, 15806,  7561,   739, 47729,  8420,  6963,  8420,  8326,  6841,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9282, 19911, 16180,   739,  9065, 32599,   739,  9110, 21332,\n",
            "          7426,  9695,  9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9338,  8420,  7258,\n",
            "          7669, 21332,   739, 10301,  6898,  7769,   739,  9282, 19911, 16180,\n",
            "         38270,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6826,  8168,   739,  9731, 22285,   739,  9203, 10737,\n",
            "          6841, 15800, 17843, 18101, 13815,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 17268,  7889, 18006, 26473, 11029,  7605,   739,  9074,\n",
            "          6947,  9397,   739,  9105,  8721, 29791, 17690,  6828,  7692,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9886, 45825,   739, 24104, 50252,   739, 12009,  7374,  7877,\n",
            "           739, 12174,   445,   739,  9081,  6874,  8159,  7777,  7393, 24824,\n",
            "          7426,  9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 31903,\n",
            "          8762,  8529,  7763,  6886,  8528,   739, 10859,  9203, 12438,   739,\n",
            "          9246, 22278,  8168,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7849,  7760,   739, 10076,  8335, 12206,   739,  9081,\n",
            "          6874,  8159,   739, 15594,  8344, 13906,   739,  7570,  9695,  9025,\n",
            "          9341,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 13108,\n",
            "          8006,  7219,  7605,   739, 17690,  7771,  7281, 45798,   739, 34735,\n",
            "          7281,  7120,  8335,  7793,  6958,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 25722,  8102,  8505, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4, 32450,  9278,  9564, 20600, 18101,   401, 30070,\n",
            "         12548,  8255, 38270,   739,  9081,  8006, 37699,  7772, 36568,   739,\n",
            "         46311,  8519,  8467,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7837,  8214,   739, 43304,  8397,  8570, 13906,   739,\n",
            "          7570,  9695,  9025,  9341,   739,    10,     4, 32450,  9278,  9564,\n",
            "         20600, 18101,   401, 17366, 20479, 43304,  8397, 48908,   739, 17268,\n",
            "          7889,  9214,  7239, 22512, 14568,  7847,  8159,  8126,  8652,   739,\n",
            "         13429,  8652,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 26158,   739, 49417,  8381,   739, 11509,  7689,  8091,  7426,\n",
            "          9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9039,  7383,\n",
            "          6958,  7252, 46812,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9230,  8123,  8423,  7478, 22092,   739, 20074, 16146,  8126,\n",
            "         10683,  9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,  9390,\n",
            "          6825,  6963,  8420,   739, 38232,  7258,  6958,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9091,  7596,  8267,  8066, 18006, 43075,  7824, 11001, 17494,\n",
            "         18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,  8084,   739,\n",
            "            10,     4, 32450,  9278,  9564, 20600, 18101,   401, 12870,  9295,\n",
            "          8474, 20551,  6920,   739,  9942,  8519,  8420,  8255,  9203, 12438,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 29511,  6973,   739, 48081,  8168,   739, 10389, 22092,   739,\n",
            "         37208,  7380,  8006,  8658,   739, 16605, 13503, 13906,  9695,  9025,\n",
            "          9080, 13815,  8711,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 46311,  7556,  6920,   739, 33471,  6920,   739,  9203,  8346,\n",
            "          7673, 20479,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8521, 33807, 23849, 11734, 48908,  7991,  8346, 15473,\n",
            "          9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 16314,  7772, 36568,   739, 14330,  6963,  7219,  7605,  8550,\n",
            "          7244,   739,  9201,  7824,  7888,  8263,  6963,  7605,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7188, 20262,  7760,  8066, 10632,  8152, 10155,  9296,\n",
            "          8006, 13047, 20618,  9277, 13088,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9079,  7287,  7904,  7605,   739,  9296,  8006, 30951,\n",
            "          9050,  8484,  7965,  7703,  8276,   739,  9407,  8513, 30322,  8608,\n",
            "          7991,  7388,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 44167,  8326,  6841,  8091,   739, 23168,   739,  9300,  8168,\n",
            "           739, 15594,  8344,   739, 29580,  8187,  7671,  7470, 36258,  9242,\n",
            "          9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9121, 20716, 23168,  8528,   739,  9096,  6866,  7970,\n",
            "          6903, 25511, 15235, 21279,  6866,  8608,   739, 10301,  8263,  9081,\n",
            "          8658,  8528,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 24694,   739, 31903,   739,  9081,  8006,  8697,  7413,   739,\n",
            "          9755,  7532,  7847, 18518, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401, 43272,  8006,\n",
            "          7849,  7198,   739, 12213, 20551,  7605,   739,  9076,  8628, 19970,\n",
            "          8139,  8282,  7739,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11355,  7851,   739, 22162,  7556,  8260, 36121, 28926,  7888,\n",
            "           739,  9208,  8260,  7426,  9695,  9025,  9080, 48541,  9242,  9379,\n",
            "         13815, 15084,  7801,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 10099, 10754,  7172, 38270,   739,  9128, 20479,   739,\n",
            "         46311,  7759,  8186,  7000,  8420,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7706,  6826,  7770,  8066, 24415,  8066, 25881, 14186,\n",
            "          7561, 15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9063,  7561,  9324,  7605,   739,\n",
            "         11294, 20551,  7249,  9810, 15189,  8146,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 26460,  7482,   739, 21555,   739,  9427,  7487,  7533,  8420,\n",
            "          8126,  7847,   739, 46998,   739, 30191,  8125, 15800, 17843, 18101,\n",
            "         13815,    10,     4,  9548, 32450, 20600, 18101,   401, 48832,  8187,\n",
            "           739,  9123, 28035, 39137, 10645,  7877,  6866,  8519,   739,  9072,\n",
            "          6855, 50033, 12775,  8092,  7172,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7501,  8471,  8711,  7561,  7496,  8066, 10494,  6920,\n",
            "          7847,  7532,  8066, 18101,  8091,  8066, 26367,  6958,  7290,  7894,\n",
            "          8066, 12789,  8615, 15800, 17843, 18101,  9666,  8236,  7801,  8084,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9163,  6830, 38232,\n",
            "          7258,  6958,   739,   739,  8569, 33752,  7605,   739,  9128, 20479,\n",
            "          9203,  8187,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9300,  6884,  8346,   739,  9214,  8213,   739,  9300, 18563,\n",
            "          8006,  8168,   739,  9091,  7604,   739, 12218,  8425,  7470, 36258,\n",
            "          9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9098,  7561,  7849,  7258,  7669,  8326,  6841,\n",
            "           739, 19673,  8528,   739,  9091, 12305,  7482,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 13879,  7957,  8125,   739, 16547,  7119,  7469,  8159,   739,\n",
            "          9324, 19421, 36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 49375,  9142,  7374,  7605,\n",
            "           739, 21035,  8238, 29523,  8588,  6963,   739,  9043,  7889, 50252,\n",
            "          8588,  6963, 10548,  9236,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 24724,  8158,  8168,  8066, 15275,  7397,  8066,  9390,  8168,\n",
            "          8260,  8066,  9427,  7487,  7756,  7607,  7470, 31406,  9242,  9379,\n",
            "          9666,  8236,  7801,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9488,  7407,  8754,  8708,  8528,   739, 26248,  8467,\n",
            "          8095, 20271,   739,  9169,  6918,  8159,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 17512,  8066, 18288,  8704,  7000,  8270,  8066,  9206,\n",
            "          7605,  8066,  9300, 18563, 46812,  8066, 43272,  8006, 13047, 20618,\n",
            "          9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401, 39169,\n",
            "          8000,  7111,  8711,  7561,  8615,  8187,   739, 47674,  8381,  7605,\n",
            "           739, 43272,  8006,  7790,  7597,  8263,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11046,  7470, 31406,  9242,  9379,  9666,  8236,  7801,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 12789,  8615,\n",
            "          6963,  8420,   739, 34026,  7019,  7584,   739, 10632,  7584, 22289,\n",
            "          7833,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7497,   739, 34284,  7321,   739, 10336,  8091,   739,\n",
            "          9193,   739,  9164,  7609,  8397,  8570, 13906,  9695,  9025,  9080,\n",
            "         13815,  8711,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         26473, 33471,  9118,  7469,  7605,   739, 26473, 46998,  9203, 12438,\n",
            "           739, 18983, 19641, 29289, 48060,  8263,  7656,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8772,  8397,   739, 12303,  7497, 13432,   739,  9301,\n",
            "         12438, 49094,   739,  9123, 16979,   739, 32367,  7098,  8196, 13906,\n",
            "          9855, 16285,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9072,  6855,  9275,  7258,  9072, 12449,  8608,   739, 35815,\n",
            "          9109, 13420,  8658,  7098,  8420,  8255,  9488,  7055,  8643,   739,\n",
            "         30057, 21826,  9580, 36095,  8196, 35119, 36568,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8519,  8694, 39504, 15473, 22375,  9695,  9025,  9846,\n",
            "          6969,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9421,  8694, 39504, 12753,  6918,  8159,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47061,  6866,  8599,  7711,  8066,  9070,  8420, 24665,  7561,\n",
            "          8066, 19216,  8066, 31260, 15800, 17843, 18101,  8146,  7471,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 12218,  8146, 33468,  7373,\n",
            "         33752,  7605,   739,  9105,  8721,  9719,  7756, 11029,  7605,   739,\n",
            "          9340,  8066,  7487,  7469, 50252,  7556,  8425,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 12032,  8236,   739,  9625,  6978, 19421, 36258,  9242,  9702,\n",
            "          9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9301,  7888,  7984,  8426,  7877,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9319,  8701,  8091,  8066, 40276,  8260,  7470, 31406,  9242,\n",
            "          9379,  9666,  8236,  7801,  8084,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 23168,  6905,  8159,  7000,  8420, 38270,   739,\n",
            "          9299,  6881,  7760,  6982,  8158,  8187,   739,  9319,  7374,  7188,\n",
            "         20479,  8330,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8511, 14118, 29201,  8346, 15800, 17843, 18101,  8146,\n",
            "          7471,    10,     4, 32450,  9278,  9564, 20600, 18101,   401, 24708,\n",
            "         40276,  9077,  7877,  9338,  8420, 30951,   739, 19787,  8625,  7700,\n",
            "          7847,   739,  9163, 27467,  7321,  8456, 13503,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 14821,   739, 40276,  7851,   739, 26206,  6833,  8213,  6953,\n",
            "           739, 26473,  8506,  6853,   739,  9382, 10546, 36258,  9242,  9702,\n",
            "          9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 12213, 20551,  7692, 43933,   739,  9338,  8420,  8237,   739,\n",
            "          9105,  8721,  9719,  7756, 11029,  7605,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9020,   690,   395,  7487,   739,  9103,  6824,  7183, 16180,\n",
            "          7470, 36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9296,  8006, 30951,  9050,  8484,\n",
            "          7965,  7703,  8276,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 30057,  7824,  6953,   739, 10389,  7824,  6953,   739, 47147,\n",
            "          8037,   739,  9132,  7763,  6881,   739,  9145,  8186,  8091,  7470,\n",
            "         36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9427,  7487,  7079,  6920,   739,  9340,\n",
            "          8066,  7487,  7469, 50252,  7556,  8425,   739,  9072,  7697,  7079,\n",
            "          7532,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8340, 19824, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 13108,  8006,\n",
            "         12321,  8528,   739, 35796,  8052,  8146,  7556,  8425,   739, 10859,\n",
            "         22092, 46133, 16180,  7654,  8139,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6874,  9436,  7445, 13906,  9695,  9025,  9080, 13815,\n",
            "          8711,  8244,    10,     4, 32450,  9278,  9564, 20600, 18101,   401,\n",
            "         23297,  8618,   739,  9105,  7557,  7000,  8420,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8399,  8168,  8066, 21502, 15800, 17843, 18101,  9666,\n",
            "          8236,  7801,  8084,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         13879,  8694,  8159,   739,  9338, 13730,  7652,  8429,  7235, 35119,\n",
            "         36568,   739,  9664,  8467,  8519,  8420,  8255,  7772, 36568,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7609,  8403,  7825,  8158,   739,  9153, 15800, 17843,\n",
            "         18101, 13815,    10,     4,  9548, 32450, 20600, 18101,   401, 14330,\n",
            "          6963, 21599, 41022, 13004,  9043,  7889, 14330,  6963,   739,  9076,\n",
            "          8628, 26473,  9203, 12438,   739, 15386,  8263,  8269, 38228, 26248,\n",
            "         22092,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8615, 44818,  7777,  7393, 24824,   739, 40276,   739,\n",
            "          9142,  7374,   739,  9117,  7175, 26219,  7803,  7877, 15473, 22375,\n",
            "          9695,  9025,  9846,  6969,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9098,  7561,  7139,  7452,  8263,  8528,   739, 11361,\n",
            "          7889, 44167, 19970,  8139,   739, 47729,  8420,  8588,  6963,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9297,  7409,  7631, 10410,  9695,  9025,  9080,  9242,  9620,\n",
            "         48397,  8711,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 11949,  7172,  8371,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7777,  6835, 43075,   739,  9091,  6923,   739, 40276,\n",
            "          8260,  7335,   739, 10076,  8335, 12206,   739,  9755,  8125, 13906,\n",
            "          9855, 16285,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9267,  7209,  7188,  6835,  8194,   739, 30613,  7584, 38270,\n",
            "           739, 19216,  8474,  7824,  9799,  8711, 12272, 34243,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8474,  8159,  8168,   739,  9338,  7702,  6889,  8094,\n",
            "           739,  9174,  7472,   739,  9358,  6963,  8420,   739,  9142,  7374,\n",
            "          7492, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 10859,  8367,  6884,  8346,  7669,  8425,  6841,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 26460,  7055, 10324, 11355,  7760,  8066, 50380, 12206, 13047,\n",
            "         20618,  9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         43272,  8006,  6972,  8679,  6958,   739, 48656,  8263,  9055,  7669,\n",
            "         48908,  7605,   739,  9686,  7584,  7605,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 26460,  8721,   739, 14796,  8193,   739, 26314, 10023,  7445,\n",
            "           739, 35960,  8193,   739, 33471, 23025, 13906,   739,  7570,  9695,\n",
            "          9025,  9341,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         33471, 23025,  7654,  8139,   739, 10114, 11211,  7281, 12753,  6918,\n",
            "          8159,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7540,  7588,  6920,  7847,   739,  9164,   739,  9081,\n",
            "         22278,  7079,   739,  9395,  7847,   739, 10758,  7478, 22092, 15473,\n",
            "         22375,  9695,  9025,  9846,  6969,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 46936,  7847,  8688,   739, 33974, 21323,  7258,\n",
            "          7669,  8330,   739,  9055,  7669, 43551,  6920,  7847,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9164,  7832, 12715,  9719,  8765,  8091,  8066, 17366, 14765,\n",
            "         17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,  8084,\n",
            "           739,    10,     4, 32450,  9278,  9564, 20600, 18101,   401, 17366,\n",
            "         20479,  7824, 11556,  6923,  7692,  8588,  6963,   739,  9105,  7557,\n",
            "          7188, 20479, 21332,   739, 36250,  6828,  7692,  8330,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8511,  8117,   739,  9118,  8346,   739,  9719,  7847,\n",
            "         15473, 22375,  9695,  9025,  9846,  6969,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 46048,  7847,  8688,   739, 10816,  7692,\n",
            "          8432,  6920,  7847,   739, 34303,  9193,  7258,  7669,  8694,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9649,   739, 28545,  7597,  7416,  7671,   739, 12174,   445,\n",
            "           739,  9132, 31847,   739,  9103,  6824,  7183, 16180,  8704,  7426,\n",
            "          9695,  9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 14712,  8102,  8694,  8159,\n",
            "           739,  9673,  8420,  7970,  9590,  8098,  7596,  9203, 12438,   739,\n",
            "         12213, 20551,  6920,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 14598,  8747,   739,  9065, 32599,   739,  9546, 14229,  9695,\n",
            "          9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9128,  7056,  8187,\n",
            "          6893,   739, 17366,  7501,  8094,  8330,   739, 18006,  8168,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 22278,  7079,  8146, 15473, 22375,  9695,  9025,  9846,\n",
            "          6969,  8084,   739,    10,     4, 32450,  9278,  9564, 20600, 18101,\n",
            "           401,  9170,  7374,  7489,  7258,   739, 10252,  8563,  9324,  7605,\n",
            "           739,  9081,  8006,  8052, 22085,  7772, 36568,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8690, 27435,   739,  9719,  7847,   739, 11046,  7352,\n",
            "          7561,   739, 34798,  8381, 13906,  9855, 16285,  9666,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9214,  7239, 22512,  9498,\n",
            "          8168,  8326,  6841,   739, 12024,  7488,  7888, 40774,  7252, 46812,\n",
            "           739,  9230,  8612,  7652,  8599,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 36253,  8159,   739, 30713,  8158,  7335, 15473, 22375,  9695,\n",
            "          9025,  9846,  6969,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 10939,  7185,  8159,   739,  9079,  7287,  8711, 12272, 45825,\n",
            "          8330,   739,  9995,  7235,  7584, 17686,  9092,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8615, 10737,  8615,  8092,  7208, 13906,   739,  7570,\n",
            "          9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9050,  7652,  8429,  7235, 50252, 25894,  7771,  7281, 45798,\n",
            "           739,  9050,  7652,  8429,  7235,  8588,  6963,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 50252,   739,  9020,   690,   395,  8570,   739,  9142,\n",
            "          7374,   739, 26473,  8381,  7605,  8091, 15473, 22375,  9695,  9025,\n",
            "          9846,  6969,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9039, 40774,  9203, 12438,   739,  9079,  7287,  7904,  7605,   739,\n",
            "         12213, 20551,  6920,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 16146,  7561, 15473,  9695,  9025,  9080, 18101,    10,\n",
            "             4, 32450,  9278,  9564, 20600, 18101,   401, 30613,  7584, 21332,\n",
            "           739,  9235, 31234,  7944,  8068,  8159,  8528,   739, 26367,  6958,\n",
            "          8092,  8018, 21323, 21332,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9206,  7777,  6835,  7777,  7393, 24824,  8066, 10286,  7543,\n",
            "          8066,  9267,  7209,  8066,  9098,  7561,  8066,  9039,  8255,  7180,\n",
            "          7470, 31406,  9242,  9379,  9666,  8236,  7801,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9121,  7208,  7209,  8330,\n",
            "           739,  9098,  7561,  8615,  8187,   739, 33468,  7373,  8474, 20551,\n",
            "          8330,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194, 16941,  7897,  8091,   739,  9110,  8006,   739, 10632,\n",
            "          8772,  8397,  6828,   739, 12152,   739, 29010, 16180, 13906,   739,\n",
            "          7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9110,  8006,  7258,  7669,   739,  9110,  8006,  8381,\n",
            "          7605,   739,  9110,  8006,  7824,  7532,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8750,   739, 26473,  8193,   739, 33471, 23025,   739,\n",
            "          9132,  8018,  8033,  6949,   739, 37912,  6826,  8168, 13906,   739,\n",
            "          7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9848,  8539,  8420,  8513,  8429,  7407,   739,  9128,\n",
            "         20479,  7771,  7281, 45798,   739, 16547, 45837, 35119, 36568,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9340,  8066,  9039,  8618,  8091,  8126, 12031, 10814,  7252,\n",
            "          8168,  6824, 17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,\n",
            "          7055,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9755,  7303,  7342,  8146,   739,  9340,  7654,  8139,   739,  9340,\n",
            "          6963,  8420,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 32952,  8529,  8474,   739, 28545,  8674, 15473,  9695,\n",
            "          9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         21826, 11737,  6932,   739,  9215,  8471, 26473,  9230,  8609, 11737,\n",
            "          6932,   739, 26255,  8529,  8474,  6920,  7847,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 25722,  6903,  7889,  8381,   739, 29523,  8187,  7671,   739,\n",
            "          9722,  8708,  7760, 13906,  9855, 16285,  9666,  8244,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 15351,  9099,  8159,   739, 10286,\n",
            "          7543,  9077,  7877,  9407,  8513, 12937, 13503, 11029,  7605,   739,\n",
            "         11046, 12206,  9034,  7648,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9730,  6857, 10324, 41190,  8066,  9338,  8420,  7983,  8066,\n",
            "         12663, 11813, 17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,\n",
            "          7055,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9181,  8528,   739,  9050,  6938,  8330,   739, 19857,  6866,  8168,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9091,  8066,  7756,  7692,   739, 10336,  8091,  7426,  9695,\n",
            "          9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 19275,  9043,  7889, 34243,  9142,\n",
            "          7374,  8381,  7605,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9118, 12605, 31406,  9242,  9379,  9666,  8236,  7801,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9995,  7235,\n",
            "          7584, 17686,  9092,   739, 13108,  8006, 27731,  9059,  7482,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  9588,  7258,  7472,  8066, 33750,  6830,  8066, 24708,\n",
            "          7770,  8066, 35403, 27467, 13047, 20618,  9277, 13088,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9174,  7472,  8168,  7965,  8326,\n",
            "           739,  9193, 24998,  8052,  7770,  6884,  7185,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6830, 31551,  7671,  8213,  6953,   739,  9070,  8420,\n",
            "         24665,  7561,   739, 13162,   739,   739,  8308,  7532, 15473,  9695,\n",
            "          9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         12218,  7532,   739,  9098,  7561,  6963,  8420,   739,  9285,  8529,\n",
            "         10721,  8330,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 18524,   739, 18288,  8704,  7000,  8270,   739,  9206,  7605,\n",
            "           739,  9300, 18563, 46812,   739, 43272, 10987,  9695,  9025,  9080,\n",
            "         48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 43272,  8006,  9962,  8022,  7991,\n",
            "           739, 43272,  8006,  7759,  8186,   739, 12213, 20551,  8711,  7561,\n",
            "          6874,  8159,  7556,  8425,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 46048, 30003,  9214, 16537,  8694,  8066, 46105,  8066,  9300,\n",
            "         18563, 34243,  9033,  7902,  8056,  9885,  7194,  8066, 29823, 10023,\n",
            "         17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 16547, 45837,\n",
            "         35119, 36568,   739, 43272,  8006,  8474, 20551,  7692, 43933,   739,\n",
            "         14330,  6963,  7219,  7605,  8550,  7244,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 17939,   739, 48908,  7556,   739,  9719, 10683,  9695,  9025,\n",
            "          9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 17268,  7889,  7970,  7609,  8397,  8330,\n",
            "           739, 12213, 20551,  6920,  7605,   739, 44167, 50252,  8193,  6920,\n",
            "          8326,  6841,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7631, 13503,  7281,  7694,   739,  9625,  6978, 22092,\n",
            "           739, 10758,  7478, 22092,  7335, 15473, 22375,  9695,  9025,  9846,\n",
            "          6969,   739,    10,     4,  9548, 32450, 20600, 18101,   401,  9072,\n",
            "          6855, 20738,  8326,  6841,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39103,  6886,   739, 35960,  8193,   739, 46071,   739, 39011,\n",
            "          8367,  6855,  7208,   739,  9077,  7877, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4,  9548, 32450, 20600, 18101,   401, 46071, 49051,\n",
            "          7833,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 12218,  8146,   739,  9266,   739, 30713,  8158,  7335,   739,\n",
            "         10814,  8772,  8397,   739, 14330,  6963,  8091,  7426,  9695,  9025,\n",
            "          9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 26473,  8588,  6963,  7079,\n",
            "          7521,  7588,   739, 12218,  8146,  7605,  6903, 35796,  8168,   739,\n",
            "         12218,  8146,  7609,  8403,  6920,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 45096,  7671, 12206,  8066, 10286,  7543,  8236, 11556, 11949,\n",
            "          7407,  7281,  8420,  8255, 15473,  9695,  9025,  9080, 18101,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9847, 19911,  8528,  7847,\n",
            "          8126,   739,  9267,  7209,  7188,  6835,  8194,   739,  9324, 21323,\n",
            "          8423,  7478,  8528,  7847,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 14796,  7428,   739, 10814,  8474,   739, 24694,  7470, 36258,\n",
            "          9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 19275,  9583,  8346,   739, 24694,  6963,  8420,\n",
            "           739,  9118,  7904, 21323,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 29511, 19307,   739, 42660,  7532,   739,  9427,  7487,  6920,\n",
            "          7561,   739, 14494,  8474, 12206, 15800, 17843, 18101, 13815,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 26561,  6889, 19307,  6884,\n",
            "          7185,   739, 29755,  7185, 27467,  6877,  6903,  7461, 35119, 36568,\n",
            "           739, 29755,  7849,  6963,  8420,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47063,  6953,   739,  9203, 10737,  8615,  8092,  7208,   739,\n",
            "          9163, 27467,   739,  9427,  7487,  6920,  7561,  8091, 13906,   739,\n",
            "          7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 26473, 46998,  9203, 12438,   739,  9164, 29716,  8126,\n",
            "          8187,  6893,   739,  9624,  7889, 44767,  8330,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7258,  8125,   739, 12218,  7532,  6920,  7847,   739,\n",
            "          9407,  8513, 45825, 15800, 17843, 18101, 13815,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 10382, 23764,  7824,  7532,   739, 43272,\n",
            "          8006,  7556,  8425,  7079,  7532,   739,  9072,  6855, 50033, 12775,\n",
            "          8092,  7172,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7533,  8420, 16146,  7561,  8066,  9107,  7588, 12206,\n",
            "          8066,  9211,  8615, 10737, 15800, 17843, 18101,  9666,  8236,  7801,\n",
            "          8084,    10,     4,  9548, 32450, 20600, 18101,   401,  9072,  6855,\n",
            "         10286,  7543,  9300, 24998,  9421, 12338,   739, 30613,  7584, 21332,\n",
            "           739, 34284,  7321,  7000,  8420,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 20512,   739,  9166,  8694,   739,  9070,  8420,  7584,  7556,\n",
            "           739,  9065,  8403, 19421, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401, 18006,  8168,\n",
            "          9299,  6881,  7760, 38270,   739,  9338,  8420,  6963,  8420,  8326,\n",
            "          6841,   739, 38232,  7258,  6958,  7654,  8139,  7605,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7496,  7851,   739, 22162,  7556,  8260, 36121, 28926,\n",
            "          7888,   739,  9208,  8260, 15800, 17843, 18101, 13815,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 46311,  7759,  8186,  7000,  8420,\n",
            "           739, 46311,  7673, 20479,   739, 36250,  6828,  7692,  8330,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 10278,  7756, 10504, 31406,  9242,  9379,  9666,  8236,  7801,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,  9110,\n",
            "          8006,  7219,  7605,   739,  9110,  8006,  8381,  7605,   739,  9407,\n",
            "          8513, 37699,  7429,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 10307,  8066,  9074,  8397,  8066,  9498,  8168,  8066,  9206,\n",
            "         11702,  7407, 22411,  8066, 18006,  8168,  7470, 31406,  9242,  9379,\n",
            "          9666,  8236,  7801,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9546,  8420, 21332,   739, 26367,  6958,  9118, 29729,\n",
            "          9025,  8126,   739, 27731, 49155,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9718, 50252,   739, 15330,  8186,  7194,  7395,   739,  9411,\n",
            "           739, 17239,  7532,   739, 10164,  6886, 10007, 36258,  9242,  9702,\n",
            "          9182, 11909,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,   739,  8282,  7739,   739, 47164, 12870,  8168,  7532,   739,\n",
            "         19216,  8220,  9193, 50252,  7654,  8139,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8570,  8772,  8397,   739, 25511,  7467,   739,  9132,\n",
            "          8018, 21332,  8704,  6860,   739,  9163,  6830, 13906,   739,  7570,\n",
            "          9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9427,  7487,  8588,  6825,   739, 46311,  8168, 21332,   739,\n",
            "         17366,  6897,  8528,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7258,  7669,  8326,  6841,  8091,  8066,  9218, 15800,\n",
            "         17843, 18101,  8146,  7471,    10,     4, 32450,  9278,  9564, 20600,\n",
            "         18101,   401,  9098,  7561,  7252,  8168,  7075,  7692,   739, 36250,\n",
            "          6828,  7692,  8330,   739, 19787,  7824,  9799,  8420,  8513,  7220,\n",
            "         31218,  8511,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39102,  8397, 45837,  8066,  9046,  8762, 38874, 15800, 17843,\n",
            "         18101,  8146,  7471,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         16547, 45837, 35119, 36568,   739, 17268,  7889,  7970,  7609,  8397,\n",
            "          8330,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 10632,  8772, 32599,  6824, 17494, 18101, 11063, 13815,  8705,\n",
            "         12230,  9199,  9019,  7055,  8084,   739,    10,     4, 32450,  9278,\n",
            "          9564, 20600, 18101,   401, 17366, 20479, 11022,  7870,  7085,  8599,\n",
            "         19970,  8139,  6929,  7652,  6886,  8194,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 46760,  7585,  6951,  9907,  8255, 13906,  9695,  9025,\n",
            "          9080, 13815,  8711,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9174, 10233,  8413,  7771,  7281, 45798,   739,  9118,  8756,\n",
            "          6903, 14766,  8448, 21323, 38270,   739,  9174, 10233,  8413,  7771,\n",
            "          7281, 45798,   739,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8335, 13336, 17366, 20479, 12830,  7760,  8066, 16258,\n",
            "          8066, 35403,  7621,  8539, 15800, 17843, 18101,  9666,  8236,  7801,\n",
            "          8084,    10,     4,  9548, 32450, 20600, 18101,   401,  9114,  6890,\n",
            "          7605,   739,  9025,  7763, 22289,  7605,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 45852, 12206,   739,  9129,  8125,   739,  9169,   739,\n",
            "          9091, 13906,   739,  7570,  9695,  9025,  9341,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9315, 20551, 10187,  7616,  8146,\n",
            "          7556,  8425,   739, 20074,  7584,  8031,  6920,   739,  9193, 24998,\n",
            "          7188,  8330,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8722,  7172,  7512, 11211,  7281,   739, 10814,  8159,\n",
            "           739,  9746,  8187,  7671,   739, 10607,  7897,  8091, 13906,  9695,\n",
            "          9025,  9080, 13815,  8711,  8244,    10,     4, 32450,  9278,  9564,\n",
            "         20600, 18101,   401, 48832,  8528,  7847,   739, 31973, 40827,  6831,\n",
            "          8052,  8272,  8006,  8588,  6963,   739, 10252,  8563, 10286,  7543,\n",
            "          9203, 25322, 11244, 13503,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8158, 45825, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9050,  7652,\n",
            "          8429,  7235,  7306,  6958,  7772, 36568,   739,  9081,  8006,  7772,\n",
            "         36568,   739,  9297, 37142,  7767,  9297,  7383,  7584,  7771,  7281,\n",
            "         45798,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8615,   739,  9114,  9466,  8397,   739,  9673,  8420,\n",
            "          7970,   739,  9153, 15473, 22375,  9695,  9025,  9846,  6969,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 10530,  7387,  8335,\n",
            "          8092,  7208,  9025,  8688,   739, 29523,  8715,  7654,  8139,   739,\n",
            "           739,  8569, 33752,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8164,  7660,  8066, 24104,  7769, 21519,  9065,  8403,\n",
            "          8158,  8066, 13111, 32934, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,  9128,\n",
            "         20479, 45837,  7772, 36568,   739, 10138,  7660,  7663,  7467, 17605,\n",
            "          7281, 45798,   739,  9338,  8420,  8519,  7182,  8511,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9755,   739, 16776,  8258,  7478,   739, 10252,  7281,  7172,\n",
            "          7694,   739, 34735, 12819, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9132,  8018,\n",
            "         46311,  9128, 20479,   739, 26248,  6889,  7467,  6891,  8216,  7372,\n",
            "          8694,  8159,   739,  9095, 35155,  8052,  8146,  7777,  8346,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 42531,  8643,  8066, 16547,  8066,  9763, 11211,  7281,  7824,\n",
            "         11556,  9137,  8615, 13047, 20618,  9277, 13088,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 16314,  8165,  8346,  7605,   739,  9722,\n",
            "          8708,  8528,   739, 27731,  7252, 46812,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7188, 20262,  7760,   739, 10632,  8152,  8159,   739,\n",
            "          9296,  8006, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 39137,  8420,  8513,  7877,  8593,   739,\n",
            "         17366, 35144,  8236,  7513,  7605,   739, 23960,  8381,  7605,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7763, 15978,   739,  8715,  7880, 10662, 11556, 13879,\n",
            "          7970, 15800, 17843, 18101,  8146,  7471,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9299,  8420, 21332, 38270,   739,  9203, 10737,\n",
            "          8452,  7478,  8213,  8563,   739, 14796,  7428, 15983,  8615, 27246,\n",
            "         15275, 41521,  9230,  8609,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7501,  7892,   739, 25717,   739, 12789,  8615,   739,\n",
            "          9091,  8243,  8756,  7532, 13906,  9695,  9025,  9080, 13815,  8711,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401, 16547, 49375,\n",
            "          9072,  7697,  6920,  7847,   739, 16547,  9103,  7258,   739, 10632,\n",
            "          7889,  8381,  9118,  8189,  8152,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7496,  7760,   739, 10382,  7561, 15473, 22375,  9695,\n",
            "          9025,  9846,  6969,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9407,  8513, 37699,  7429,   739,  9039, 40774, 10252,  7865,\n",
            "           739, 14330,  6963,  7219,  7605,  8550,  7244,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 13522,  7426,  9695,  9025,  9080, 48541,  9242,  9379, 13815,\n",
            "         15084,  7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9170,  7374,  8193,  8326,  6841,   739, 44167,  8588,  6963,\n",
            "          7219,  7605,   739, 31973, 40827,  6831,  8052,  8272,  8006,  8588,\n",
            "          6963,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8420,  8446, 19763,  8240, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4,  9548, 32450, 20600, 18101,   401, 26473,  8429,\n",
            "          8413,  7771,  7281,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11046,  7141,  8125,   739,  9215,  7892,  7851,   739, 20570,\n",
            "         43075,  7182,  8265,  6860,   739,  9077,  7000,   739, 30146,  7094,\n",
            "          7433,  7426,  9695,  9025,  9080,  9242,  9620, 48397,  8711,  8084,\n",
            "           739,    10,     4, 32450,  9278,  9564, 20600, 18101,   401, 27895,\n",
            "          8006,  8658,  8588,  6963,   739,  9163, 27467, 30146,  7094,  9027,\n",
            "          8269,   739,  9763,  8117, 21899,  8330,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7597,  7416,  7671,  8213,  6953,  8066,  9299,  6881,\n",
            "          7760,  8066, 26367, 10234, 20570,  7249,  9810,  6958,  7967,  7894,\n",
            "         15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 19275,  9583,  8346,   739, 19216,  7654,\n",
            "          8139,  7605,  6903,  9163, 27467,  8276,  8168, 22092,   739, 11361,\n",
            "          7889, 44167, 19970,  8139,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9065,  7880,  6889,  7880,  8704,  8066,  9040,  8721,  8066,\n",
            "         12980,  8158,  8066, 10758,  7478,  7824, 11556,   739,  8569,  7470,\n",
            "         31406,  9242,  9379,  9666,  8236,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,   739,  8569, 18101,   739,  8569,\n",
            "          9063,  7561,  9043,  7889, 12438,  8149,   739, 10758,  7478, 22092,\n",
            "         33859, 38270,   739,   739,  8569,  9324,  7605,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 30191, 12471, 31406,  9242,  9379,  9666,  8236,  7801,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9105,  7557,\n",
            "          7654,  8139,   739,  9831,  8690, 22092, 42228,  8456, 13503,   739,\n",
            "         33953,  8006,  7557,  7654,  8139,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 34735, 15832, 39137,  8456,  8341,  8066, 21807,  8066,  9274,\n",
            "          7413,  6824, 17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,\n",
            "          7055,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         23865,  8470,  7478,  7258,  7669,  7772, 36568,   739,  9072,  6855,\n",
            "          9206,  8467,  9421, 12338,   739,  9596,  7172,  8420,  8255, 43160,\n",
            "          7172,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6835,  8762, 13906,  9695,  9025,  9080, 13815,  8711,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401, 16314,  9499,\n",
            "         20551, 33752,  7605,   739,   739,  6982,  8158,  9174, 23013,   739,\n",
            "         47957, 12024,  8420,  8187,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 25542,  8272,  8006,  8346,   739, 24562,   739,  9077, 20479,\n",
            "           739, 15090,  8272,  8006,   739,  9098,  8381, 13906,  9695,  9025,\n",
            "          9080, 13815,  8711,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 43272,  8006,  8346,  7654,  8139,   739,  9077, 20479,  9050,\n",
            "          8093, 48832,  8237,   739,  9077, 20479, 20512,  9039, 40774,  9118,\n",
            "          7469,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7609,  8397,  6963,  8420,   739,  9132,  7556, 15800,\n",
            "         17843, 18101, 13815,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9132,  7556,  8474,  7079,  6920,   739, 44167,  6963,  8420,   739,\n",
            "         48656,  8263,  9055,  7669, 48908,  7605,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8126,  7847,  7188,   739, 49727,  7877,  8368,  7208,\n",
            "          8420,  8255,   739, 44167, 15473,  9695,  9025,  9080, 18101,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 16314,  7258,  7669,  7791,\n",
            "           739,  9338,  8420,  8068, 31551,   739, 16314,  7489,  7258,  8187,\n",
            "          6893,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7789,  7461,   739,  9042,  7848,   739, 29000,  8066,\n",
            "          8148, 15473, 22375,  9695,  9025,  9846,  6969,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9089,  8006, 33752,  7605,   739,\n",
            "          9722,  8708,  7848,  8236,  7556,  8425,   739,   739,  7736,  7735,\n",
            "         35119, 36568,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9246,  6824, 17494, 18101, 11063, 13815,  8705, 12230,  9199,\n",
            "          9019,  7055,  8084,   739,    10,     4, 32450,  9278,  9564, 20600,\n",
            "         18101,   401,  9072,  6855, 20738,  8326,  6841,   739, 24724, 13444,\n",
            "          9034,   739, 32291,  6963,  7605,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8694, 33375,   739, 35494,   739,  9265,  8037,   739,\n",
            "          9153,  7258,  8125,   739,  9096,  6866,  7970, 15473,  9695,  9025,\n",
            "          9080, 18101,    10,     4,  9548, 32450, 20600, 18101,   401,  9803,\n",
            "         47922,  7970, 29523,  7772, 36568,   739, 33974,  8474,  7692,  8263,\n",
            "          8187,   739,  9893,  7048, 19193,  6866,  8608,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9319,  7467,  8608,   739, 33468,  7373, 33375,   739,  9546,\n",
            "          8420,   739,  9499, 20551,  8704,  7426,  9695,  9025,  9080, 48541,\n",
            "          9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 46311,  8519,  8467,   739, 10821,  6951,\n",
            "          7549,  6946, 10015,  8511,  9077, 11556, 11244,  7605,   739,  9128,\n",
            "         20479,  7631, 13503,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7120, 15800, 17843, 18101,  9666,  8236,  7801,  8084,\n",
            "            10,     4, 32450,  9278,  9564, 20600, 18101,   401, 17690,  7771,\n",
            "          7281, 45798,   739,  9755,  8213,  6958,   739, 16314,  8528,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8170,  8365,   739, 10964,  8056, 18693, 15800, 17843,\n",
            "         18101, 13815,    10,     4,  9548, 32450, 20600, 18101,   401, 38710,\n",
            "         22887,  8102, 12937, 13503,   739,  9150,  8365,  7556,  8425,   739,\n",
            "          9150,  8365,  6920,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 23511,  8470, 10324,  9164,  7609,  8397,  8570,  8066,\n",
            "         35403,  7621,  8539, 13047, 20618,  9277, 13088,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 23865,  8470,  7478, 44167,  7556,  8425,\n",
            "           739, 17690,  7000,  8420,   739,  9081,  8006,  7252,  8168,  8330,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 35309,  7098,  6853, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9022,  7479,\n",
            "          8084,  6853,  8599, 20512, 35119, 36568,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8772,  7407,  7865,   739,  9079,  7588,  6920,  7847,\n",
            "           739, 20512, 13906,  9855, 16285,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9315, 20551, 30282,  7772, 36568,   739,\n",
            "         33974, 21323,  6920,  7847,   739,  9719,  8187,  9072,  7697,  7532,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 29523,  8187,  7671,  8213,  6953,  8066,  9070,  8420, 24665,\n",
            "          7561,  8066, 13162,  8066,   739,  8308,  7532,  7470, 31406,  9242,\n",
            "          9379,  9666,  8236,  7801,  8084,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9070,  8420,  7584,  7488,  6920,  7847,   739,\n",
            "         12218,  7532,   739, 13162,  7501,  8094,  8528,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7321,  6920,  7321,   739,  9120,  7066,  8474,   739,\n",
            "         37302,   739, 14330,  6963, 19824,   739, 22124,  6949, 15473,  9695,\n",
            "          9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         28017,  7626,  7622,   739,   739,  8569,  7584,  8031,  8474,  6920,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,   433,  7182, 34653,  8000,  7111,  8168, 18688,  9719,\n",
            "          7847,  7188, 13047, 20618,  9277, 13088,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9065,  7209,  8424,  7079,  7532,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 24562, 22416,   739, 15699,  8381,  7692,   739, 35119, 41521,\n",
            "           739, 31367,  8511,  7470, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401, 10632,  7889,\n",
            "          8381,  9118,  8189,  8152,   739, 17366,  7967,  7894,  7763,  7770,\n",
            "          8588,  6963,   739, 23980,  9777,  9099,  8159,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 38514,  8092,  7756,  6893, 15473, 22375,  9695,  9025,  9846,\n",
            "          6969,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9164, 29716,  8126,  8187,  6893,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 46760,  7585,  7889,  8381,   739,  9211,  8000,  8615,\n",
            "          6841,   739, 43396, 20186,   739,  9145,  8381, 12206, 13906,  9855,\n",
            "         16285,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         17268,  7889,   739,  7395,  7599,  7258,  7669,  8694,   739,  9528,\n",
            "          9301,  8431,  9942, 13529,  9203, 12438,   739,  9059,  8037, 50252,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 20570,  8615,  7880, 10410,  9695,  9025,  9080,  9242,  9620,\n",
            "         48397,  8711,  8084,   739,    10,     4, 32450,  9278,  9564, 20600,\n",
            "         18101,   401, 45416,  6824, 40147,  6919, 12715, 46760,  7585, 22092,\n",
            "           739, 43272,  8006,  7849,  7198,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7249,  9810,  6958,  8092,  7260,   739, 37290,   739,\n",
            "          9103,  6824,  7183, 13906,  9855, 16285,  9666,  8244,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 23763,  8563,  9145,  7487,  9077,\n",
            "          7596,   739, 26473,  8068,  8159,  8330,   739, 46311, 16314, 33752,\n",
            "          7605,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194, 31238,  7648,  8066, 49417, 22278,  8066, 10814,  8625,\n",
            "          7979,  6953, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 40053,  8679,  9340, 14330,  6963,   739,\n",
            "          9174,  7472,  9206,  7556,  8425,   739,  9181,  8528,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 30280,  8066, 11355,  7760,  8213, 24655,  9074,  8054,\n",
            "          8066, 23911,  7979,  6953, 15473,  9695,  9025,  9080, 18101,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 10286,  7543, 27632,  9848,\n",
            "          8539,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 10076,  8335,  6920,  7847,   739, 49417, 22278,  7470, 36258,\n",
            "          9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 39169,  8000,  7111,  8168,  8006,  8588,  6963,\n",
            "         21332,   739, 12024,  7488,  7692, 43933,   739, 21046, 27467,  8187,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9079,  8125,   739,  9072,  7697,  8000,  7111,  7426,  9695,\n",
            "          9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,\n",
            "            10,     4, 32450,  9278,  9564, 20600, 18101,   401,  9072,  7697,\n",
            "          7079,  7532,   739, 44167,  9474,  7258,  8474, 16547,  8330,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8186,  7194,  7395,   739,  9193,   739,  9301,  8507,\n",
            "          7485, 13906,  9695,  9025,  9080, 13815,  8711,  8244,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9215,  8471,  9072,  7697,  9099,\n",
            "          8159,   739, 11057, 19829, 16314, 33752,  7605,   739, 12213, 20551,\n",
            "          8165,  8346,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 40796,   739,  9345,  8038,   739, 20570,  7194,  6949,\n",
            "           739,  9407,  8513, 49033,   739, 14330,  6963, 16182,  7194,  7395,\n",
            "         15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9133,  7407,  7865, 10321,  7397,  8690, 21279,  6866,\n",
            "          8608,   739,  9777,  8381,  7605,   739, 24155,  8679, 12303,  7467,\n",
            "          7652,  9375,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 44746,   739, 12663,  8006,   739,  9042,  7848,   739,\n",
            "         10133,  8658,  7478,   739,  9358,  7979,  6953, 13906,   739,  7570,\n",
            "          9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9722,  8708,  7848,  8236,  7556,  8425,   739,  9193, 24998,\n",
            "         22416,  7185,  8159,   739, 35815, 30322,  8548,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 23269,  7426,  9695,  9025,  9080, 48541,  9242,  9379, 13815,\n",
            "         15084,  7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 18140,  7648,   739,  9390,  6825,  6963,  8420,   739, 43272,\n",
            "          8006,  7790,  7597,  8263,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7533,  8420, 16146,  8126,  7847,   739,  9039,  8618,\n",
            "          8091,   739, 50380, 12206,   739, 11093,  7877,  7019,  7877, 15473,\n",
            "         22375,  9695,  9025,  9846,  6969,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 10758,  7478, 50252,   739,  9109,  8615,  7258,\n",
            "          7669,   739, 48270, 44167,  8588,  6963,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7561,  8187,  7671,  7561,  8187,  7671,   739,  9077,\n",
            "          6828,  7692,   739,  9300,  6884,  8346, 13906,  9855, 16285,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9098,  7561,\n",
            "          7139,  7452,  8263,  8528,   739,  9098,  8168,   739,  8282,  7739,\n",
            "           739,  9300,  6884,  8346,  7188,  7760,  7556,  8425,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 26811, 16621, 26367,  6958,  7335,  8066, 38710, 22887,\n",
            "          8102,  8066,  9470,  7760, 15800, 17843, 18101,  9666,  8236,  7801,\n",
            "          8084,    10,     4,  9548, 32450, 20600, 18101,   401,  9072,  6855,\n",
            "         50033, 12775,  8092,  7172,   739, 50033, 14330,  6963,   739, 38710,\n",
            "         22887,  8102, 12937, 13503,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8570,  7235, 21700,  9270, 27467, 15473, 22375,  9695,\n",
            "          9025,  9846,  6969,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 33974,  8186,   739, 28017,  6920,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8196,  9581,  8066,  9132, 11211, 22092, 13047, 20618,\n",
            "          9277, 13088,    10,     4, 32450,  9278,  9564, 20600, 18101,   401,\n",
            "         11949,  7172,  8371,   739, 10252,  8563, 10286,  7543,  9421, 12338,\n",
            "           739, 10252,  8563, 10286,  7543,  9203, 25322, 11244, 13503,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39104,  8018, 13028, 35403, 27467, 15800, 17843, 18101,  8146,\n",
            "          7471,    10,     4,  9548, 32450, 20600, 18101,   401, 17366,  6841,\n",
            "          8168,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 11163,  8474, 20551,   739,  9201, 50252,   739,  9138,\n",
            "          8240, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 19275,  9583,  8346,   739, 10859,  6920,  7605,\n",
            "           739, 46311,  7219,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7281, 10662, 15473,  9695,  9025,  9080, 18101,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9123, 28035, 39137,  9942,\n",
            "         13529,   739, 39137, 23707,  8420,  8255,   739,  9072,  6855, 13883,\n",
            "          6951,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 36514,  7596,  6938,   739, 47729,  8420,  8570, 21332,   739,\n",
            "          9129,  7793,  8528,   739,  9427,  7487,  7533,  8420,  8126,  7847,\n",
            "           739, 34284,  7321,  7426,  9695,  9025,  9080,  9242,  9620, 48397,\n",
            "          8711,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9174, 23013,  6893,   739,  9128,  7056,  8187,  6893,   739, 12218,\n",
            "          8146,  7609,  8403,  6920,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 12937, 13503, 22092, 15473,  9695,  9025,  9080, 18101,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 44167, 12937, 13503,\n",
            "           739,   739,  8341, 12937, 13503,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8367,  8754, 22278,   739,  9049,  7904,  8091,   739,\n",
            "          9092,  7561,  8091,  7533,  8420,   739, 48908,  8168, 13906,   739,\n",
            "          7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 33974,  7258,  7669,  7904,   739, 11509,  7689,  7778,\n",
            "          7689,   739, 43551,  6920,  7847,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 31260,  8158,   739, 23330, 33845,  9695,  9025,  9080, 48541,\n",
            "          9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9118,  8756,  6903,  8701,  6853,  8671,\n",
            "          7281,   739, 50900,  8694,  8159,   739, 13879,  8694,  8159,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9942,  8643,  7428,  8420,  7172,  7335,  7426,  9695,  9025,\n",
            "          9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4, 32450,\n",
            "          9278,  9564, 20600, 18101,   401,  9893,  7048, 19193,  6866,  8608,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9488,  7122,  7372, 29708, 46311,  7673, 20479,  8091,  8066,\n",
            "          9050,  7757,  9466,  8397,  8066, 18006,  7487,  7469,  6860,  7470,\n",
            "         31406,  9242,  9379,  9666,  8236,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9267,  7209,  7188,  6835,  8194,\n",
            "           739, 17366,  7967,  7894,  7763,  7770,  8588,  6963,   739, 19216,\n",
            "          8220,  9193, 50252,  7654,  8139,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 30982, 40774, 15473,  9695,  9025,  9080, 18101,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9076,  8628, 26473,  9203, 12438,\n",
            "           739,  9338,  8420,  6963,  8381,  7605,   739,  9039, 40774, 20358,\n",
            "          8519,  8519,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9079,  8276,  7410,  7372,  8420, 30908, 36258,  9242,  9702,\n",
            "          9182, 11909,  9666,  8244,    10,     4, 32450,  9278,  9564, 20600,\n",
            "         18101,   401, 46311,  8420,  8255,  7429,  8588,  6963,   739,  9039,\n",
            "         40774, 20358,  8519,  8519,   739,  9259,  7760, 12937, 13503,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7804,  7397,   739, 23672,  7793,  8528,   739, 40276,\n",
            "         12206, 15800, 17843, 18101, 13815,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,   739,  7736,  7735, 35119, 36568,   739, 26248,  8467,\n",
            "          8095, 20271,   739, 14796,  7428, 15983,  8615, 27246, 15275, 41521,\n",
            "          9230,  8609,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7426,  8255,  7487,   739,  9233,  8006,   739,  9826,\n",
            "         15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9233,  8006,  8000,  7111,  8330,   739, 12213, 20551,\n",
            "          7670,  8006,  8346,  6920,   739,  9117,  8267,  8643, 13529,  9244,\n",
            "          7596,  7877,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8711,  7791,  8168,  8066,  9300, 18563,  6920, 14314,\n",
            "          8066, 11949,  6824, 15800, 17843, 18101,  8146,  7471,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9528,  9301,  8431, 27752,   739,\n",
            "         26367,  6958,  6963,  8420,  8326,  6841,   739,  9831,  8690,  9474,\n",
            "          8528,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9030,  7730,  8066, 10286,  7543,  8260,  8066, 23168,  6905,\n",
            "          9436, 17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 16605,\n",
            "         13503,  7772, 36568,   739, 10187,  7616,  8146,  7079,  8346,   739,\n",
            "         12678,  8146, 16180,  7079,  8346,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 15275,  7397,  8066, 23672,  7793,  8528,  8066, 40276, 19421,\n",
            "         31406,  9242,  9379,  9666,  8236,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9072,  8688, 10645,  6958,  7138,\n",
            "           739, 26248,  8467,  8095, 20271,   739,  9488,  7407,  8754,  8708,\n",
            "          8528,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8774,  8196,  8033, 12287, 28017, 25671,  9079,  6903,\n",
            "         15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9050,  7652,  8429,  7235,  8033,  8006,  8052,  8689,\n",
            "          7771,  7281, 45798,   739,  9050,  7652,  8429,  7235,  8033,  8006,\n",
            "          8052,  7690, 38270,   739,  9081,  8006,  7772, 36568,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 43093, 19911, 16180,   739,  9132,  8018,  7198,   739,\n",
            "          9470,  7198, 15473, 22375,  9695,  9025,  9846,  6969,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 17366,  6841,  8168,   739,\n",
            "         33953,  7849,  7198,  7654,  8139,   739,  9470,  7198,  7654,  8139,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6905,  8159, 13906,  9855, 16285,  9666,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 35985,  8679,  9098, 12272,\n",
            "          9664,  7824,  8563,   739, 47283,  9058,  8159, 33752,  7605,   739,\n",
            "          9058,  8159, 18218,  8537,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9407,  8513,  7877, 18518, 36258,  9242,  9702,  9182, 11909,\n",
            "          9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401, 10859,\n",
            "          7824, 11556, 14330,  6963,  6828,  8420,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7777,  7393, 24824, 13906,   739,  7570,  9695,  9025,\n",
            "          9341,   739,    10,     4, 32450,  9278,  9564, 20600, 18101,   401,\n",
            "         46311,  7219,  7605,   739,  9170,  7374,  9848,  8539,  9114,  7690,\n",
            "         38270,   739,  9174,  7472,  8168,  7965,  8326,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 38514,  7000,  8270,   739, 18120,  6889, 32599,   739, 27752,\n",
            "          7621, 15800, 17843, 18101, 13815,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 10252,  8563,  9407,  8255,  9230,  8469,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39102,  8615,  7198,   739,  9497, 12830,  7760,   739,  9020,\n",
            "           690,   394,  7487,   739, 25359, 22092, 13906,  9855, 16285,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9028,  8117,\n",
            "          7532,   739, 10286,  7543, 19216,  8721,  9201, 50252, 16605, 13503,\n",
            "           739,  9105,  8721,  9340, 11029,  7605,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8105, 44743, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4, 32450,  9278,  9564, 20600, 18101,   401, 26367,\n",
            "          6958,  6874,  8159,  8346,  7652,  7904,   739,  9454,  9581,  8420,\n",
            "          8513,   739, 19508,  8006, 16215,  8092,  8599,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7512, 11211,  7281,   739, 24104,  7605,   739,  9091,\n",
            "          8397,  8074, 13906,  9855, 16285,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 26207,  7700,  7692, 43933,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 21424, 40827, 13906,  9855, 16285,  9666,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 31973, 40827,  6831,  8052,\n",
            "          8272,  8006,  8588,  6963,   739, 31973, 40827,  8528,  7847,  8126,\n",
            "           739,  9697,  8006,  7772, 36568,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7182,  8265,  8166,  8066,  9203, 38295,  8420,  8255,\n",
            "         44803,  8066, 23707,  8420,  8255,  6889,  8368,  8745,  8066,  9524,\n",
            "         24516,  9339,  8420,  7760, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,  9407,\n",
            "          7372, 16983,  7888,   739, 10907, 14571,  8339,  7321,   739, 13879,\n",
            "          8694,  8159,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 15090,  8272, 10987,  9695,  9025,  9080, 48541,  9242,  9379,\n",
            "         13815, 15084,  7801,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9132,  7244,   739, 10055,  7652,  8346,   739, 31973,\n",
            "         40827,  6831,  8052,  8272,  8006,  8588,  6963,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 10286,  7543,  8260,  8066,  9719, 12031,  9132,  7398,  8066,\n",
            "          9073, 22412,  6824, 17494, 18101, 11063, 13815,  8705, 12230,  9199,\n",
            "          9019,  7055,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9072,  7697,  7079,  7532,   739, 16605, 13503,  7772, 36568,\n",
            "           739, 12213, 20551,  6826,  8168,  7654,  8139,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 10076,  8335,  6920,  7847,   739, 49417, 22278,  7426,  9695,\n",
            "          9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 12218,  8146,  7609,\n",
            "          8403,  6920,   739, 33468,  7373,  9121, 20716,  9118,  8425,   739,\n",
            "         16547,  9103,  7258,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8694,  7865,  7824, 11556,  9746,  6830,  8570, 21332,\n",
            "         15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9163, 27467,  7321,  8456, 13503,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8446, 11211,  7281, 26419,  9818,  8066,  9427,  7487,\n",
            "          7561,  8066,  9114,  7652, 15473,  9695,  9025,  9080, 18101,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9133, 40115, 36910,  8539,\n",
            "           739, 30613,  7584,  9848,  8539, 38270,   739,   739, 39610,  8381,\n",
            "          7605,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6893,  7616,   739,  9110,  8006, 21143,   739,  9203,\n",
            "          7383,  6963,   739, 16476,  8255, 22092, 13906,  9695,  9025,  9080,\n",
            "         13815,  8711,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         10187,  7616,  8146,  7556,  8425,   739,  9315, 20551, 10187,  7616,\n",
            "          8146,  7556,  8425,   739, 10623,  7533,  8420,  8615,  7383,  8588,\n",
            "          6963,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8243,  8066,  9166,  7584,  8052,  8272,  8006, 30003,\n",
            "         11294,  7244,  8066,  9300, 18563,  7496,  6826,  8168,  8066, 46311,\n",
            "         15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 11057,  7992,  7824, 22512,   739, 46311,\n",
            "          8420,  8255,  7429,  8588,  6963,   739, 41021, 50252,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 42530,  7480,  7694, 11556,  9020,   690,   393, 27925, 10133,\n",
            "          8658, 10324,  9070,  8420, 24665,  7561, 13047, 20618,  9277, 13088,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9070,  8420,  7584,\n",
            "          7488,  6920,  7847,   739, 12218,  7532,   739,  9089,  8006, 11093,\n",
            "          7877,  7019,  7877,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9218,  8066, 30191,  8066, 10389,  8066, 29000, 46760,  7585,\n",
            "          8066, 21035, 46840, 17494, 18101, 11063, 13815,  8705, 12230,  9199,\n",
            "          9019,  7055,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 11141,  8519,  7098, 13420,  9203, 12438,   739, 24708,  9064,\n",
            "          7372,  8519, 35119, 36568,   739,  9081,  8006,  8052, 22085,  7772,\n",
            "         36568,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8446,  7586,   739,  9170,  7374,   739,  9358,  7584,\n",
            "           739, 14330,  6963, 19824, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9170,  7374,\n",
            "          8330,   739,  9904,  6903,  7461, 12443,  7833,  7605,   739,  9181,\n",
            "          8528,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7524,  7428,  8066, 10814,  8474,  8066, 24694, 15800,\n",
            "         17843, 18101,  8146,  7471,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 19275,  9583,  8346,   739,  9079,  7262,  8187,   739, 12213,\n",
            "         20551,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8339,  6958,  8168,  8066,  9132,  8018,  8033,  6949,\n",
            "          8066,  9065, 32599,  8066, 19216,  8066, 26367,  6958,  7290,  7894,\n",
            "         13047, 20618,  9277, 13088,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 44167,  7605,  7669,  8425,   739, 35796, 49375,  9072,  7697,\n",
            "          6920,  7847,   739, 26367,  6958, 45825,  8187,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 38512,  6889, 10234,  9546,  8420,  7760,  8066, 26473,  7760,\n",
            "          8066, 20570,  8615,  7182,  8265,  6860,  8066,  9065,  7182,  8420,\n",
            "          8255, 15800, 17843, 18101,  8146,  7471,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9128, 20479,  7631, 13503,   739,  9128, 20479,\n",
            "          8495,  7756, 13987,   739, 20512,  7791,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 50595,  7540,   739, 35403,  7621,  8539,   739, 40276, 15473,\n",
            "         22375,  9695,  9025,  9846,  6969,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 35264,  6920,   739, 25805,  7502,  8186, 38270,\n",
            "           739,  9233,  8006,  6835,  8194,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 29511, 32599,  8066, 28545,  8243,  7416,  7671,  8066, 10964,\n",
            "          8056, 18693,  8066, 10814,  7605,  8066, 35753, 16943, 15800, 17843,\n",
            "         18101,  9666,  8236,  7801,  8084,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,   739,  7010,  9885,  8397,  8330,   739, 33953,  7849,\n",
            "          7198,  7654,  8139,   739,  9098,  7561,  7849,  7258,  7669,  8326,\n",
            "          6841,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9079,  8125,   739,  9072,  7697,  8000,  7111,  7426,  9695,\n",
            "          9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4,\n",
            "         32450,  9278,  9564, 20600, 18101,   401, 44167,  9474,  7258,  8474,\n",
            "         16547,  8330,   739,  9072,  7697,  7079,  7532,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,   392,   690,   393,  6841, 15800, 17843, 18101, 13815,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9356,  7556,  9072,\n",
            "          7697,  6920,  7847,   739, 33974, 21323,  7258,  7669,  8330,   739,\n",
            "         24724, 13444,  9169,  6963,  8420,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7837,   739,   739,  8174,   739,  9118,  7492, 29975,\n",
            "           739,  9164,  7609,  8397, 15800, 17843, 18101, 13815,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9118,  7492, 29975,  7556,  8425,\n",
            "           739, 35796,  8052,  8467, 24831,  7991,  8511,   739, 43272,  8006,\n",
            "          7654, 16570,  7824,  7532,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9065, 32599,  7426,  9695,  9025,  9080,  9242,  9620, 48397,\n",
            "          8711,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         33974,  7847, 23024,   739, 12213, 20551,  8196,  8126,  7654,  8139,\n",
            "           739, 10859,  7849,  7258,  7669,  8326,  6841,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9164,  7609,  8397,  8570,   739,  9488,  7407, 12206,  7426,\n",
            "          9695,  9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,    10,\n",
            "             4, 32450,  9278,  9564, 20600, 18101,   401,  9488,  7407,  8092,\n",
            "          7244,   739, 13108,  8006,  7219,  7605,   739,  9488,  7407, 20111,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9044,   739,  9166,  7584,  8052,  8272,  8006,  8346,   739,\n",
            "         11294,  7244,   739,  9300, 18563,  7496,  6826,  8168,   739, 26521,\n",
            "          9926,  9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,  9072,\n",
            "          7697,  7902,  6920,  7847,   739,  9070,  6947,  7380,  7318,   739,\n",
            "         46311,  6982,  8158, 21323,  8330,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9749,  7182, 13729,  9429,  7793,  8528,  8066, 14264,  8168,\n",
            "          6824, 17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 19275,\n",
            "          8149,  7889, 49375, 30057, 27268,  7605,   739,  9072,  6855,  9206,\n",
            "          8467,  9421, 12338,   739,  9072,  6855, 50033, 12775,  8092,  7172,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8429,  7122,  7372,  8125,   739, 46311,  7673, 20479,\n",
            "          8091,   739,  9050,  7757,  9466,  8397,   739, 18006,  7487,  7469,\n",
            "          6860, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 17366,  7967,  7894,  7763,  7770,  8588,  6963,\n",
            "           739, 27895,  8006,  8658, 38270,   739, 29523, 17170,  8461,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9020,   690,   393,  6841,   739,  9092, 24242,  7597,   739,\n",
            "         12077,   739, 47729,  8420,  8570, 21332,  7426,  9695,  9025,  9080,\n",
            "         48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 30057, 22042,  9407,  8255, 35119,\n",
            "         36568,   739, 26367,  6958, 12870,  6951,  8146,   739, 26493, 39476,\n",
            "          9324,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7847,  7763,  8161,  7741, 10324, 10581,  8135,  8066,\n",
            "         48081,  8168, 15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 11181, 40147,  7584,  8031,\n",
            "          6920,   739, 29755, 23025,  7654,  8139,   739, 33468,  7373,  7847,\n",
            "         23024,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 25542, 10415, 15473,  9695,  9025,  9080, 18101,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9114, 10415,  7556,  8425,   739,\n",
            "         23763,  8563,  7487,  7521,  7588,  6920,  7847,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 29511,  7847,   739, 20007,  7120,  7258,   739,  9226,  7847,\n",
            "           739, 10814,  8772, 32599,   739,  9098,  7561, 15800, 17843, 18101,\n",
            "         13815,    10,     4,  9548, 32450, 20600, 18101,   401,  9301,  7185,\n",
            "         43243,  7669,   739, 31973, 40827, 20512, 35119, 36568,   739,  9028,\n",
            "          8117,  7532,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8563,  8701,  8091,  8066, 40276,  8260, 15800, 17843,\n",
            "         18101,  9666,  8236,  7801,  8084,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 10099, 10754,  7172, 38270,   739,  9036,  7889,  7188,\n",
            "          8000,  7111, 38270,   739, 12024,  7488,  8168,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9193,   739, 12303,  7497, 13432,   739,  9201, 50252,  7198,\n",
            "         13558, 36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 26473,  7654,  8139,  7605,   739,\n",
            "          9036,  7889,  9395,  7847,   739,  9105,  8721, 10104,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,   433,  7533,  8420, 46812, 18688,  9203, 10737,  8066,\n",
            "         23426, 50252, 15473, 22375,  9695,  9025,  9846,  6969,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9203, 10737,  8452,\n",
            "          7478,  8213,  8563,   739,  9128, 20479,  7631, 13503,   739, 10821,\n",
            "          6951,  7549,  6946, 10015,  8511,  9077, 11556, 11244,  7605,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 26280,  8381, 15473,  9695,  9025,  9080, 18101,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9063,  8381,  7772, 36568,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7258,  7472,  8066, 12443, 13047, 20618,  9277, 13088,\n",
            "            10,     4, 32450,  9278,  9564, 20600, 18101,   401,  9079,  7262,\n",
            "          8187,   739, 23826, 45837,  7772, 36568,   739, 27196,  6866,  7692,\n",
            "         43933,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7383,  7293,  7756, 13906,   739,  7570,  9695,  9025,\n",
            "          9341,   739,    10,     4,  9548, 32450, 20600, 18101,   401,  9338,\n",
            "          8420,  8519,  7182,  8511,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7187,  6828,  8066,   739,  8316,  6919, 25308, 17690,\n",
            "          7654,  8146, 15800, 17843, 18101,  8146,  7471,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9043,  7889, 34243,  9352,  7244, 15381,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 38513,  8168, 15473,  9695,  9025,  9080, 18101,    10,     4,\n",
            "         32450,  9278,  9564, 20600, 18101,   401,  9105,  7557,  8187,  6893,\n",
            "           739,  9674, 29161,  7258,  8420, 22092,   739, 46894,  7532,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9474,  7848, 45837,   739,  9203, 10737,  6841,   739, 17939,\n",
            "           739, 30191, 12471, 36258,  9242,  9702,  9182, 11909,  9666,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9203, 12438,  7772,\n",
            "         36568,   739, 11141,  8519,  7098, 13420,  9203, 12438,   739,  9105,\n",
            "          8721, 29791, 17690,  6828,  7692,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7306,  6958,  8290,   739, 48908,  7182,   739, 26473,\n",
            "         15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 48832, 26473,  8588,  6963,   739,  9098,  7561,  8615,\n",
            "          8187,   739, 22311, 28433,  9132,  7244,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8346,  7847, 13906,  9855, 16285,  9666,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 46936,  7847,  8688,   739,\n",
            "         47283, 19970,  8139,   739, 16314,  9664,  8213,  7335,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47063,  7410,   739, 10632,  7793,  8528,   739,  9959, 24855,\n",
            "           739,  9324,  8427,  6920,  7561,   739,  9117,  6866,  8599, 13906,\n",
            "          9855, 16285,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 10301,  8263,  7000,  8420, 38270,   739,  9123, 28035, 39137,\n",
            "         10645,  7877,  6866,  8519,   739, 21899,  8704,  7889, 21332,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,   392,   690,   397,  6841,   739, 48832,  7595,  7265,\n",
            "         13906,  9695,  9025,  9080, 13815,  8711,  8244,    10,     4, 32450,\n",
            "          9278,  9564, 20600, 18101,   401,  9315, 20551, 10187,  7616,  8146,\n",
            "          7556,  8425,   739,  9034,  8326,  6841,   739,  9036,  7889,  9395,\n",
            "          7847,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  6831,  8052,  8272,  8006, 15800, 17843, 18101, 13815,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9098,  7561,  7644,\n",
            "          7584,  7605,   739, 43272,  8006,  7759,  8186,   739, 10055,  7652,\n",
            "          8346,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 10321,  7397,  8690,  6824, 17494, 18101, 11063, 13815,  8705,\n",
            "         12230,  9199,  9019,  7055,  8084,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 16314,  9664,  8213,  7335,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9086,   739,  9259,  7894,   739,  9526,  7489,  7258,   739,\n",
            "          9297, 37142,  7767,   739,  9346,  7426,  9695,  9025,  9080,  9242,\n",
            "          9620, 48397,  8711,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9208, 26473, 44167,  9118,  8425,   739, 29523,  8528,\n",
            "           739,  9128, 20479,  8495,  7756, 13987,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7492,  7480,  8159, 47818,  9132,  7244,  8066,   739,\n",
            "          8308,  7532,  8066,  9319,  7467,  8608,  7991,  8066, 21112,  6893,\n",
            "          7281, 15800, 17843, 18101,  8146,  7471,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 17690,  8456, 13503,   739, 33974,  8092,  7244,\n",
            "           739, 22311, 28433,  9132,  7244,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 18120,  7533, 15978,  9059,  6847,  7760,  8066,  9673,  8474,\n",
            "         12206,  8066,  9059,  8367,  7470, 31406,  9242,  9379,  9666,  8236,\n",
            "          7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         35960,  7556, 21332,   739, 48908,  8168,  7321,  7654,  8146,   739,\n",
            "         10382,  7605,  8263, 35634,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47063,  6953, 15800, 17843, 18101, 13815,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 17690,  7000,  8420,   739, 17366, 20479,\n",
            "         19216,  8309, 19970,  8139,  7605,   739,  9098,  7763,  8187,  7653,\n",
            "          7561,  8765,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7827,  8267, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 13108,  8006,\n",
            "          6826,  8168, 21332,   739, 29755,  7849,  6963,  8420,   739, 21046,\n",
            "         27467, 12443, 33752,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47063,  7000, 13906,   739,  7570,  9695,  9025,  9341,   739,\n",
            "            10,     4, 32450,  9278,  9564, 20600, 18101,   401,  9077, 23774,\n",
            "          8330,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9211,  8000,  8615, 12605, 31406,  9242,  9379,  9666,  8236,\n",
            "          7801,  8084,   739,    10,     4, 32450,  9278,  9564, 20600, 18101,\n",
            "           401, 19216,  7654,  8139,  7605,  6903,  9163, 27467,  8276,  8168,\n",
            "         22092,   739, 13108,  8006,  7219,  7605,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,   392,   690,   393,  8066, 20008,  8669,  6889, 16180,\n",
            "          8066, 28569,  7000,  7488, 15800, 17843, 18101,  8146,  7471,    10,\n",
            "             4, 32450,  9278,  9564, 20600, 18101,   401,  9596,  7172,  8429,\n",
            "          7497, 13432,  8420,  8255, 43160,  7172,   739, 47164, 24724,  7252,\n",
            "         46812,   739, 44167,  9118, 21332,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 40276, 12206,   739, 24583,   739,  9346,  9620,  7445,  7426,\n",
            "          9695,  9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9215,  8471,  9072,  7697,\n",
            "          9099,  8159,   739,  9091,  6923, 45825,  7556,  8425,   739, 17690,\n",
            "          7771,  7281, 45798,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7258, 10867,  9169,  8187,  7671,  8066,  9300,  8066,\n",
            "         21555,  7395,  8066,  9162,  6949,  6841, 15800, 17843, 18101,  9666,\n",
            "          8236,  7801,  8084,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9214,  7239, 22512,  9498,  8168,  8326,  6841,   739,  9055,  7669,\n",
            "          7489,  7258,  8528,   739,  9429,  8265,  7791,  9077,  6889, 10234,\n",
            "         43304,  8397,  7904,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7561,  8187,  7671,   739, 10286,  7543,  8260, 15473,\n",
            "         22375,  9695,  9025,  9846,  6969,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9081,  8006, 44767,  8330,   739, 12094, 15719,\n",
            "           739,  9479,  6947, 44797,  7294,  8599,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 35771,  6953,  7958,  8066,  9451, 29708,  9132,  7521,  7652,\n",
            "         13729,  9050, 19193,  7372,  6853, 11556, 15386, 15800, 17843, 18101,\n",
            "          9666,  8236,  7801,  8084,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 15386,  8263,  8269, 38228, 26248, 22092,   739,  9092,  7847,\n",
            "          8187,  6893,   739, 48270,  8236,  7513,  7605,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9046,  7019, 25308,  9413, 10546, 31406,  9242,  9379,  9666,\n",
            "          8236,  7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9413,  8006,  8000,  7111, 38270,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 30146,  7094,  7433,   739,  9526,  7489,  7258,   739, 23433,\n",
            "          8263,   739,  9138,  7492,   739, 42094,  9695,  9025,  9080, 48541,\n",
            "          9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 10489,  7489,  7258,   739,  9024,  6893,\n",
            "          8092,  6853,  8263,  8528,   739, 49375,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7249,  9810,  6958,  7541,  7760,   739, 49727,  7877,\n",
            "           739, 48268, 19911, 16180,   739,  9107, 43075, 13906,  9855, 16285,\n",
            "          9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9050,\n",
            "          7652,  8429,  7235,  8033,  8006,  8052,  7690, 38270,   739, 43523,\n",
            "         50243,  9301,  8159,   739, 19275,  9043,  7889, 34243,  9142,  7374,\n",
            "          8381,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7837, 20479,  7290,  7894,   739,  9407,  8513,  8126,\n",
            "          7847,   739, 12213,  8159,  8168, 15800, 17843, 18101, 13815,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401, 46048,  7847,  8688,   739,\n",
            "          9105,  8721,  8126,  7880,  7219,  7605,   739,  9755,  6919,  8615,\n",
            "         12438,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7777,  6835, 12206,   739,  9105,  7557, 41477,  7652,\n",
            "          7000,   739, 12678,  8146, 16180,  8704,   739, 23122, 18726,  7621,\n",
            "          8265,   739,  9020,   690,   394,  7487, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4,  9548, 32450, 20600, 18101,   401,  9072,  6855,\n",
            "          9338, 20551,  9942, 13529,  9203, 12438,   739, 35985,  8679,  9098,\n",
            "         12272,  9664,  7824,  8563,   739, 15676,  8503, 23707,   739,  7002,\n",
            "          6962,  9556,  9203, 12438,   739,     1,     3,     3,     3,     3],\n",
            "        [    2, 45576,  8006,  7557,   739,  9942, 13529,   739,  9026,  8708,\n",
            "          7470, 36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9132,  7244,   739, 23168,  7493,\n",
            "          8135,  8528,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9121,  8104,   739,  9395,  7918,  7777,  6835,   739, 25455,\n",
            "         12206,  8213,  6953,  7470, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9429,  8265,\n",
            "          7791,  9077,  6889, 10234, 43304,  8397,  7904,   739, 49375,  6866,\n",
            "          8168,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8381,  7427,   739, 23826,  8000,  7609,  8397, 13906,\n",
            "          9695,  9025,  9080, 13815,  8711,  8244,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 43523, 50243,  9301,  8159,   739, 11509,  8688,\n",
            "          7428,   739,  9664,  7824,  8563,   739, 13267,  8420,  8255,  7771,\n",
            "          7281, 45798,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 38512,  7480, 22416, 15473, 22375,  9695,  9025,  9846,  6969,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 31903,\n",
            "          8762,  8529,  7763,  6886,  8528,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 24824,  8066,  9297,  7409,  7631, 10324, 31260,  8306,\n",
            "          8615, 13047, 20618,  9277, 13088,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 11949,  7172,  8371,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7533,  8427,  6920,  7561, 13906,  9695,  9025,  9080,\n",
            "         13815,  8711,  8244,    10,     4, 32450,  9278,  9564, 20600, 18101,\n",
            "           401, 12213, 20551, 16180,  7219,  7605,   739,  9181,  8330,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9028,  7949,  8052, 24238,  7599,   739, 19508,  8006, 16215,\n",
            "          8092,  8599,   739,  9081,  8158,  7470, 36258,  9242,  9702,  9182,\n",
            "         11909,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         29523,  6920,  7847,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8346,  7918,  7777,  6835,  8066, 20570,  7198, 16123,\n",
            "         10814,  8625,  7979,  6953,  8066, 37913,  7512, 10324, 10278,  7756,\n",
            "          7692, 22092, 15473, 22375,  9695,  9025,  9846,  6969,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 49375,  6866,  8168,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39102,  8397, 45837,  8066,  9046,  8762, 38874, 15473, 22375,\n",
            "          9695,  9025,  9846,  6969,  8084,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 16547, 45837, 35119, 36568,   739, 17268,  7889,\n",
            "          7970,  7609,  8397,  8330,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9042, 26055,  9695,  9025,  9080, 48541,  9242,  9379, 13815,\n",
            "         15084,  7801,  8084,   739,    10,     4, 32450,  9278,  9564, 20600,\n",
            "         18101,   401,  9674, 29161,  7258,  8420, 22092,   739, 46894,  7532,\n",
            "           739,  9105,  7557,  8187,  6893,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9174,  8125,   739, 12218,  7532,  6920,  7847,   739,  9407,\n",
            "          8513,  8346, 10115, 36258,  9242,  9702,  9182, 11909,  9666,  8244,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9831,  8690, 22092,\n",
            "         42228,  8456, 13503,   739,  9522,  7889,  9583,  8346, 11029,  7605,\n",
            "           739, 39137,  8528,  7532,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47061,  6866,  8599,  7711,   739,  9074,  8397, 15473,  9695,\n",
            "          9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9055,  7480,  6958,   739,  9299,  6881,  7760,  6963,  7605,   739,\n",
            "         27268,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7759, 27246,  9092, 13583,  6920,  8066,  9206,  8146,\n",
            "         11556, 23960,  8066, 10076,  7492, 12206, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4,  9548, 32450, 20600, 18101,   401, 14330,  6963,\n",
            "          7219,  7605,   739, 26473,  8068, 31551,  6893,   739,  9110,  8006,\n",
            "          7219,  7605,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8040, 19824, 15800, 17843, 18101,  8146,  7471,    10,\n",
            "             4, 32450,  9278,  9564, 20600, 18101,   401, 18006,  8168,   739,\n",
            "          9376,  8746,   739,  9376,  8746,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8615, 10737,  7119,   739,  9407,  8513,  8615,  8092,\n",
            "          7208,   739,  9095, 25145,  7557,   739,  9138, 15800, 17843, 18101,\n",
            "         13815,    10,     4,  9548, 32450, 20600, 18101,   401,  9429,  8265,\n",
            "          7791,  9297,  7383,  7584, 19970,  8139,   739, 12213, 20551,  7605,\n",
            "           739, 10758,  9620,  8263,  8528,  7847,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7902,  7352,  7561,  8066, 46936,  8158,  8066,  9203,\n",
            "         38295,  8420,  8255, 44803, 13047, 20618,  9277, 13088,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9118, 12870,  6951,  8146,   739,\n",
            "         13879,  8694,  8159,   739, 47164, 24724,  7252, 46812,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7524,  7428,   739, 10814,  8474,   739, 24694, 15473,\n",
            "         22375,  9695,  9025,  9846,  6969,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9039,  7383, 17160,  7561,  7605,   739,  9079,\n",
            "          7262,  8187,   739, 26473,  6874,  8159,  8346,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7249,  9810,  6958,  7290,  7894,   739,  9358,  8772,\n",
            "          8397, 15473, 22375,  9695,  9025,  9846,  6969,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 46980,  7692,  9127, 17416,   739,\n",
            "         39137,  8528,  7532,   739,  9673,  8420,  7970, 12753,  6918,  8159,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7604, 13047, 20618,  9277, 13088,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 18890,  9043,  7889,  6886,  7374,  8330,\n",
            "           739, 10939,  7496,  8528,   739,  9904,  6903,  7461, 12443,  7833,\n",
            "          7605,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9077,  7877,  7126,  8398,  8066,  9664,  7209,  7812,  8066,\n",
            "          9214,  7239,  7597, 12715, 10076, 13652, 31406,  9242,  9379,  9666,\n",
            "          8236,  7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9039, 40774,  9664,  8213,  7335,   739,  9214,  7239, 22512,\n",
            "          9498,  8168,  8326,  6841,   739, 46311,  6982,  8158, 21323,  8330,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 28017,  7426,  9695,  9025,  9080, 48541,  9242,  9379, 13815,\n",
            "         15084,  7801,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 28017, 10104,  7252, 33823,  8146,   739,  9110,  8432,  6920,\n",
            "          7847,   739, 10301,  8263,  7654,  8139,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9288,  7695,   739,  9664,  7209,  7812,   739, 34284,  7321,\n",
            "           739, 23849,  7824,   739,  9356,  7556,  6963, 14403,  9695,  9025,\n",
            "          9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 20738,  8326,  6841,   739,  9356,  7556,\n",
            "          9072,  7697,  6920,  7847,   739, 39137,  7708,  7703,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47729,  8420,  8570, 21332,   739, 17782,  7585,  6951,  9907,\n",
            "         30908, 36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9118,  8756,  6903, 14766,  8448,\n",
            "         21323, 38270,   739,  9174, 10233,  8413,  7771,  7281, 45798,   739,\n",
            "           739,  9174, 10233,  8413,  7771,  7281, 45798,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8563,  8701,  8091,   739, 40276,  8260, 13906,   739,\n",
            "          7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 43272,  8006,  7673, 20479,   739,  9046,  7019,  7584,\n",
            "          7654,  8139,   739, 46133,  7654,  8139,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7160, 24855, 13906,  9695,  9025,  9080, 13815,  8711,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401, 12213, 20551,\n",
            "         16180,  7219,  7605,   739, 21826, 22289,  7605,   739,  9132,  7244,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,   433,  7825, 16943, 18688,  9218,  8066,  9050,  7433,\n",
            "         21878,  8066, 29645,  8052,  8149, 15800, 17843, 18101,  9666,  8236,\n",
            "          7801,  8084,    10,     4,  9548, 32450, 20600, 18101,   401,  9039,\n",
            "         40774,  9107,  7188,   739,  9117,  8267,  9942, 13529,  9203, 12438,\n",
            "           739,  9050,  7652,  8429,  7235, 50252, 25894,  7771,  7281, 45798,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6835,  7066,  8474,  8066, 35796,  8066,   739,  7010,\n",
            "          9885,  8397, 13047, 20618,  9277, 13088,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9074,  8420,  8186,   739, 35796,  7252,  8168,\n",
            "          8326,  6841,   739, 35796,  6826, 10996,  9079,  7262, 16180,  7605,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7182,  8265, 22278,   739, 40276, 12206,  8704,  7000,\n",
            "          8270, 15800, 17843, 18101, 13815,    10,     4, 32450,  9278,  9564,\n",
            "         20600, 18101,   401, 10056,  7335, 11213,  7188,  7601,   739,  9072,\n",
            "          7697,  7902,  6920,  7847,   739, 33953, 15975,  7373,  7654,  8139,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8423, 10324,  9170,  7374,  8193,  8066, 17268, 22278,\n",
            "         15800, 17843, 18101,  8146,  7471,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9407,  8513,  8124,   739,  9201, 50252,  8423,  7478,\n",
            "         22092,   739,  9059,  8037, 50252,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8615, 10737,  8615,  8092,  7208,  8066, 33468,  7373,\n",
            "          7760,  8066, 20074,  8066, 10286, 22411,  8340, 13336, 29580, 15473,\n",
            "         22375,  9695,  9025,  9846,  6969,  8084,   739,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9091,  6923, 45825,  7556,  8425,   739,\n",
            "         17366,  7967,  7894,  8237,   739, 16317, 50252,  8330,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8615, 10737,  7706,  6835,   739,  9300, 22278,   739,\n",
            "          9123, 16979,   739,  9036,  8420,   739, 14796,  8193, 15800, 17843,\n",
            "         18101, 13815,    10,     4,  9548, 32450, 20600, 18101,   401, 26367,\n",
            "         12520,  8397, 33823,  8146,   739, 49375,  6866,  8168,   739,  9098,\n",
            "          7561,  7654,  8139,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 49363,  7605,   739, 18006,  7487,  7469,  6860, 15800, 17843,\n",
            "         18101, 13815,    10,     4,  9548, 32450, 20600, 18101,   401,  9162,\n",
            "          6949,  9324,  7605,   739,   739,  8569,  9324,  7605,   739, 16547,\n",
            "          8263,  7185,  6963,  7605,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 15275,  7397,   739, 23672,  7793,  8528,   739, 40276, 19421,\n",
            "         36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 26248,  8467,  8095, 20271,   739,   739,\n",
            "          7736,  7735, 35119, 36568,   739, 24162,  8646,  7388,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 49363,  8427,  6920,  7561, 13047, 20618,  9277, 13088,    10,\n",
            "             4, 32450,  9278,  9564, 20600, 18101,   401,  9300, 29688,  8326,\n",
            "          6841,   739,  9300, 29688,  8326,  6841,   739, 47729,  8420,  6963,\n",
            "          8420,  8326,  6841,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9324,  7605,  6963,  8066,  9244, 10155,  9118,  8037,  7621,\n",
            "         27460, 40276,  8260,  6824, 17494, 18101, 11063, 13815,  8705, 12230,\n",
            "          9199,  9019,  7055,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9114,  7770,  7198,  8702,  8330,   739,  9299,  7770,\n",
            "          7847, 23024,   739,  9117,  7757, 10964,  7694,  7877, 14330,  6963,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8503,  7586, 15800, 17843, 18101, 13815,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 26383,  7586,  8721,  9164, 20479,\n",
            "         19970,  8139,   739, 20138,  7889,  9201, 50252,  9664,  8213,  7335,\n",
            "           739,  9226, 20725,  8513,  9421,  8467,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9755,  7532,  7847,  8688,   739,  9169,  8187,  7671,  7426,\n",
            "          9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401,  9498,  8168,\n",
            "          9848,  8539, 29580, 20111,  8285,  6919, 20111,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9427,  7487,  8126,  7847,   739,  9132,  8018,  8033,  6949,\n",
            "           739, 26367,  6958,  8092,  7260,  7426,  9695,  9025,  9080,  9242,\n",
            "          9620, 48397,  8711,  8084,   739,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9043,  7889, 26367,  6958,  7219,  7605,  9064,  8519,\n",
            "          7244,   739, 26473,  7258,  7669,  8330,   739, 18890, 16547,  8330,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8165, 40160,   739, 13522,  7258,   739,  9230,  8688,\n",
            "         15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401,  9105,  8721,  8126,  7880,  7219,  7605,   739, 19275,\n",
            "          9583,  8346,   739, 20260,  7652,  7778,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9803,  8236,   739,  9741,  7182,   739,  9107, 43075,  7470,\n",
            "         36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9741, 12830,  6835,  8194,   739,  9741,\n",
            "         12830,  7010,  9885,  8397, 21332,   739,  9741, 12830,  8330,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7182,  8265, 22278,  8066, 40276, 12206,  8704,  7000,\n",
            "          8270, 15800, 17843, 18101,  8146,  7471,    10,     4, 32450,  9278,\n",
            "          9564, 20600, 18101,   401, 17268,  7889,  7970,  7609,  8397,  8330,\n",
            "           739,  9072,  7697,  7902,  6920,  7847,   739, 33953, 15975,  7373,\n",
            "          7654,  8139,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8762,  6958, 13906,   739,  7570,  9695,  9025,  9341,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 31903,  8762,\n",
            "          8529,  7763,  6886,  8528,   739, 36250,  6828,  7692,  8330,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8168,  8006,  7220,  7478, 22092,   739, 13522, 15800,\n",
            "         17843, 18101, 13815,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9098, 23940,  8711,  7561,  7079,  8346,   739,  9299,  7770,  9967,\n",
            "         14808,  8006,  9546,  8420, 26473,   384,   739, 17366, 20479, 11029,\n",
            "          7605,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11576,  7398,   739,  9193,  8669,  6889, 16180,   739,  9427,\n",
            "          7561,  6920,  7561,  8091,   739,  9301,  8431,   739,  9110, 10546,\n",
            "         36258,  9242,  9702,  9182, 11909,  9666,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9072,  6855,  9206,  8467,  9109,  7285,\n",
            "          7409,   739,  9407,  8255,  7237, 21867,   739, 35985,  8521, 19193,\n",
            "          6866,  8608,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  8599,  7397,  8690,   739, 33753,   739,  9267,  7209,\n",
            "           739, 36211,  7372, 13906,   739,  7570,  9695,  9025,  9341,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9121,  7208,  7209,\n",
            "          8330,   739, 33974,  8186,   739,  9267,  7209, 38270,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7182,  8265, 43075,  8066,  9266,  8066,  9118,  7849,\n",
            "          7777,  7393, 24824,  8066, 19216, 15473, 22375,  9695,  9025,  9846,\n",
            "          6969,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9340,  7252,  8168,  8330,   739, 13108,  8006,  7556, 21332,   739,\n",
            "         29523,  8528,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 25542, 10415,   739,  9319,  7374,   739, 22990,  7293,  7865,\n",
            "           739,  9028,  8037,  7621,  8539, 15473, 22375,  9695,  9025,  9846,\n",
            "          6969,   739,    10,     4,  9548, 32450, 20600, 18101,   401, 23763,\n",
            "          8563,  7487,  7521,  7588,  6920,  7847,   739,  9319,  7374,  8528,\n",
            "          7847, 23024,   739,  9319,  7374,  6897,  8528,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7610,  8772, 32599,   739, 10286,  7888,  8610,   739,\n",
            "          9697,  8006, 13906,  9695,  9025,  9080, 13815,  8711,  8244,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9697,  8006, 45825, 21323,\n",
            "           739,  9697,  8006,  7767,  8397,  6969,  7055,  8643,   739,  9697,\n",
            "          8006,  7772, 36568,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7496, 14314,  8066,  9077, 23377, 49417, 22278,  8066,\n",
            "         11737,  6932, 20106, 12151,  8066, 20570,  7198,  8615,  8807, 13047,\n",
            "         20618,  9277, 13088,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9070,  8529,  7556, 21332,   739,  9105,  8721, 10104,   739, 33953,\n",
            "         15975,  7373,  7654,  8139,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 20570, 22278,   739, 40276, 12206,  8704,  7000,  8270,  7426,\n",
            "          9695,  9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,\n",
            "           739,    10,     4, 32450,  9278,  9564, 20600, 18101,   401,  9072,\n",
            "          7697,  7902,  6920,  7847,   739, 33953, 15975,  7373,  7654,  8139,\n",
            "           739, 17268,  7889,  7970,  7609,  8397,  8330,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 12206, 15473,  9695,  9025,  9080, 18101,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 39137,   739,  8616,  7888,   739,\n",
            "         18006,  8168,  8011,  8506, 20111,   739,  9170,  8529,  8658, 21332,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9121,  7208,  7209,   739, 15989,   739,  9091,  9683,  9695,\n",
            "          9025,  9080, 48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401,  9297, 16347,  7767,\n",
            "         28093,  8599,   739,  9121,  7208,  7209,  8330,   739,  9050,  6919,\n",
            "          8330,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9039,  8618,   739, 17366, 35144,   739, 10623,  7533,  8420,\n",
            "           739, 12019,  8427,  6920,  7561,   739, 42660,  7557,  7426,  9695,\n",
            "          9025,  9080,  9242,  9620, 48397,  8711,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401,  9498,  8168,  8326,  6841,   739,\n",
            "          9848,  8539,  8420,  8513,  8429,  7407,   739, 39137,  8420,  8513,\n",
            "          7877,  8593,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8033,  6949,   739, 20007,  7120,  7258,   739,  9474,\n",
            "          7848, 45837, 15473, 22375,  9695,  9025,  9846,  6969,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9121, 20716,  6835,  8765,\n",
            "           739,   739,  8569, 33752,  7605,   739, 31903,  8762,  8529,  7763,\n",
            "          6886,  8528,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11355, 14314,   739, 14264, 26055,  9695,  9025,  9080, 48541,\n",
            "          9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4, 32450,\n",
            "          9278,  9564, 20600, 18101,   401, 26367,  6958,  6963,  8420,  7654,\n",
            "          8139,   739,  9299,  7770,  7847, 23024,   739, 33468,  7373,  7847,\n",
            "         23024,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 42532,  7258,  8694,  8066, 23764,  8066,  9059, 15473,  9695,\n",
            "          9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         39169,  8000,  7111,  8711,  7561,  8615,  8187,   739,  9138, 25827,\n",
            "         43272,  8006,  9586,  7824,  7596,   739,  9382, 21987,  8381,  7605,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11707,  7692,  8171,  8420,  8255,  7426,  9695,  9025,  9080,\n",
            "         48541,  9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 30070, 12548,  8255, 38270,   739,\n",
            "         13267,  8420,  8255,  7771,  7281, 45798,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  7188, 12830,   739, 15275,  7397,   739,  9105,  7557,\n",
            "           739,  9324,  7777,  7393, 24824,   739, 15594,  8344, 13906,  9695,\n",
            "          9025,  9080, 13815,  8711,  8244,    10,     4,  9548, 32450, 20600,\n",
            "         18101,   401, 15355, 13334,  7889,  8092,  7244,   739,   739,  7736,\n",
            "          7735, 35119, 36568,   739,  9105,  7557,  7654,  8139,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 46311,  7673, 20479,  8091,  7426,  9695,  9025,  9080, 48541,\n",
            "          9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4, 32450,\n",
            "          9278,  9564, 20600, 18101,   401, 46311,  7219,  7605,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7967,  7894,  7760,  8066,  9138, 25827,  8711,  7763,\n",
            "         13047, 20618,  9277, 13088,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9098,  7763,  7605,   739, 10286,  7543, 22092, 17366, 20479,\n",
            "          8588,  6963,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7258,  7599,  8168,   739,  9731, 22285,   739,  9300,\n",
            "         18563,  7496, 14314,   739,  9206, 50252, 15473, 22375,  9695,  9025,\n",
            "          9846,  6969,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         47674,  8381,  7605,   739,  9074,  6947,  9397,   739, 14330,  6963,\n",
            "          7219,  7605,  8550,  7244,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 26460,  7172,  7769,  7832,   739, 17366, 20479,  7967,  7894,\n",
            "         13906,  9695,  9025,  9080, 13815,  8711,  8244,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401, 16605, 13503,  7772, 36568,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 47061,  6866,  8599,  7711,   739, 31168,   739,  9203,  7880,\n",
            "          9620,  7445,   739, 35403,  7671,  8529,   739, 35753, 16943, 15473,\n",
            "          9695,  9025,  9080, 18101,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401, 39169,  8000,  7111,  8711,  7561,  8615,  8187,   739, 50900,\n",
            "         23707,  8420,  8255, 25894,  9319,  9581,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9285,  8529,  8066, 14264,  8168,  8066,  9722,  8694,  7497,\n",
            "          8066, 10286,  7543,  8260,  8066,  9091,  6828, 10787, 17494, 18101,\n",
            "         11063, 13815,  8705, 12230,  9199,  9019,  7055,  8084,   739,    10,\n",
            "             4,  9548, 32450, 20600, 18101,   401,  9407,  8513,  7487, 11185,\n",
            "          7478,  8519,   739,  9109,  7375,  8092,  8126,   739, 35119, 36568,\n",
            "          9203, 12438,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 38297, 12206,  8066, 48276, 15528,  8066, 48060,  8263,\n",
            "         15800, 17843, 18101,  9666,  8236,  7801,  8084,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9201,  7824,  7888,  8263,  6963,  7605,\n",
            "           739, 48060,  8263, 39137, 19594,   739, 10252,  8563,  9407,  8255,\n",
            "          9230,  8469,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 13522,  8704,  7000,  8270,  7426,  9695,  9025,  9080, 48541,\n",
            "          9242,  9379, 13815, 15084,  7801,  8084,   739,    10,     4, 32450,\n",
            "          9278,  9564, 20600, 18101,   401, 26473,  7258,  7669,  8330,   739,\n",
            "         41671,  9504,  7532,   739, 35985,  8521, 19193,  6866,  8608,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9719,  7847,  7188,   739, 49727,  7877,  8368,  7208,  8420,\n",
            "          8255,   739,  9174, 11186,  9695,  9025,  9080,  9242,  9620, 48397,\n",
            "          8711,  8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9072,  6855, 20738,  8326,  6841,   739, 44167,  9070,  6947,  7380,\n",
            "          7318,   739, 33974,  7258,  7669,  7904,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 39102,  8626,  7763,  6881,  7760,   739,  9301,   739,  9664,\n",
            "           739, 29000,  8066,  8148,   739,  9421,  8694, 39504, 13906,  9855,\n",
            "         16285,  9666,  8244,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         18006,  8168,  8052,  8272,  8006,  7849, 29161,  8146,   739, 44167,\n",
            "          9118, 21332,   739,  9055,  7669, 43551,  6920,  7847,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7694,   739,  9301,  8507, 15473, 22375,  9695,  9025,\n",
            "          9846,  6969,   739,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "         46311, 21323,  7605,   739,  9297, 37142,  7767,  9297,  7383,  7584,\n",
            "          7771,  7281, 45798,   739,  9407,  8513, 30322,  8608,  7991,  7388,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 35309,  8599,  8158,  8066,  9300, 18563, 46812,  8066,  9118,\n",
            "          7877, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9092,  7847,  7075,  7692,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 42997,  6874,  7470, 36258,  9242,  9702,  9182, 11909,  9666,\n",
            "          8244,    10,     4,  9548, 32450, 20600, 18101,   401,  9193, 24998,\n",
            "          7237,  8214,  7079,  8346,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7492,  7480,  8159,  7258,   739, 21279, 11702, 13906,\n",
            "           739,  7570,  9695,  9025,  9341,   739,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401, 17690,  8456, 13503,   739, 20512,  9285,  6946,\n",
            "          9301,  8507,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 20301,  7543, 15832, 39137,  8456,  8341,  8066, 21807,  8066,\n",
            "          9274,  7413, 15473,  9695,  9025,  9080, 18101,    10,     4,  9548,\n",
            "         32450, 20600, 18101,   401,  9072,  6855,  9206,  8467,  9109,  7285,\n",
            "          7409,   739,  9596,  7172,  8420,  8255, 43160,  7172,   739,  9072,\n",
            "          6855, 50033, 12775,  8092,  7172,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2,  9194,  8420,  8513,  8126, 12031,  9755,  7532,  7847, 20422,\n",
            "         10420,  7889, 13047, 20618,  9277, 13088,    10,     4,  9548, 32450,\n",
            "         20600, 18101,   401,  9498,  8168,  9848,  8539, 29580, 20111,  8285,\n",
            "          6919, 20111,   739, 46048,  7847,  8688,   739,  9848,  8539,  8420,\n",
            "          8513,  8429,  7407,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7285,  6982, 12206,   739,  9673,  8420,  7970,   739,\n",
            "         28545,   739, 33869,   739,  9193, 50252, 15473,  9695,  9025,  9080,\n",
            "         18101,    10,     4,  9548, 32450, 20600, 18101,   401,  9299,  7770,\n",
            "          7847, 23024,   739, 10855,  6969,  7877,   739,  9673,  8420,  7970,\n",
            "          9590,  8098,  7596,  9203, 12438,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 20794,  7892, 16123, 10753,  7182, 10324, 11762,  6951, 31851,\n",
            "          7512,  8696,  8066,  9673,  8474, 12206,  8066,  9468,  8152, 18046,\n",
            "         17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,  8084,\n",
            "           739,    10,     4,  9548, 32450, 20600, 18101,   401, 17366,  8432,\n",
            "          6920,  7847,   739,  9128, 20479,  7771,  7281, 45798,   739,  9118,\n",
            "          7904, 21323,   739,     1,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  7426,  8255, 20186,   739, 33017,   739,  9164,   739,\n",
            "         12789,  8615,  8807,   739, 14302, 15473,  9695,  9025,  9080, 18101,\n",
            "            10,     4,  9548, 32450, 20600, 18101,   401, 33017, 21332,   739,\n",
            "         29645,  8052,  7690, 38270,   739, 14330,  6963,  7219,  7605,  8550,\n",
            "          7244,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "token_ids ====>  tensor([[    2, 15594,  8344,  8066, 46936,  8158,  6824, 17494, 18101, 11063,\n",
            "         13815,  8705, 12230,  9199,  9019,  7055,  8084,   739,    10,     4,\n",
            "          9548, 32450, 20600, 18101,   401, 10301,  6898,  7769,   739, 15594,\n",
            "          8344,  8187,  6893,   739,  9719,  6841,  8168,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 29010, 16180,  8066,  9522,  7889, 35136,  8474,  8066,   739,\n",
            "          8324, 29708, 16309,  6831,  8052,  8272, 12287,  9324,  7605,  8091,\n",
            "          6824, 17494, 18101, 11063, 13815,  8705, 12230,  9199,  9019,  7055,\n",
            "          8084,   739,    10,     4,  9548, 32450, 20600, 18101,   401,  9201,\n",
            "          7824,  7888,  8263,  6963,  7605,   739, 16547,  8263,  7185,  6963,\n",
            "          7605,   739, 27406,  7967, 40115,  7692,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194,  6874,  8159,   739,  9470,  7258,  7669,   739, 48908,\n",
            "          7556,   739,  9323,   739, 49727,  7877,  8368,  7208,  8420,  8255,\n",
            "         15800, 17843, 18101, 13815,    10,     4,  9548, 32450, 20600, 18101,\n",
            "           401,  9259,  7760,  6963,  8420,  8330,   739,  9050,  6938,  8330,\n",
            "           739, 26367,  6958, 33974,  8330,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9194, 19193,  6866,  8608,  7532,  8066, 33753, 15800, 17843,\n",
            "         18101,  8146,  7471,    10,     4,  9548, 32450, 20600, 18101,   401,\n",
            "          9133,  7407,  7865, 10321,  7397,  8690, 21279,  6866,  8608,   739,\n",
            "          9170,  7374,  8615, 12438,   739,  9072,  6855,  9338, 20551,  9942,\n",
            "         13529,  9203, 12438,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "end\n"
          ]
        }
      ],
      "source": [
        "class ChatbotDataset(Dataset):\n",
        "    def __init__(self, chats, max_len=Max_len):\n",
        "        self._data = chats\n",
        "        self.max_len = max_len\n",
        "        self.q_token = Q_TKN\n",
        "        self.a_token = A_TKN\n",
        "        self.sent_token = SENT\n",
        "        self.eos = EOS\n",
        "        self.mask = MASK\n",
        "        self.tokenizer = koGPT2_TOKENIZER\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        turn = self._data.iloc[idx]\n",
        "        q = turn['질문']\n",
        "        q = re.sub(r\"([?.!,])\", r\" \", q)\n",
        "\n",
        "        a = turn['답변']\n",
        "        a = re.sub(r\"([?.!,])\", r\" \", a)\n",
        "\n",
        "        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
        "        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
        "\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
        "\n",
        "        mask = [1] * len(token_ids)\n",
        "\n",
        "        while len(token_ids) < self.max_len:\n",
        "            token_ids += [self.tokenizer.pad_token_id]\n",
        "            mask += [0]\n",
        "\n",
        "        return torch.LongTensor(token_ids), torch.LongTensor(mask)\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "    # Find the maximum length in this batch\n",
        "    max_len = max(len(item[0]) for item in batch)\n",
        "\n",
        "    # Pad data and mask to have the same length\n",
        "    padded_data = [item[0].tolist() + [koGPT2_TOKENIZER.pad_token_id] * (max_len - len(item[0])) for item in batch]\n",
        "    padded_mask = [item[1].tolist() + [0] * (max_len - len(item[1])) for item in batch]\n",
        "\n",
        "    return torch.LongTensor(padded_data), torch.LongTensor(padded_mask)\n",
        "\n",
        "\n",
        "\n",
        "train_set = ChatbotDataset(Ingredient_QA, max_len=Max_len)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=4, num_workers=0, shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "print(\"start\")\n",
        "for batch_idx, samples in enumerate(train_dataloader):\n",
        "    token_ids, mask = samples\n",
        "    print(\"token_ids ====> \", token_ids)\n",
        "    print(\"mask =====> \", mask)\n",
        "print(\"end\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "import time\n",
        "\n",
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "BOS = '</s>'\n",
        "EOS = '</s>'\n",
        "MASK = '<unused0>'\n",
        "SENT = '<unused1>'\n",
        "PAD = '<pad>'\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 학습 데이터 교체할때는 여기 수정\n",
        "train_set = ChatbotDataset(Ingredient_QA, max_len=Max_len)\n",
        "train_dataloader = DataLoader(train_set, batch_size=2, num_workers=0, shuffle=True, collate_fn=collate_batch,)\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "learning_rate = 3e-5\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epoch = 5\n",
        "Sneg = -1e18\n",
        "gradient_accumulation_steps = 4\n",
        "\n",
        "# Loss 기록을 위한 리스트 초기화\n",
        "losses = []\n",
        "\n",
        "checkpoint_interval = 1  # 1로 하면 학습 1에폭당 저장, 2로하면 짝수 에폭당 저장.\n",
        "\n",
        "time1 = time.time()\n",
        "print(\"start\")\n",
        "for ep in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, samples in enumerate(train_dataloader):\n",
        "        token_ids, mask = samples\n",
        "        token_ids, mask = token_ids.to(device), mask.to(device)\n",
        "\n",
        "        outputs = model(token_ids, attention_mask=mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        shift_logits = logits[..., :-1, :].contiguous()\n",
        "        shift_labels = token_ids[..., 1:].contiguous()\n",
        "\n",
        "        loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "        loss = loss.mean() / gradient_accumulation_steps  # Normalize and ensure scalar\n",
        "        total_loss += loss.item()\n",
        "        losses.append(loss.item())  # Loss 기록\n",
        "        loss.backward()\n",
        "\n",
        "        # 실제 학습은 gradient_accumulation_steps 의 수에 따라 (지금은 4) 4의 배수일때마다 역전파를 실행한다.\n",
        "        # 이 말은 4배치 마다 학습을 하겠다는 것이고, 이는 곧 실제 배치 사이즈와 상관없이 4배치 마다 학습을 한다는 것이다.\n",
        "        # 이는 gpu 메모리가 적을때 굉장히 좋은 옵션이 된다. 실제로는 2배치로 돌리지만 사실상 4배치 8배치 16배치... 로 할 수 있다는 뜻이다.\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            print(f\"Step {step+1}, Epoch {ep+1}/{epoch}, Loss: {total_loss}\")\n",
        "            total_loss = 0\n",
        "\n",
        "    # 매 에폭마다 체크포인트 저장\n",
        "    if ep % checkpoint_interval == 0:\n",
        "        # 모델 상태 및 필요한 다른 정보 저장\n",
        "        checkpoint = {\n",
        "            'epoch': ep,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'losses': losses,  # 현재까지의 손실 기록 추가\n",
        "        }\n",
        "        # 파일로 저장\n",
        "        torch.save(checkpoint, f\"checkpoint_model_epoch_{ep}.pth\")\n",
        "\n",
        "print(\"end\")\n",
        "time2 = time.time()"
      ],
      "metadata": {
        "id": "nMrroQ4ecOqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c1e281-082b-409e-f128-7d0178555722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Step 11272, Epoch 4/5, Loss: 0.3388432748615742\n",
            "Step 11276, Epoch 4/5, Loss: 0.42986589670181274\n",
            "Step 11280, Epoch 4/5, Loss: 0.346787229180336\n",
            "Step 11284, Epoch 4/5, Loss: 0.3504398241639137\n",
            "Step 11288, Epoch 4/5, Loss: 0.40401872992515564\n",
            "Step 11292, Epoch 4/5, Loss: 0.3971584439277649\n",
            "Step 11296, Epoch 4/5, Loss: 0.3371809870004654\n",
            "Step 11300, Epoch 4/5, Loss: 0.3126152753829956\n",
            "Step 11304, Epoch 4/5, Loss: 0.3767300248146057\n",
            "Step 11308, Epoch 4/5, Loss: 0.30356787517666817\n",
            "Step 11312, Epoch 4/5, Loss: 0.3024241328239441\n",
            "Step 11316, Epoch 4/5, Loss: 0.3525763116776943\n",
            "Step 11320, Epoch 4/5, Loss: 0.32151979953050613\n",
            "Step 11324, Epoch 4/5, Loss: 0.30277467519044876\n",
            "Step 11328, Epoch 4/5, Loss: 0.399701863527298\n",
            "Step 11332, Epoch 4/5, Loss: 0.40999505668878555\n",
            "Step 11336, Epoch 4/5, Loss: 0.315835177898407\n",
            "Step 11340, Epoch 4/5, Loss: 0.3092334419488907\n",
            "Step 11344, Epoch 4/5, Loss: 0.41402407735586166\n",
            "Step 11348, Epoch 4/5, Loss: 0.34260789304971695\n",
            "Step 11352, Epoch 4/5, Loss: 0.35583746433258057\n",
            "Step 11356, Epoch 4/5, Loss: 0.34086450189352036\n",
            "Step 11360, Epoch 4/5, Loss: 0.31179681047797203\n",
            "Step 11364, Epoch 4/5, Loss: 0.35917291790246964\n",
            "Step 11368, Epoch 4/5, Loss: 0.38815589994192123\n",
            "Step 11372, Epoch 4/5, Loss: 0.4028232470154762\n",
            "Step 11376, Epoch 4/5, Loss: 0.3352137878537178\n",
            "Step 11380, Epoch 4/5, Loss: 0.31800277158617973\n",
            "Step 11384, Epoch 4/5, Loss: 0.30853821709752083\n",
            "Step 11388, Epoch 4/5, Loss: 0.27941954880952835\n",
            "Step 11392, Epoch 4/5, Loss: 0.32013316452503204\n",
            "Step 11396, Epoch 4/5, Loss: 0.40284018963575363\n",
            "Step 11400, Epoch 4/5, Loss: 0.36163952201604843\n",
            "Step 11404, Epoch 4/5, Loss: 0.3935771584510803\n",
            "Step 11408, Epoch 4/5, Loss: 0.2972886189818382\n",
            "Step 11412, Epoch 4/5, Loss: 0.33572207763791084\n",
            "Step 11416, Epoch 4/5, Loss: 0.29031436145305634\n",
            "Step 11420, Epoch 4/5, Loss: 0.2971584126353264\n",
            "Step 11424, Epoch 4/5, Loss: 0.37578701227903366\n",
            "Step 11428, Epoch 4/5, Loss: 0.4114411175251007\n",
            "Step 11432, Epoch 4/5, Loss: 0.31174521893262863\n",
            "Step 11436, Epoch 4/5, Loss: 0.40630654245615005\n",
            "Step 11440, Epoch 4/5, Loss: 0.36273597925901413\n",
            "Step 11444, Epoch 4/5, Loss: 0.39884136617183685\n",
            "Step 11448, Epoch 4/5, Loss: 0.34056636691093445\n",
            "Step 11452, Epoch 4/5, Loss: 0.3200700916349888\n",
            "Step 11456, Epoch 4/5, Loss: 0.3182879872620106\n",
            "Step 11460, Epoch 4/5, Loss: 0.39783013612031937\n",
            "Step 11464, Epoch 4/5, Loss: 0.3262142762541771\n",
            "Step 11468, Epoch 4/5, Loss: 0.30405396968126297\n",
            "Step 11472, Epoch 4/5, Loss: 0.3396768197417259\n",
            "Step 11476, Epoch 4/5, Loss: 0.2579573430120945\n",
            "Step 11480, Epoch 4/5, Loss: 0.3376546613872051\n",
            "Step 11484, Epoch 4/5, Loss: 0.41180889308452606\n",
            "Step 11488, Epoch 4/5, Loss: 0.37772558629512787\n",
            "Step 11492, Epoch 4/5, Loss: 0.30263399332761765\n",
            "Step 11496, Epoch 4/5, Loss: 0.3269846551120281\n",
            "Step 11500, Epoch 4/5, Loss: 0.4042505547404289\n",
            "Step 11504, Epoch 4/5, Loss: 0.4194420501589775\n",
            "Step 11508, Epoch 4/5, Loss: 0.39686065912246704\n",
            "Step 11512, Epoch 4/5, Loss: 0.36221397668123245\n",
            "Step 11516, Epoch 4/5, Loss: 0.2854400798678398\n",
            "Step 11520, Epoch 4/5, Loss: 0.34347421675920486\n",
            "Step 11524, Epoch 4/5, Loss: 0.3699074685573578\n",
            "Step 11528, Epoch 4/5, Loss: 0.24722228571772575\n",
            "Step 11532, Epoch 4/5, Loss: 0.21294071525335312\n",
            "Step 11536, Epoch 4/5, Loss: 0.35150593519210815\n",
            "Step 11540, Epoch 4/5, Loss: 0.3123752698302269\n",
            "Step 11544, Epoch 4/5, Loss: 0.39078760147094727\n",
            "Step 11548, Epoch 4/5, Loss: 0.293585866689682\n",
            "Step 11552, Epoch 4/5, Loss: 0.3360667750239372\n",
            "Step 11556, Epoch 4/5, Loss: 0.3267957717180252\n",
            "Step 11560, Epoch 4/5, Loss: 0.2627355344593525\n",
            "Step 11564, Epoch 4/5, Loss: 0.2957093194127083\n",
            "Step 11568, Epoch 4/5, Loss: 0.3547680303454399\n",
            "Step 11572, Epoch 4/5, Loss: 0.3210715502500534\n",
            "Step 11576, Epoch 4/5, Loss: 0.37191031873226166\n",
            "Step 11580, Epoch 4/5, Loss: 0.4232689142227173\n",
            "Step 11584, Epoch 4/5, Loss: 0.3581223040819168\n",
            "Step 11588, Epoch 4/5, Loss: 0.2809765636920929\n",
            "Step 11592, Epoch 4/5, Loss: 0.29895593971014023\n",
            "Step 11596, Epoch 4/5, Loss: 0.23143506050109863\n",
            "Step 11600, Epoch 4/5, Loss: 0.31490451842546463\n",
            "Step 11604, Epoch 4/5, Loss: 0.33614055812358856\n",
            "Step 11608, Epoch 4/5, Loss: 0.3729885146021843\n",
            "Step 11612, Epoch 4/5, Loss: 0.33425936102867126\n",
            "Step 11616, Epoch 4/5, Loss: 0.4527719244360924\n",
            "Step 11620, Epoch 4/5, Loss: 0.35494523867964745\n",
            "Step 11624, Epoch 4/5, Loss: 0.35952332615852356\n",
            "Step 11628, Epoch 4/5, Loss: 0.2675478719174862\n",
            "Step 11632, Epoch 4/5, Loss: 0.3679293543100357\n",
            "Step 11636, Epoch 4/5, Loss: 0.3202591799199581\n",
            "Step 11640, Epoch 4/5, Loss: 0.4077479690313339\n",
            "Step 11644, Epoch 4/5, Loss: 0.28783517703413963\n",
            "Step 11648, Epoch 4/5, Loss: 0.38618575781583786\n",
            "Step 11652, Epoch 4/5, Loss: 0.3192787356674671\n",
            "Step 11656, Epoch 4/5, Loss: 0.31607867777347565\n",
            "Step 11660, Epoch 4/5, Loss: 0.3034656420350075\n",
            "Step 11664, Epoch 4/5, Loss: 0.3146943934261799\n",
            "Step 11668, Epoch 4/5, Loss: 0.29188478738069534\n",
            "Step 11672, Epoch 4/5, Loss: 0.40277957171201706\n",
            "Step 11676, Epoch 4/5, Loss: 0.3183952122926712\n",
            "Step 11680, Epoch 4/5, Loss: 0.3796226233243942\n",
            "Step 11684, Epoch 4/5, Loss: 0.37430572137236595\n",
            "Step 11688, Epoch 4/5, Loss: 0.3804938718676567\n",
            "Step 11692, Epoch 4/5, Loss: 0.36392856761813164\n",
            "Step 11696, Epoch 4/5, Loss: 0.3728397935628891\n",
            "Step 11700, Epoch 4/5, Loss: 0.34384363889694214\n",
            "Step 11704, Epoch 4/5, Loss: 0.34694816917181015\n",
            "Step 11708, Epoch 4/5, Loss: 0.38257723301649094\n",
            "Step 11712, Epoch 4/5, Loss: 0.34542880952358246\n",
            "Step 11716, Epoch 4/5, Loss: 0.31649602204561234\n",
            "Step 11720, Epoch 4/5, Loss: 0.3463716059923172\n",
            "Step 11724, Epoch 4/5, Loss: 0.3052258789539337\n",
            "Step 11728, Epoch 4/5, Loss: 0.3227379620075226\n",
            "Step 11732, Epoch 4/5, Loss: 0.33746231347322464\n",
            "Step 11736, Epoch 4/5, Loss: 0.3350607454776764\n",
            "Step 11740, Epoch 4/5, Loss: 0.3562634736299515\n",
            "Step 11744, Epoch 4/5, Loss: 0.30016956478357315\n",
            "Step 11748, Epoch 4/5, Loss: 0.256530586630106\n",
            "Step 11752, Epoch 4/5, Loss: 0.32525745779275894\n",
            "Step 11756, Epoch 4/5, Loss: 0.416315458714962\n",
            "Step 11760, Epoch 4/5, Loss: 0.338809359818697\n",
            "Step 11764, Epoch 4/5, Loss: 0.27206970378756523\n",
            "Step 11768, Epoch 4/5, Loss: 0.3391178250312805\n",
            "Step 11772, Epoch 4/5, Loss: 0.3632395267486572\n",
            "Step 11776, Epoch 4/5, Loss: 0.3445424623787403\n",
            "Step 11780, Epoch 4/5, Loss: 0.3687683641910553\n",
            "Step 11784, Epoch 4/5, Loss: 0.33950477465987206\n",
            "Step 11788, Epoch 4/5, Loss: 0.3611927255988121\n",
            "Step 11792, Epoch 4/5, Loss: 0.3094682842493057\n",
            "Step 11796, Epoch 4/5, Loss: 0.33299772813916206\n",
            "Step 11800, Epoch 4/5, Loss: 0.36974581331014633\n",
            "Step 11804, Epoch 4/5, Loss: 0.30555279180407524\n",
            "Step 11808, Epoch 4/5, Loss: 0.39714735746383667\n",
            "Step 11812, Epoch 4/5, Loss: 0.3064194917678833\n",
            "Step 11816, Epoch 4/5, Loss: 0.34563566744327545\n",
            "Step 11820, Epoch 4/5, Loss: 0.383941825479269\n",
            "Step 11824, Epoch 4/5, Loss: 0.2839980274438858\n",
            "Step 11828, Epoch 4/5, Loss: 0.3589090630412102\n",
            "Step 11832, Epoch 4/5, Loss: 0.34946534782648087\n",
            "Step 11836, Epoch 4/5, Loss: 0.34511304646730423\n",
            "Step 11840, Epoch 4/5, Loss: 0.3839609995484352\n",
            "Step 11844, Epoch 4/5, Loss: 0.33787618950009346\n",
            "Step 11848, Epoch 4/5, Loss: 0.37762946635484695\n",
            "Step 11852, Epoch 4/5, Loss: 0.36427029222249985\n",
            "Step 11856, Epoch 4/5, Loss: 0.34500712901353836\n",
            "Step 11860, Epoch 4/5, Loss: 0.3337540440261364\n",
            "Step 11864, Epoch 4/5, Loss: 0.30789533257484436\n",
            "Step 11868, Epoch 4/5, Loss: 0.32721078023314476\n",
            "Step 11872, Epoch 4/5, Loss: 0.2854843847453594\n",
            "Step 11876, Epoch 4/5, Loss: 0.3027932122349739\n",
            "Step 11880, Epoch 4/5, Loss: 0.3090815432369709\n",
            "Step 11884, Epoch 4/5, Loss: 0.3471481129527092\n",
            "Step 11888, Epoch 4/5, Loss: 0.36191925033926964\n",
            "Step 11892, Epoch 4/5, Loss: 0.3373996689915657\n",
            "Step 11896, Epoch 4/5, Loss: 0.41270871460437775\n",
            "Step 11900, Epoch 4/5, Loss: 0.3351644426584244\n",
            "Step 11904, Epoch 4/5, Loss: 0.2882690019905567\n",
            "Step 11908, Epoch 4/5, Loss: 0.24460315331816673\n",
            "Step 11912, Epoch 4/5, Loss: 0.28467607125639915\n",
            "Step 11916, Epoch 4/5, Loss: 0.36194754764437675\n",
            "Step 11920, Epoch 4/5, Loss: 0.409458689391613\n",
            "Step 11924, Epoch 4/5, Loss: 0.382266640663147\n",
            "Step 11928, Epoch 4/5, Loss: 0.34965748339891434\n",
            "Step 11932, Epoch 4/5, Loss: 0.3033425100147724\n",
            "Step 11936, Epoch 4/5, Loss: 0.3556477800011635\n",
            "Step 11940, Epoch 4/5, Loss: 0.2817254662513733\n",
            "Step 11944, Epoch 4/5, Loss: 0.3542388267815113\n",
            "Step 11948, Epoch 4/5, Loss: 0.29888905212283134\n",
            "Step 11952, Epoch 4/5, Loss: 0.3990395665168762\n",
            "Step 11956, Epoch 4/5, Loss: 0.3770914450287819\n",
            "Step 11960, Epoch 4/5, Loss: 0.3744547478854656\n",
            "Step 11964, Epoch 4/5, Loss: 0.45547662675380707\n",
            "Step 11968, Epoch 4/5, Loss: 0.4282975420355797\n",
            "Step 11972, Epoch 4/5, Loss: 0.44000420719385147\n",
            "Step 11976, Epoch 4/5, Loss: 0.30612812936306\n",
            "Step 11980, Epoch 4/5, Loss: 0.3457850143313408\n",
            "Step 11984, Epoch 4/5, Loss: 0.37027354910969734\n",
            "Step 11988, Epoch 4/5, Loss: 0.3009638488292694\n",
            "Step 11992, Epoch 4/5, Loss: 0.40240585803985596\n",
            "Step 11996, Epoch 4/5, Loss: 0.31156766414642334\n",
            "Step 12000, Epoch 4/5, Loss: 0.3866353929042816\n",
            "Step 12004, Epoch 4/5, Loss: 0.3328207656741142\n",
            "Step 12008, Epoch 4/5, Loss: 0.3223082944750786\n",
            "Step 12012, Epoch 4/5, Loss: 0.3739962801337242\n",
            "Step 12016, Epoch 4/5, Loss: 0.31453175097703934\n",
            "Step 12020, Epoch 4/5, Loss: 0.3197302371263504\n",
            "Step 12024, Epoch 4/5, Loss: 0.30640917271375656\n",
            "Step 12028, Epoch 4/5, Loss: 0.3418441638350487\n",
            "Step 12032, Epoch 4/5, Loss: 0.3674270659685135\n",
            "Step 12036, Epoch 4/5, Loss: 0.3170742094516754\n",
            "Step 12040, Epoch 4/5, Loss: 0.3025573194026947\n",
            "Step 12044, Epoch 4/5, Loss: 0.33312882483005524\n",
            "Step 12048, Epoch 4/5, Loss: 0.33102308958768845\n",
            "Step 12052, Epoch 4/5, Loss: 0.32174818217754364\n",
            "Step 12056, Epoch 4/5, Loss: 0.3229197487235069\n",
            "Step 12060, Epoch 4/5, Loss: 0.3156959004700184\n",
            "Step 12064, Epoch 4/5, Loss: 0.40263407677412033\n",
            "Step 12068, Epoch 4/5, Loss: 0.37203290313482285\n",
            "Step 12072, Epoch 4/5, Loss: 0.34251242503523827\n",
            "Step 12076, Epoch 4/5, Loss: 0.33711929619312286\n",
            "Step 12080, Epoch 4/5, Loss: 0.34840741008520126\n",
            "Step 12084, Epoch 4/5, Loss: 0.2791638784110546\n",
            "Step 12088, Epoch 4/5, Loss: 0.32145944982767105\n",
            "Step 12092, Epoch 4/5, Loss: 0.2949039302766323\n",
            "Step 12096, Epoch 4/5, Loss: 0.2877560667693615\n",
            "Step 12100, Epoch 4/5, Loss: 0.3476510979235172\n",
            "Step 12104, Epoch 4/5, Loss: 0.4076332449913025\n",
            "Step 12108, Epoch 4/5, Loss: 0.25681862235069275\n",
            "Step 12112, Epoch 4/5, Loss: 0.31473127752542496\n",
            "Step 12116, Epoch 4/5, Loss: 0.3676445335149765\n",
            "Step 12120, Epoch 4/5, Loss: 0.33220387250185013\n",
            "Step 12124, Epoch 4/5, Loss: 0.2564655914902687\n",
            "Step 12128, Epoch 4/5, Loss: 0.22724908962845802\n",
            "Step 12132, Epoch 4/5, Loss: 0.3013327419757843\n",
            "Step 12136, Epoch 4/5, Loss: 0.36174558848142624\n",
            "Step 12140, Epoch 4/5, Loss: 0.42760448157787323\n",
            "Step 12144, Epoch 4/5, Loss: 0.37150269374251366\n",
            "Step 12148, Epoch 4/5, Loss: 0.43512820452451706\n",
            "Step 12152, Epoch 4/5, Loss: 0.3738110773265362\n",
            "Step 12156, Epoch 4/5, Loss: 0.30918336659669876\n",
            "Step 12160, Epoch 4/5, Loss: 0.3612286075949669\n",
            "Step 12164, Epoch 4/5, Loss: 0.3379492685198784\n",
            "Step 12168, Epoch 4/5, Loss: 0.3071216829121113\n",
            "Step 12172, Epoch 4/5, Loss: 0.35360700637102127\n",
            "Step 12176, Epoch 4/5, Loss: 0.30091091245412827\n",
            "Step 12180, Epoch 4/5, Loss: 0.3286607787013054\n",
            "Step 12184, Epoch 4/5, Loss: 0.3100416660308838\n",
            "Step 12188, Epoch 4/5, Loss: 0.30968116223812103\n",
            "Step 12192, Epoch 4/5, Loss: 0.3874240145087242\n",
            "Step 12196, Epoch 4/5, Loss: 0.3139130398631096\n",
            "Step 12200, Epoch 4/5, Loss: 0.3232160620391369\n",
            "Step 12204, Epoch 4/5, Loss: 0.343171201646328\n",
            "Step 12208, Epoch 4/5, Loss: 0.3252672180533409\n",
            "Step 12212, Epoch 4/5, Loss: 0.3611939549446106\n",
            "Step 12216, Epoch 4/5, Loss: 0.3669048175215721\n",
            "Step 12220, Epoch 4/5, Loss: 0.36440011858940125\n",
            "Step 12224, Epoch 4/5, Loss: 0.3645687662065029\n",
            "Step 12228, Epoch 4/5, Loss: 0.31227946653962135\n",
            "Step 12232, Epoch 4/5, Loss: 0.4070611596107483\n",
            "Step 12236, Epoch 4/5, Loss: 0.3584020882844925\n",
            "Step 12240, Epoch 4/5, Loss: 0.3825591579079628\n",
            "Step 12244, Epoch 4/5, Loss: 0.2386949397623539\n",
            "Step 12248, Epoch 4/5, Loss: 0.26348211988806725\n",
            "Step 12252, Epoch 4/5, Loss: 0.35726409405469894\n",
            "Step 12256, Epoch 4/5, Loss: 0.29546061903238297\n",
            "Step 12260, Epoch 4/5, Loss: 0.3340887390077114\n",
            "Step 12264, Epoch 4/5, Loss: 0.3105883076786995\n",
            "Step 12268, Epoch 4/5, Loss: 0.32379933819174767\n",
            "Step 12272, Epoch 4/5, Loss: 0.2740234024822712\n",
            "Step 12276, Epoch 4/5, Loss: 0.39393144845962524\n",
            "Step 12280, Epoch 4/5, Loss: 0.3426726460456848\n",
            "Step 12284, Epoch 4/5, Loss: 0.3008900582790375\n",
            "Step 12288, Epoch 4/5, Loss: 0.3783242329955101\n",
            "Step 12292, Epoch 4/5, Loss: 0.39532696828246117\n",
            "Step 12296, Epoch 4/5, Loss: 0.3315265364944935\n",
            "Step 12300, Epoch 4/5, Loss: 0.2670876234769821\n",
            "Step 12304, Epoch 4/5, Loss: 0.2822521813213825\n",
            "Step 12308, Epoch 4/5, Loss: 0.3318204805254936\n",
            "Step 12312, Epoch 4/5, Loss: 0.27769313752651215\n",
            "Step 12316, Epoch 4/5, Loss: 0.2955501154065132\n",
            "Step 12320, Epoch 4/5, Loss: 0.2916684225201607\n",
            "Step 12324, Epoch 4/5, Loss: 0.35062381252646446\n",
            "Step 12328, Epoch 4/5, Loss: 0.31829265877604485\n",
            "Step 12332, Epoch 4/5, Loss: 0.3453560881316662\n",
            "Step 12336, Epoch 4/5, Loss: 0.3246840313076973\n",
            "Step 12340, Epoch 4/5, Loss: 0.4658101126551628\n",
            "Step 12344, Epoch 4/5, Loss: 0.3987491726875305\n",
            "Step 12348, Epoch 4/5, Loss: 0.29613879695534706\n",
            "Step 12352, Epoch 4/5, Loss: 0.20177020132541656\n",
            "Step 12356, Epoch 4/5, Loss: 0.435405895113945\n",
            "Step 12360, Epoch 4/5, Loss: 0.3846333250403404\n",
            "Step 12364, Epoch 4/5, Loss: 0.3605954945087433\n",
            "Step 12368, Epoch 4/5, Loss: 0.3957251124083996\n",
            "Step 12372, Epoch 4/5, Loss: 0.2909243404865265\n",
            "Step 12376, Epoch 4/5, Loss: 0.3351527899503708\n",
            "Step 12380, Epoch 4/5, Loss: 0.3100684620440006\n",
            "Step 12384, Epoch 4/5, Loss: 0.2785732373595238\n",
            "Step 12388, Epoch 4/5, Loss: 0.333680123090744\n",
            "Step 12392, Epoch 4/5, Loss: 0.24509772285819054\n",
            "Step 12396, Epoch 4/5, Loss: 0.2993747368454933\n",
            "Step 12400, Epoch 4/5, Loss: 0.2981547936797142\n",
            "Step 12404, Epoch 4/5, Loss: 0.42333704233169556\n",
            "Step 12408, Epoch 4/5, Loss: 0.30704648420214653\n",
            "Step 12412, Epoch 4/5, Loss: 0.3222309686243534\n",
            "Step 12416, Epoch 4/5, Loss: 0.40724069625139236\n",
            "Step 12420, Epoch 4/5, Loss: 0.3102274090051651\n",
            "Step 12424, Epoch 4/5, Loss: 0.3008589930832386\n",
            "Step 12428, Epoch 4/5, Loss: 0.30455632507801056\n",
            "Step 12432, Epoch 4/5, Loss: 0.3169216960668564\n",
            "Step 12436, Epoch 4/5, Loss: 0.3817272484302521\n",
            "Step 12440, Epoch 4/5, Loss: 0.3487783931195736\n",
            "Step 12444, Epoch 4/5, Loss: 0.45686380565166473\n",
            "Step 12448, Epoch 4/5, Loss: 0.2655786871910095\n",
            "Step 12452, Epoch 4/5, Loss: 0.2969031594693661\n",
            "Step 12456, Epoch 4/5, Loss: 0.39621222764253616\n",
            "Step 12460, Epoch 4/5, Loss: 0.38459647446870804\n",
            "Step 12464, Epoch 4/5, Loss: 0.3014017157256603\n",
            "Step 12468, Epoch 4/5, Loss: 0.33258505910634995\n",
            "Step 12472, Epoch 4/5, Loss: 0.42059287428855896\n",
            "Step 12476, Epoch 4/5, Loss: 0.29298537969589233\n",
            "Step 12480, Epoch 4/5, Loss: 0.2854575552046299\n",
            "Step 12484, Epoch 4/5, Loss: 0.2978946901857853\n",
            "Step 12488, Epoch 4/5, Loss: 0.3225319981575012\n",
            "Step 12492, Epoch 4/5, Loss: 0.34425415843725204\n",
            "Step 12496, Epoch 4/5, Loss: 0.3156283535063267\n",
            "Step 12500, Epoch 4/5, Loss: 0.4091217890381813\n",
            "Step 12504, Epoch 4/5, Loss: 0.361225962638855\n",
            "Step 12508, Epoch 4/5, Loss: 0.28549306094646454\n",
            "Step 12512, Epoch 4/5, Loss: 0.3694048672914505\n",
            "Step 12516, Epoch 4/5, Loss: 0.27384374290704727\n",
            "Step 12520, Epoch 4/5, Loss: 0.3729286640882492\n",
            "Step 12524, Epoch 4/5, Loss: 0.32014815136790276\n",
            "Step 12528, Epoch 4/5, Loss: 0.3122044652700424\n",
            "Step 12532, Epoch 4/5, Loss: 0.4145406186580658\n",
            "Step 12536, Epoch 4/5, Loss: 0.3153325729072094\n",
            "Step 12540, Epoch 4/5, Loss: 0.35043517872691154\n",
            "Step 12544, Epoch 4/5, Loss: 0.35744014382362366\n",
            "Step 12548, Epoch 4/5, Loss: 0.3054286390542984\n",
            "Step 12552, Epoch 4/5, Loss: 0.3144286908209324\n",
            "Step 12556, Epoch 4/5, Loss: 0.4231245815753937\n",
            "Step 12560, Epoch 4/5, Loss: 0.31364844366908073\n",
            "Step 12564, Epoch 4/5, Loss: 0.34961704164743423\n",
            "Step 12568, Epoch 4/5, Loss: 0.3902842178940773\n",
            "Step 12572, Epoch 4/5, Loss: 0.2864193841814995\n",
            "Step 12576, Epoch 4/5, Loss: 0.3634389489889145\n",
            "Step 12580, Epoch 4/5, Loss: 0.3688812665641308\n",
            "Step 12584, Epoch 4/5, Loss: 0.2844398133456707\n",
            "Step 12588, Epoch 4/5, Loss: 0.28539253771305084\n",
            "Step 12592, Epoch 4/5, Loss: 0.3280835635960102\n",
            "Step 12596, Epoch 4/5, Loss: 0.31391751766204834\n",
            "Step 12600, Epoch 4/5, Loss: 0.382832907140255\n",
            "Step 12604, Epoch 4/5, Loss: 0.41873256117105484\n",
            "Step 12608, Epoch 4/5, Loss: 0.2782267928123474\n",
            "Step 12612, Epoch 4/5, Loss: 0.3043559081852436\n",
            "Step 12616, Epoch 4/5, Loss: 0.2977668270468712\n",
            "Step 12620, Epoch 4/5, Loss: 0.28220177814364433\n",
            "Step 12624, Epoch 4/5, Loss: 0.3533724993467331\n",
            "Step 12628, Epoch 4/5, Loss: 0.34704312309622765\n",
            "Step 12632, Epoch 4/5, Loss: 0.28650543838739395\n",
            "Step 12636, Epoch 4/5, Loss: 0.3303375393152237\n",
            "Step 12640, Epoch 4/5, Loss: 0.34329845011234283\n",
            "Step 12644, Epoch 4/5, Loss: 0.30722661316394806\n",
            "Step 12648, Epoch 4/5, Loss: 0.28986145183444023\n",
            "Step 12652, Epoch 4/5, Loss: 0.37003592401742935\n",
            "Step 12656, Epoch 4/5, Loss: 0.3101038746535778\n",
            "Step 12660, Epoch 4/5, Loss: 0.28431937098503113\n",
            "Step 12664, Epoch 4/5, Loss: 0.3731013871729374\n",
            "Step 12668, Epoch 4/5, Loss: 0.3778596371412277\n",
            "Step 12672, Epoch 4/5, Loss: 0.3386761508882046\n",
            "Step 12676, Epoch 4/5, Loss: 0.3701857179403305\n",
            "Step 12680, Epoch 4/5, Loss: 0.3192492127418518\n",
            "Step 12684, Epoch 4/5, Loss: 0.2940963990986347\n",
            "Step 12688, Epoch 4/5, Loss: 0.40459972620010376\n",
            "Step 12692, Epoch 4/5, Loss: 0.2962949424982071\n",
            "Step 12696, Epoch 4/5, Loss: 0.37196021527051926\n",
            "Step 12700, Epoch 4/5, Loss: 0.3454018458724022\n",
            "Step 12704, Epoch 4/5, Loss: 0.31209204345941544\n",
            "Step 12708, Epoch 4/5, Loss: 0.4267658516764641\n",
            "Step 12712, Epoch 4/5, Loss: 0.4322458356618881\n",
            "Step 12716, Epoch 4/5, Loss: 0.38721659034490585\n",
            "Step 12720, Epoch 4/5, Loss: 0.3488846458494663\n",
            "Step 12724, Epoch 4/5, Loss: 0.3089843578636646\n",
            "Step 12728, Epoch 4/5, Loss: 0.29376889392733574\n",
            "Step 12732, Epoch 4/5, Loss: 0.3595389910042286\n",
            "Step 12736, Epoch 4/5, Loss: 0.44848065078258514\n",
            "Step 12740, Epoch 4/5, Loss: 0.3791109770536423\n",
            "Step 12744, Epoch 4/5, Loss: 0.3593679666519165\n",
            "Step 12748, Epoch 4/5, Loss: 0.3895571753382683\n",
            "Step 12752, Epoch 4/5, Loss: 0.2939925715327263\n",
            "Step 12756, Epoch 4/5, Loss: 0.31819090619683266\n",
            "Step 12760, Epoch 4/5, Loss: 0.35397911071777344\n",
            "Step 12764, Epoch 4/5, Loss: 0.39280373603105545\n",
            "Step 12768, Epoch 4/5, Loss: 0.275980930775404\n",
            "Step 12772, Epoch 4/5, Loss: 0.37888672202825546\n",
            "Step 12776, Epoch 4/5, Loss: 0.34865421056747437\n",
            "Step 12780, Epoch 4/5, Loss: 0.41759341210126877\n",
            "Step 12784, Epoch 4/5, Loss: 0.28038815408945084\n",
            "Step 12788, Epoch 4/5, Loss: 0.43722303211688995\n",
            "Step 12792, Epoch 4/5, Loss: 0.37312445044517517\n",
            "Step 12796, Epoch 4/5, Loss: 0.28290771692991257\n",
            "Step 12800, Epoch 4/5, Loss: 0.3407980501651764\n",
            "Step 12804, Epoch 4/5, Loss: 0.36656542867422104\n",
            "Step 12808, Epoch 4/5, Loss: 0.3644034042954445\n",
            "Step 12812, Epoch 4/5, Loss: 0.36658357456326485\n",
            "Step 12816, Epoch 4/5, Loss: 0.2733866460621357\n",
            "Step 12820, Epoch 4/5, Loss: 0.32738548144698143\n",
            "Step 12824, Epoch 4/5, Loss: 0.35005732253193855\n",
            "Step 12828, Epoch 4/5, Loss: 0.32174209505319595\n",
            "Step 12832, Epoch 4/5, Loss: 0.2703944705426693\n",
            "Step 12836, Epoch 4/5, Loss: 0.3728504553437233\n",
            "Step 12840, Epoch 4/5, Loss: 0.3324456587433815\n",
            "Step 12844, Epoch 4/5, Loss: 0.2863617390394211\n",
            "Step 12848, Epoch 4/5, Loss: 0.34637754410505295\n",
            "Step 12852, Epoch 4/5, Loss: 0.32433389872312546\n",
            "Step 12856, Epoch 4/5, Loss: 0.29944711923599243\n",
            "Step 12860, Epoch 4/5, Loss: 0.38563961535692215\n",
            "Step 12864, Epoch 4/5, Loss: 0.365764781832695\n",
            "Step 12868, Epoch 4/5, Loss: 0.33296041935682297\n",
            "Step 12872, Epoch 4/5, Loss: 0.3990523889660835\n",
            "Step 12876, Epoch 4/5, Loss: 0.35567037016153336\n",
            "Step 12880, Epoch 4/5, Loss: 0.33726073428988457\n",
            "Step 12884, Epoch 4/5, Loss: 0.386164054274559\n",
            "Step 12888, Epoch 4/5, Loss: 0.4545680359005928\n",
            "Step 12892, Epoch 4/5, Loss: 0.3413076028227806\n",
            "Step 12896, Epoch 4/5, Loss: 0.3178708329796791\n",
            "Step 12900, Epoch 4/5, Loss: 0.27653130888938904\n",
            "Step 12904, Epoch 4/5, Loss: 0.34017838910222054\n",
            "Step 12908, Epoch 4/5, Loss: 0.31375623121857643\n",
            "Step 12912, Epoch 4/5, Loss: 0.3890768364071846\n",
            "Step 12916, Epoch 4/5, Loss: 0.31233635544776917\n",
            "Step 12920, Epoch 4/5, Loss: 0.4053611531853676\n",
            "Step 12924, Epoch 4/5, Loss: 0.32964668795466423\n",
            "Step 12928, Epoch 4/5, Loss: 0.30205589160323143\n",
            "Step 12932, Epoch 4/5, Loss: 0.32886160910129547\n",
            "Step 12936, Epoch 4/5, Loss: 0.31493210792541504\n",
            "Step 12940, Epoch 4/5, Loss: 0.3708278387784958\n",
            "Step 12944, Epoch 4/5, Loss: 0.3082321099936962\n",
            "Step 12948, Epoch 4/5, Loss: 0.3397061824798584\n",
            "Step 12952, Epoch 4/5, Loss: 0.3385680243372917\n",
            "Step 12956, Epoch 4/5, Loss: 0.378792405128479\n",
            "Step 12960, Epoch 4/5, Loss: 0.28244154155254364\n",
            "Step 12964, Epoch 4/5, Loss: 0.3223978355526924\n",
            "Step 12968, Epoch 4/5, Loss: 0.2665652073919773\n",
            "Step 12972, Epoch 4/5, Loss: 0.3439090698957443\n",
            "Step 12976, Epoch 4/5, Loss: 0.29170506820082664\n",
            "Step 12980, Epoch 4/5, Loss: 0.3044072091579437\n",
            "Step 12984, Epoch 4/5, Loss: 0.3140177056193352\n",
            "Step 12988, Epoch 4/5, Loss: 0.36956245452165604\n",
            "Step 12992, Epoch 4/5, Loss: 0.3232945576310158\n",
            "Step 12996, Epoch 4/5, Loss: 0.3859503045678139\n",
            "Step 13000, Epoch 4/5, Loss: 0.3176267631351948\n",
            "Step 13004, Epoch 4/5, Loss: 0.34067127108573914\n",
            "Step 13008, Epoch 4/5, Loss: 0.3426436744630337\n",
            "Step 13012, Epoch 4/5, Loss: 0.4060801565647125\n",
            "Step 13016, Epoch 4/5, Loss: 0.3375096172094345\n",
            "Step 13020, Epoch 4/5, Loss: 0.3500281497836113\n",
            "Step 13024, Epoch 4/5, Loss: 0.2766713611781597\n",
            "Step 13028, Epoch 4/5, Loss: 0.3249000124633312\n",
            "Step 13032, Epoch 4/5, Loss: 0.42134271562099457\n",
            "Step 13036, Epoch 4/5, Loss: 0.3042011894285679\n",
            "Step 13040, Epoch 4/5, Loss: 0.2720213308930397\n",
            "Step 13044, Epoch 4/5, Loss: 0.39604752510786057\n",
            "Step 13048, Epoch 4/5, Loss: 0.2664829380810261\n",
            "Step 13052, Epoch 4/5, Loss: 0.3861939609050751\n",
            "Step 13056, Epoch 4/5, Loss: 0.3650926351547241\n",
            "Step 13060, Epoch 4/5, Loss: 0.3874690793454647\n",
            "Step 13064, Epoch 4/5, Loss: 0.27011802792549133\n",
            "Step 13068, Epoch 4/5, Loss: 0.3693937063217163\n",
            "Step 13072, Epoch 4/5, Loss: 0.28599588200449944\n",
            "Step 13076, Epoch 4/5, Loss: 0.36746425926685333\n",
            "Step 13080, Epoch 4/5, Loss: 0.29341690987348557\n",
            "Step 13084, Epoch 4/5, Loss: 0.303971279412508\n",
            "Step 13088, Epoch 4/5, Loss: 0.39180881530046463\n",
            "Step 13092, Epoch 4/5, Loss: 0.3988778442144394\n",
            "Step 13096, Epoch 4/5, Loss: 0.30158884078264236\n",
            "Step 13100, Epoch 4/5, Loss: 0.346005205065012\n",
            "Step 13104, Epoch 4/5, Loss: 0.3272443003952503\n",
            "Step 13108, Epoch 4/5, Loss: 0.37380699068307877\n",
            "Step 13112, Epoch 4/5, Loss: 0.42698250710964203\n",
            "Step 13116, Epoch 4/5, Loss: 0.4768175184726715\n",
            "Step 13120, Epoch 4/5, Loss: 0.3559272736310959\n",
            "Step 13124, Epoch 4/5, Loss: 0.4184295982122421\n",
            "Step 13128, Epoch 4/5, Loss: 0.2917392663657665\n",
            "Step 13132, Epoch 4/5, Loss: 0.3083244003355503\n",
            "Step 13136, Epoch 4/5, Loss: 0.3671496585011482\n",
            "Step 13140, Epoch 4/5, Loss: 0.23983196541666985\n",
            "Step 13144, Epoch 4/5, Loss: 0.33911219611763954\n",
            "Step 13148, Epoch 4/5, Loss: 0.37574227899312973\n",
            "Step 13152, Epoch 4/5, Loss: 0.30047887936234474\n",
            "Step 13156, Epoch 4/5, Loss: 0.3592739552259445\n",
            "Step 13160, Epoch 4/5, Loss: 0.31298403814435005\n",
            "Step 13164, Epoch 4/5, Loss: 0.33945413678884506\n",
            "Step 13168, Epoch 4/5, Loss: 0.42869142442941666\n",
            "Step 13172, Epoch 4/5, Loss: 0.4064752459526062\n",
            "Step 13176, Epoch 4/5, Loss: 0.25276805832982063\n",
            "Step 13180, Epoch 4/5, Loss: 0.41455234214663506\n",
            "Step 13184, Epoch 4/5, Loss: 0.2686058320105076\n",
            "Step 13188, Epoch 4/5, Loss: 0.25501175224781036\n",
            "Step 13192, Epoch 4/5, Loss: 0.33136409148573875\n",
            "Step 13196, Epoch 4/5, Loss: 0.3491695784032345\n",
            "Step 13200, Epoch 4/5, Loss: 0.3355780765414238\n",
            "Step 13204, Epoch 4/5, Loss: 0.37919872999191284\n",
            "Step 13208, Epoch 4/5, Loss: 0.3078424781560898\n",
            "Step 13212, Epoch 4/5, Loss: 0.3327399156987667\n",
            "Step 13216, Epoch 4/5, Loss: 0.33953557908535004\n",
            "Step 13220, Epoch 4/5, Loss: 0.2751614414155483\n",
            "Step 13224, Epoch 4/5, Loss: 0.37021367251873016\n",
            "Step 13228, Epoch 4/5, Loss: 0.2772289514541626\n",
            "Step 13232, Epoch 4/5, Loss: 0.39000339061021805\n",
            "Step 13236, Epoch 4/5, Loss: 0.35304906219244003\n",
            "Step 13240, Epoch 4/5, Loss: 0.34145311266183853\n",
            "Step 13244, Epoch 4/5, Loss: 0.4252072274684906\n",
            "Step 13248, Epoch 4/5, Loss: 0.34737101197242737\n",
            "Step 13252, Epoch 4/5, Loss: 0.38964302092790604\n",
            "Step 13256, Epoch 4/5, Loss: 0.3517918363213539\n",
            "Step 13260, Epoch 4/5, Loss: 0.33626294881105423\n",
            "Step 13264, Epoch 4/5, Loss: 0.32327232882380486\n",
            "Step 13268, Epoch 4/5, Loss: 0.41845470666885376\n",
            "Step 13272, Epoch 4/5, Loss: 0.3555266782641411\n",
            "Step 13276, Epoch 4/5, Loss: 0.33575284481048584\n",
            "Step 13280, Epoch 4/5, Loss: 0.33550285547971725\n",
            "Step 13284, Epoch 4/5, Loss: 0.39544446021318436\n",
            "Step 13288, Epoch 4/5, Loss: 0.3044382929801941\n",
            "Step 13292, Epoch 4/5, Loss: 0.3386959880590439\n",
            "Step 13296, Epoch 4/5, Loss: 0.32665709778666496\n",
            "Step 13300, Epoch 4/5, Loss: 0.3229509964585304\n",
            "Step 13304, Epoch 4/5, Loss: 0.4109218642115593\n",
            "Step 13308, Epoch 4/5, Loss: 0.3955836780369282\n",
            "Step 13312, Epoch 4/5, Loss: 0.35604842007160187\n",
            "Step 13316, Epoch 4/5, Loss: 0.31645743548870087\n",
            "Step 13320, Epoch 4/5, Loss: 0.30941493064165115\n",
            "Step 13324, Epoch 4/5, Loss: 0.32408764213323593\n",
            "Step 13328, Epoch 4/5, Loss: 0.30621716380119324\n",
            "Step 13332, Epoch 4/5, Loss: 0.39479725807905197\n",
            "Step 13336, Epoch 4/5, Loss: 0.3665468990802765\n",
            "Step 13340, Epoch 4/5, Loss: 0.2897360101342201\n",
            "Step 13344, Epoch 4/5, Loss: 0.3539629802107811\n",
            "Step 13348, Epoch 4/5, Loss: 0.3021620661020279\n",
            "Step 13352, Epoch 4/5, Loss: 0.3198896795511246\n",
            "Step 13356, Epoch 4/5, Loss: 0.3443321958184242\n",
            "Step 13360, Epoch 4/5, Loss: 0.2964188940823078\n",
            "Step 13364, Epoch 4/5, Loss: 0.37990691512823105\n",
            "Step 13368, Epoch 4/5, Loss: 0.31012817472219467\n",
            "Step 13372, Epoch 4/5, Loss: 0.3059419170022011\n",
            "Step 13376, Epoch 4/5, Loss: 0.3155183456838131\n",
            "Step 13380, Epoch 4/5, Loss: 0.3465956151485443\n",
            "Step 13384, Epoch 4/5, Loss: 0.37568992376327515\n",
            "Step 13388, Epoch 4/5, Loss: 0.36521343886852264\n",
            "Step 13392, Epoch 4/5, Loss: 0.3748411387205124\n",
            "Step 13396, Epoch 4/5, Loss: 0.34724268317222595\n",
            "Step 13400, Epoch 4/5, Loss: 0.3166828155517578\n",
            "Step 13404, Epoch 4/5, Loss: 0.3009585626423359\n",
            "Step 13408, Epoch 4/5, Loss: 0.3478585332632065\n",
            "Step 13412, Epoch 4/5, Loss: 0.3498166911303997\n",
            "Step 13416, Epoch 4/5, Loss: 0.3477121517062187\n",
            "Step 13420, Epoch 4/5, Loss: 0.3718154579401016\n",
            "Step 13424, Epoch 4/5, Loss: 0.2579699270427227\n",
            "Step 13428, Epoch 4/5, Loss: 0.3398876413702965\n",
            "Step 13432, Epoch 4/5, Loss: 0.3584313318133354\n",
            "Step 13436, Epoch 4/5, Loss: 0.28141577541828156\n",
            "Step 13440, Epoch 4/5, Loss: 0.303533673286438\n",
            "Step 13444, Epoch 4/5, Loss: 0.3660501465201378\n",
            "Step 13448, Epoch 4/5, Loss: 0.35882730036973953\n",
            "Step 13452, Epoch 4/5, Loss: 0.29864588379859924\n",
            "Step 13456, Epoch 4/5, Loss: 0.3441174663603306\n",
            "Step 13460, Epoch 4/5, Loss: 0.3167097419500351\n",
            "Step 13464, Epoch 4/5, Loss: 0.36730051785707474\n",
            "Step 13468, Epoch 4/5, Loss: 0.27039988711476326\n",
            "Step 13472, Epoch 4/5, Loss: 0.4108148068189621\n",
            "Step 13476, Epoch 4/5, Loss: 0.36936330050230026\n",
            "Step 13480, Epoch 4/5, Loss: 0.3531953990459442\n",
            "Step 13484, Epoch 4/5, Loss: 0.2718038223683834\n",
            "Step 13488, Epoch 4/5, Loss: 0.3455723226070404\n",
            "Step 13492, Epoch 4/5, Loss: 0.30447910726070404\n",
            "Step 13496, Epoch 4/5, Loss: 0.2640044800937176\n",
            "Step 13500, Epoch 4/5, Loss: 0.377797931432724\n",
            "Step 13504, Epoch 4/5, Loss: 0.2691146545112133\n",
            "Step 13508, Epoch 4/5, Loss: 0.33851374313235283\n",
            "Step 13512, Epoch 4/5, Loss: 0.33031151443719864\n",
            "Step 13516, Epoch 4/5, Loss: 0.34886525571346283\n",
            "Step 13520, Epoch 4/5, Loss: 0.3278496190905571\n",
            "Step 13524, Epoch 4/5, Loss: 0.3442608341574669\n",
            "Step 13528, Epoch 4/5, Loss: 0.3024074099957943\n",
            "Step 13532, Epoch 4/5, Loss: 0.36741903424263\n",
            "Step 13536, Epoch 4/5, Loss: 0.35580286383628845\n",
            "Step 13540, Epoch 4/5, Loss: 0.2619093023240566\n",
            "Step 13544, Epoch 4/5, Loss: 0.2977956309914589\n",
            "Step 13548, Epoch 4/5, Loss: 0.34543273225426674\n",
            "Step 13552, Epoch 4/5, Loss: 0.33170630782842636\n",
            "Step 13556, Epoch 4/5, Loss: 0.2791682854294777\n",
            "Step 13560, Epoch 4/5, Loss: 0.334074504673481\n",
            "Step 13564, Epoch 4/5, Loss: 0.3426477313041687\n",
            "Step 13568, Epoch 4/5, Loss: 0.3439253345131874\n",
            "Step 13572, Epoch 4/5, Loss: 0.40747449547052383\n",
            "Step 13576, Epoch 4/5, Loss: 0.4051789715886116\n",
            "Step 13580, Epoch 4/5, Loss: 0.4011862799525261\n",
            "Step 13584, Epoch 4/5, Loss: 0.36985450237989426\n",
            "Step 13588, Epoch 4/5, Loss: 0.3056473694741726\n",
            "Step 13592, Epoch 4/5, Loss: 0.341093048453331\n",
            "Step 13596, Epoch 4/5, Loss: 0.38387856259942055\n",
            "Step 13600, Epoch 4/5, Loss: 0.2710523456335068\n",
            "Step 13604, Epoch 4/5, Loss: 0.3536468520760536\n",
            "Step 13608, Epoch 4/5, Loss: 0.32468826323747635\n",
            "Step 13612, Epoch 4/5, Loss: 0.30255959928035736\n",
            "Step 13616, Epoch 4/5, Loss: 0.3324529156088829\n",
            "Step 13620, Epoch 4/5, Loss: 0.40804965794086456\n",
            "Step 13624, Epoch 4/5, Loss: 0.2732987627387047\n",
            "Step 13628, Epoch 4/5, Loss: 0.32542016357183456\n",
            "Step 13632, Epoch 4/5, Loss: 0.3121594563126564\n",
            "Step 13636, Epoch 4/5, Loss: 0.37315357476472855\n",
            "Step 13640, Epoch 4/5, Loss: 0.31775330007076263\n",
            "Step 13644, Epoch 4/5, Loss: 0.3100826367735863\n",
            "Step 13648, Epoch 4/5, Loss: 0.3586735166609287\n",
            "Step 13652, Epoch 4/5, Loss: 0.3571889251470566\n",
            "Step 13656, Epoch 4/5, Loss: 0.3324606120586395\n",
            "Step 13660, Epoch 4/5, Loss: 0.38584497570991516\n",
            "Step 13664, Epoch 4/5, Loss: 0.252840343862772\n",
            "Step 13668, Epoch 4/5, Loss: 0.28209900483489037\n",
            "Step 13672, Epoch 4/5, Loss: 0.2719808965921402\n",
            "Step 13676, Epoch 4/5, Loss: 0.3226664289832115\n",
            "Step 13680, Epoch 4/5, Loss: 0.33343611657619476\n",
            "Step 13684, Epoch 4/5, Loss: 0.31587713211774826\n",
            "Step 13688, Epoch 4/5, Loss: 0.3941991701722145\n",
            "Step 13692, Epoch 4/5, Loss: 0.2932369261980057\n",
            "Step 13696, Epoch 4/5, Loss: 0.3064796179533005\n",
            "Step 13700, Epoch 4/5, Loss: 0.2793283984065056\n",
            "Step 13704, Epoch 4/5, Loss: 0.3912910223007202\n",
            "Step 13708, Epoch 4/5, Loss: 0.3652958758175373\n",
            "Step 13712, Epoch 4/5, Loss: 0.35671366751194\n",
            "Step 13716, Epoch 4/5, Loss: 0.3964793384075165\n",
            "Step 13720, Epoch 4/5, Loss: 0.30174877122044563\n",
            "Step 13724, Epoch 4/5, Loss: 0.28567202389240265\n",
            "Step 13728, Epoch 4/5, Loss: 0.34114205092191696\n",
            "Step 13732, Epoch 4/5, Loss: 0.36222921311855316\n",
            "Step 13736, Epoch 4/5, Loss: 0.30998681485652924\n",
            "Step 13740, Epoch 4/5, Loss: 0.30329929664731026\n",
            "Step 13744, Epoch 4/5, Loss: 0.3741578459739685\n",
            "Step 13748, Epoch 4/5, Loss: 0.3593677058815956\n",
            "Step 13752, Epoch 4/5, Loss: 0.32591724395751953\n",
            "Step 13756, Epoch 4/5, Loss: 0.3325069434940815\n",
            "Step 13760, Epoch 4/5, Loss: 0.3922360837459564\n",
            "Step 13764, Epoch 4/5, Loss: 0.386513315141201\n",
            "Step 13768, Epoch 4/5, Loss: 0.3706532046198845\n",
            "Step 13772, Epoch 4/5, Loss: 0.26632585376501083\n",
            "Step 13776, Epoch 4/5, Loss: 0.40338728576898575\n",
            "Step 13780, Epoch 4/5, Loss: 0.2758285067975521\n",
            "Step 13784, Epoch 4/5, Loss: 0.25298788771033287\n",
            "Step 13788, Epoch 4/5, Loss: 0.33083219826221466\n",
            "Step 13792, Epoch 4/5, Loss: 0.2960962690412998\n",
            "Step 13796, Epoch 4/5, Loss: 0.3011692389845848\n",
            "Step 13800, Epoch 4/5, Loss: 0.40934573113918304\n",
            "Step 13804, Epoch 4/5, Loss: 0.3176904171705246\n",
            "Step 13808, Epoch 4/5, Loss: 0.3020402863621712\n",
            "Step 13812, Epoch 4/5, Loss: 0.39031482487916946\n",
            "Step 13816, Epoch 4/5, Loss: 0.31893710419535637\n",
            "Step 13820, Epoch 4/5, Loss: 0.31718023121356964\n",
            "Step 13824, Epoch 4/5, Loss: 0.338031142950058\n",
            "Step 13828, Epoch 4/5, Loss: 0.3745686449110508\n",
            "Step 13832, Epoch 4/5, Loss: 0.42706073820590973\n",
            "Step 13836, Epoch 4/5, Loss: 0.281114362180233\n",
            "Step 13840, Epoch 4/5, Loss: 0.28866881132125854\n",
            "Step 13844, Epoch 4/5, Loss: 0.36940139159560204\n",
            "Step 13848, Epoch 4/5, Loss: 0.3990419805049896\n",
            "Step 13852, Epoch 4/5, Loss: 0.31655365973711014\n",
            "Step 13856, Epoch 4/5, Loss: 0.3175988718867302\n",
            "Step 13860, Epoch 4/5, Loss: 0.3197941705584526\n",
            "Step 13864, Epoch 4/5, Loss: 0.3938933238387108\n",
            "Step 13868, Epoch 4/5, Loss: 0.3346717096865177\n",
            "Step 13872, Epoch 4/5, Loss: 0.2986418679356575\n",
            "Step 13876, Epoch 4/5, Loss: 0.39832109957933426\n",
            "Step 13880, Epoch 4/5, Loss: 0.3248306065797806\n",
            "Step 13884, Epoch 4/5, Loss: 0.29749851301312447\n",
            "Step 13888, Epoch 4/5, Loss: 0.33569327741861343\n",
            "Step 13892, Epoch 4/5, Loss: 0.2875513508915901\n",
            "Step 13896, Epoch 4/5, Loss: 0.29099898412823677\n",
            "Step 13900, Epoch 4/5, Loss: 0.38672421127557755\n",
            "Step 13904, Epoch 4/5, Loss: 0.323250487446785\n",
            "Step 13908, Epoch 4/5, Loss: 0.3779296725988388\n",
            "Step 13912, Epoch 4/5, Loss: 0.3105952851474285\n",
            "Step 13916, Epoch 4/5, Loss: 0.37251122295856476\n",
            "Step 13920, Epoch 4/5, Loss: 0.3695644661784172\n",
            "Step 13924, Epoch 4/5, Loss: 0.3121648021042347\n",
            "Step 13928, Epoch 4/5, Loss: 0.405483640730381\n",
            "Step 13932, Epoch 4/5, Loss: 0.3200804740190506\n",
            "Step 13936, Epoch 4/5, Loss: 0.404395192861557\n",
            "Step 13940, Epoch 4/5, Loss: 0.33574699610471725\n",
            "Step 13944, Epoch 4/5, Loss: 0.3568371459841728\n",
            "Step 13948, Epoch 4/5, Loss: 0.32198528572916985\n",
            "Step 13952, Epoch 4/5, Loss: 0.36431488394737244\n",
            "Step 13956, Epoch 4/5, Loss: 0.3113267533481121\n",
            "Step 13960, Epoch 4/5, Loss: 0.33200933784246445\n",
            "Step 13964, Epoch 4/5, Loss: 0.3685140013694763\n",
            "Step 13968, Epoch 4/5, Loss: 0.34359241276979446\n",
            "Step 13972, Epoch 4/5, Loss: 0.37579161673784256\n",
            "Step 13976, Epoch 4/5, Loss: 0.2963031120598316\n",
            "Step 13980, Epoch 4/5, Loss: 0.354944683611393\n",
            "Step 13984, Epoch 4/5, Loss: 0.38764622807502747\n",
            "Step 13988, Epoch 4/5, Loss: 0.3866396024823189\n",
            "Step 13992, Epoch 4/5, Loss: 0.3539331220090389\n",
            "Step 13996, Epoch 4/5, Loss: 0.335164412856102\n",
            "Step 14000, Epoch 4/5, Loss: 0.3372527062892914\n",
            "Step 14004, Epoch 4/5, Loss: 0.29214929416775703\n",
            "Step 14008, Epoch 4/5, Loss: 0.3447059243917465\n",
            "Step 14012, Epoch 4/5, Loss: 0.3804626166820526\n",
            "Step 14016, Epoch 4/5, Loss: 0.34132395684719086\n",
            "Step 14020, Epoch 4/5, Loss: 0.3364267833530903\n",
            "Step 14024, Epoch 4/5, Loss: 0.3085053376853466\n",
            "Step 14028, Epoch 4/5, Loss: 0.3050853870809078\n",
            "Step 14032, Epoch 4/5, Loss: 0.3748460039496422\n",
            "Step 14036, Epoch 4/5, Loss: 0.2973754145205021\n",
            "Step 14040, Epoch 4/5, Loss: 0.3733285292983055\n",
            "Step 14044, Epoch 4/5, Loss: 0.3787921145558357\n",
            "Step 14048, Epoch 4/5, Loss: 0.3194890767335892\n",
            "Step 14052, Epoch 4/5, Loss: 0.3715958520770073\n",
            "Step 14056, Epoch 4/5, Loss: 0.3425319865345955\n",
            "Step 14060, Epoch 4/5, Loss: 0.31204240024089813\n",
            "Step 14064, Epoch 4/5, Loss: 0.35177867487072945\n",
            "Step 14068, Epoch 4/5, Loss: 0.37037019431591034\n",
            "Step 14072, Epoch 4/5, Loss: 0.30404461920261383\n",
            "Step 14076, Epoch 4/5, Loss: 0.4145549312233925\n",
            "Step 14080, Epoch 4/5, Loss: 0.28600890189409256\n",
            "Step 14084, Epoch 4/5, Loss: 0.3368791490793228\n",
            "Step 14088, Epoch 4/5, Loss: 0.3065575510263443\n",
            "Step 14092, Epoch 4/5, Loss: 0.28986499458551407\n",
            "Step 14096, Epoch 4/5, Loss: 0.29137835279107094\n",
            "Step 14100, Epoch 4/5, Loss: 0.3104148246347904\n",
            "Step 14104, Epoch 4/5, Loss: 0.28610652312636375\n",
            "Step 14108, Epoch 4/5, Loss: 0.3533376529812813\n",
            "Step 14112, Epoch 4/5, Loss: 0.3691728115081787\n",
            "Step 14116, Epoch 4/5, Loss: 0.3218076564371586\n",
            "Step 14120, Epoch 4/5, Loss: 0.35905010998249054\n",
            "Step 14124, Epoch 4/5, Loss: 0.3332269862294197\n",
            "Step 14128, Epoch 4/5, Loss: 0.3913293480873108\n",
            "Step 14132, Epoch 4/5, Loss: 0.2911785803735256\n",
            "Step 14136, Epoch 4/5, Loss: 0.28632400929927826\n",
            "Step 14140, Epoch 4/5, Loss: 0.3678574413061142\n",
            "Step 14144, Epoch 4/5, Loss: 0.30144529044628143\n",
            "Step 14148, Epoch 4/5, Loss: 0.33572786673903465\n",
            "Step 14152, Epoch 4/5, Loss: 0.2616868242621422\n",
            "Step 14156, Epoch 4/5, Loss: 0.37502481415867805\n",
            "Step 14160, Epoch 4/5, Loss: 0.3337392359972\n",
            "Step 14164, Epoch 4/5, Loss: 0.2791777327656746\n",
            "Step 14168, Epoch 4/5, Loss: 0.3143795281648636\n",
            "Step 14172, Epoch 4/5, Loss: 0.25206132233142853\n",
            "Step 14176, Epoch 4/5, Loss: 0.33078208565711975\n",
            "Step 14180, Epoch 4/5, Loss: 0.38066481798887253\n",
            "Step 14184, Epoch 4/5, Loss: 0.3450780585408211\n",
            "Step 14188, Epoch 4/5, Loss: 0.2932826653122902\n",
            "Step 14192, Epoch 4/5, Loss: 0.350382499396801\n",
            "Step 14196, Epoch 4/5, Loss: 0.32209159433841705\n",
            "Step 14200, Epoch 4/5, Loss: 0.3128505237400532\n",
            "Step 14204, Epoch 4/5, Loss: 0.36013632267713547\n",
            "Step 14208, Epoch 4/5, Loss: 0.3749757260084152\n",
            "Step 14212, Epoch 4/5, Loss: 0.367196761071682\n",
            "Step 14216, Epoch 4/5, Loss: 0.39624200016260147\n",
            "Step 14220, Epoch 4/5, Loss: 0.3302062153816223\n",
            "Step 14224, Epoch 4/5, Loss: 0.32311176508665085\n",
            "Step 14228, Epoch 4/5, Loss: 0.29917721077799797\n",
            "Step 14232, Epoch 4/5, Loss: 0.323671318590641\n",
            "Step 14236, Epoch 4/5, Loss: 0.30547405779361725\n",
            "Step 14240, Epoch 4/5, Loss: 0.31215526163578033\n",
            "Step 14244, Epoch 4/5, Loss: 0.33080585673451424\n",
            "Step 14248, Epoch 4/5, Loss: 0.294252160936594\n",
            "Step 14252, Epoch 4/5, Loss: 0.3362050876021385\n",
            "Step 14256, Epoch 4/5, Loss: 0.31139325350522995\n",
            "Step 14260, Epoch 4/5, Loss: 0.39752429723739624\n",
            "Step 14264, Epoch 4/5, Loss: 0.3499021604657173\n",
            "Step 14268, Epoch 4/5, Loss: 0.38275715336203575\n",
            "Step 14272, Epoch 4/5, Loss: 0.3070754408836365\n",
            "Step 14276, Epoch 4/5, Loss: 0.36970921605825424\n",
            "Step 14280, Epoch 4/5, Loss: 0.3569996729493141\n",
            "Step 14284, Epoch 4/5, Loss: 0.3738982155919075\n",
            "Step 14288, Epoch 4/5, Loss: 0.23358190059661865\n",
            "Step 14292, Epoch 4/5, Loss: 0.314902164041996\n",
            "Step 14296, Epoch 4/5, Loss: 0.34965142607688904\n",
            "Step 14300, Epoch 4/5, Loss: 0.41047216206789017\n",
            "Step 14304, Epoch 4/5, Loss: 0.4206984043121338\n",
            "Step 14308, Epoch 4/5, Loss: 0.2596309706568718\n",
            "Step 14312, Epoch 4/5, Loss: 0.3278709352016449\n",
            "Step 14316, Epoch 4/5, Loss: 0.3387242257595062\n",
            "Step 14320, Epoch 4/5, Loss: 0.35005179792642593\n",
            "Step 14324, Epoch 4/5, Loss: 0.3538423180580139\n",
            "Step 14328, Epoch 4/5, Loss: 0.4274865984916687\n",
            "Step 14332, Epoch 4/5, Loss: 0.3287636823952198\n",
            "Step 14336, Epoch 4/5, Loss: 0.37384429946541786\n",
            "Step 14340, Epoch 4/5, Loss: 0.38051459938287735\n",
            "Step 14344, Epoch 4/5, Loss: 0.28339891135692596\n",
            "Step 14348, Epoch 4/5, Loss: 0.363465391099453\n",
            "Step 14352, Epoch 4/5, Loss: 0.3833378106355667\n",
            "Step 14356, Epoch 4/5, Loss: 0.4049406200647354\n",
            "Step 14360, Epoch 4/5, Loss: 0.36208057403564453\n",
            "Step 14364, Epoch 4/5, Loss: 0.30655550584197044\n",
            "Step 14368, Epoch 4/5, Loss: 0.3288443572819233\n",
            "Step 14372, Epoch 4/5, Loss: 0.38460835069417953\n",
            "Step 14376, Epoch 4/5, Loss: 0.33158644288778305\n",
            "Step 14380, Epoch 4/5, Loss: 0.26865002512931824\n",
            "Step 14384, Epoch 4/5, Loss: 0.3582428991794586\n",
            "Step 14388, Epoch 4/5, Loss: 0.3877880424261093\n",
            "Step 14392, Epoch 4/5, Loss: 0.38568053394556046\n",
            "Step 14396, Epoch 4/5, Loss: 0.3110539838671684\n",
            "Step 14400, Epoch 4/5, Loss: 0.35795579105615616\n",
            "Step 14404, Epoch 4/5, Loss: 0.31504083424806595\n",
            "Step 14408, Epoch 4/5, Loss: 0.31201379746198654\n",
            "Step 14412, Epoch 4/5, Loss: 0.28639130666852\n",
            "Step 14416, Epoch 4/5, Loss: 0.3646434023976326\n",
            "Step 14420, Epoch 4/5, Loss: 0.31252462044358253\n",
            "Step 14424, Epoch 4/5, Loss: 0.31793585419654846\n",
            "Step 14428, Epoch 4/5, Loss: 0.2775666005909443\n",
            "Step 14432, Epoch 4/5, Loss: 0.3014138713479042\n",
            "Step 14436, Epoch 4/5, Loss: 0.3320992738008499\n",
            "Step 14440, Epoch 4/5, Loss: 0.3153690993785858\n",
            "Step 14444, Epoch 4/5, Loss: 0.3865708261728287\n",
            "Step 14448, Epoch 4/5, Loss: 0.4589245393872261\n",
            "Step 14452, Epoch 4/5, Loss: 0.368909627199173\n",
            "Step 14456, Epoch 4/5, Loss: 0.31082430481910706\n",
            "Step 14460, Epoch 4/5, Loss: 0.38606250286102295\n",
            "Step 14464, Epoch 4/5, Loss: 0.2973265200853348\n",
            "Step 14468, Epoch 4/5, Loss: 0.37094683945178986\n",
            "Step 14472, Epoch 4/5, Loss: 0.41056131571531296\n",
            "Step 14476, Epoch 4/5, Loss: 0.3663129471242428\n",
            "Step 14480, Epoch 4/5, Loss: 0.3162098675966263\n",
            "Step 14484, Epoch 4/5, Loss: 0.3678912855684757\n",
            "Step 14488, Epoch 4/5, Loss: 0.3147609531879425\n",
            "Step 14492, Epoch 4/5, Loss: 0.361698005348444\n",
            "Step 14496, Epoch 4/5, Loss: 0.3333776816725731\n",
            "Step 14500, Epoch 4/5, Loss: 0.3495704419910908\n",
            "Step 14504, Epoch 4/5, Loss: 0.3883498087525368\n",
            "Step 14508, Epoch 4/5, Loss: 0.3424588143825531\n",
            "Step 14512, Epoch 4/5, Loss: 0.33558303117752075\n",
            "Step 14516, Epoch 4/5, Loss: 0.37422803044319153\n",
            "Step 14520, Epoch 4/5, Loss: 0.31157178059220314\n",
            "Step 14524, Epoch 4/5, Loss: 0.28303689509630203\n",
            "Step 14528, Epoch 4/5, Loss: 0.3659745007753372\n",
            "Step 14532, Epoch 4/5, Loss: 0.3101172558963299\n",
            "Step 14536, Epoch 4/5, Loss: 0.3468124009668827\n",
            "Step 14540, Epoch 4/5, Loss: 0.3132645785808563\n",
            "Step 14544, Epoch 4/5, Loss: 0.3356938362121582\n",
            "Step 14548, Epoch 4/5, Loss: 0.309656523168087\n",
            "Step 14552, Epoch 4/5, Loss: 0.4150976687669754\n",
            "Step 14556, Epoch 4/5, Loss: 0.3651116341352463\n",
            "Step 14560, Epoch 4/5, Loss: 0.2636038176715374\n",
            "Step 14564, Epoch 4/5, Loss: 0.39436104893684387\n",
            "Step 14568, Epoch 4/5, Loss: 0.3047838471829891\n",
            "Step 14572, Epoch 4/5, Loss: 0.37240131944417953\n",
            "Step 14576, Epoch 4/5, Loss: 0.3651088997721672\n",
            "Step 14580, Epoch 4/5, Loss: 0.35096073895692825\n",
            "Step 14584, Epoch 4/5, Loss: 0.3371906541287899\n",
            "Step 14588, Epoch 4/5, Loss: 0.29827050492167473\n",
            "Step 14592, Epoch 4/5, Loss: 0.30416612327098846\n",
            "Step 14596, Epoch 4/5, Loss: 0.2840811349451542\n",
            "Step 14600, Epoch 4/5, Loss: 0.3257649391889572\n",
            "Step 14604, Epoch 4/5, Loss: 0.37152624130249023\n",
            "Step 14608, Epoch 4/5, Loss: 0.31842879578471184\n",
            "Step 14612, Epoch 4/5, Loss: 0.31688645854592323\n",
            "Step 14616, Epoch 4/5, Loss: 0.2671978212893009\n",
            "Step 14620, Epoch 4/5, Loss: 0.29247843101620674\n",
            "Step 14624, Epoch 4/5, Loss: 0.33623160421848297\n",
            "Step 14628, Epoch 4/5, Loss: 0.3602993115782738\n",
            "Step 14632, Epoch 4/5, Loss: 0.3334568664431572\n",
            "Step 14636, Epoch 4/5, Loss: 0.36674391478300095\n",
            "Step 14640, Epoch 4/5, Loss: 0.29349640384316444\n",
            "Step 14644, Epoch 4/5, Loss: 0.38857923448085785\n",
            "Step 14648, Epoch 4/5, Loss: 0.33012767881155014\n",
            "Step 14652, Epoch 4/5, Loss: 0.38542214781045914\n",
            "Step 14656, Epoch 4/5, Loss: 0.27697815746068954\n",
            "Step 14660, Epoch 4/5, Loss: 0.33679483085870743\n",
            "Step 14664, Epoch 4/5, Loss: 0.2601185366511345\n",
            "Step 14668, Epoch 4/5, Loss: 0.2742801420390606\n",
            "Step 14672, Epoch 4/5, Loss: 0.3234405890107155\n",
            "Step 14676, Epoch 4/5, Loss: 0.3359108716249466\n",
            "Step 14680, Epoch 4/5, Loss: 0.25854701176285744\n",
            "Step 14684, Epoch 4/5, Loss: 0.26325591653585434\n",
            "Step 14688, Epoch 4/5, Loss: 0.4029437452554703\n",
            "Step 14692, Epoch 4/5, Loss: 0.34143786132335663\n",
            "Step 14696, Epoch 4/5, Loss: 0.36740539595484734\n",
            "Step 14700, Epoch 4/5, Loss: 0.33092883601784706\n",
            "Step 14704, Epoch 4/5, Loss: 0.33899977803230286\n",
            "Step 14708, Epoch 4/5, Loss: 0.32728704810142517\n",
            "Step 14712, Epoch 4/5, Loss: 0.3112823888659477\n",
            "Step 14716, Epoch 4/5, Loss: 0.2508530169725418\n",
            "Step 14720, Epoch 4/5, Loss: 0.3391641601920128\n",
            "Step 14724, Epoch 4/5, Loss: 0.3194827325642109\n",
            "Step 14728, Epoch 4/5, Loss: 0.30057258531451225\n",
            "Step 14732, Epoch 4/5, Loss: 0.31191935390233994\n",
            "Step 14736, Epoch 4/5, Loss: 0.26950280368328094\n",
            "Step 14740, Epoch 4/5, Loss: 0.3910648450255394\n",
            "Step 14744, Epoch 4/5, Loss: 0.3936246633529663\n",
            "Step 14748, Epoch 4/5, Loss: 0.3488024026155472\n",
            "Step 14752, Epoch 4/5, Loss: 0.28756682202219963\n",
            "Step 14756, Epoch 4/5, Loss: 0.307937104254961\n",
            "Step 14760, Epoch 4/5, Loss: 0.3146137371659279\n",
            "Step 14764, Epoch 4/5, Loss: 0.40827616304159164\n",
            "Step 14768, Epoch 4/5, Loss: 0.4217624142765999\n",
            "Step 14772, Epoch 4/5, Loss: 0.33772847801446915\n",
            "Step 14776, Epoch 4/5, Loss: 0.36486847698688507\n",
            "Step 14780, Epoch 4/5, Loss: 0.35523470491170883\n",
            "Step 14784, Epoch 4/5, Loss: 0.35155925899744034\n",
            "Step 14788, Epoch 4/5, Loss: 0.31307918205857277\n",
            "Step 14792, Epoch 4/5, Loss: 0.29590480402112007\n",
            "Step 14796, Epoch 4/5, Loss: 0.31832320243120193\n",
            "Step 14800, Epoch 4/5, Loss: 0.343268446624279\n",
            "Step 14804, Epoch 4/5, Loss: 0.2806558459997177\n",
            "Step 14808, Epoch 4/5, Loss: 0.3704472482204437\n",
            "Step 14812, Epoch 4/5, Loss: 0.3716696500778198\n",
            "Step 14816, Epoch 4/5, Loss: 0.31745002418756485\n",
            "Step 14820, Epoch 4/5, Loss: 0.33789849653840065\n",
            "Step 14824, Epoch 4/5, Loss: 0.33674342930316925\n",
            "Step 14828, Epoch 4/5, Loss: 0.3263283669948578\n",
            "Step 14832, Epoch 4/5, Loss: 0.37728457152843475\n",
            "Step 14836, Epoch 4/5, Loss: 0.26751813292503357\n",
            "Step 14840, Epoch 4/5, Loss: 0.326177254319191\n",
            "Step 14844, Epoch 4/5, Loss: 0.3014840669929981\n",
            "Step 14848, Epoch 4/5, Loss: 0.302003875374794\n",
            "Step 14852, Epoch 4/5, Loss: 0.3256406709551811\n",
            "Step 14856, Epoch 4/5, Loss: 0.3563501834869385\n",
            "Step 14860, Epoch 4/5, Loss: 0.3067682608962059\n",
            "Step 14864, Epoch 4/5, Loss: 0.34149787947535515\n",
            "Step 14868, Epoch 4/5, Loss: 0.3566785305738449\n",
            "Step 14872, Epoch 4/5, Loss: 0.3501046597957611\n",
            "Step 14876, Epoch 4/5, Loss: 0.3280150517821312\n",
            "Step 14880, Epoch 4/5, Loss: 0.3387870192527771\n",
            "Step 14884, Epoch 4/5, Loss: 0.3282919153571129\n",
            "Step 14888, Epoch 4/5, Loss: 0.26359570771455765\n",
            "Step 14892, Epoch 4/5, Loss: 0.42386649549007416\n",
            "Step 14896, Epoch 4/5, Loss: 0.3252875469624996\n",
            "Step 14900, Epoch 4/5, Loss: 0.3794672265648842\n",
            "Step 14904, Epoch 4/5, Loss: 0.2960407994687557\n",
            "Step 14908, Epoch 4/5, Loss: 0.37027356028556824\n",
            "Step 14912, Epoch 4/5, Loss: 0.30623091012239456\n",
            "Step 14916, Epoch 4/5, Loss: 0.36063821613788605\n",
            "Step 14920, Epoch 4/5, Loss: 0.3785680830478668\n",
            "Step 14924, Epoch 4/5, Loss: 0.3961368016898632\n",
            "Step 14928, Epoch 4/5, Loss: 0.4090902507305145\n",
            "Step 14932, Epoch 4/5, Loss: 0.33446547389030457\n",
            "Step 14936, Epoch 4/5, Loss: 0.41160572320222855\n",
            "Step 14940, Epoch 4/5, Loss: 0.29492050781846046\n",
            "Step 14944, Epoch 4/5, Loss: 0.28353243321180344\n",
            "Step 14948, Epoch 4/5, Loss: 0.35160353034734726\n",
            "Step 14952, Epoch 4/5, Loss: 0.27663933858275414\n",
            "Step 14956, Epoch 4/5, Loss: 0.2980889417231083\n",
            "Step 14960, Epoch 4/5, Loss: 0.2999684624373913\n",
            "Step 14964, Epoch 4/5, Loss: 0.2922625169157982\n",
            "Step 14968, Epoch 4/5, Loss: 0.3446507789194584\n",
            "Step 14972, Epoch 4/5, Loss: 0.3201047368347645\n",
            "Step 14976, Epoch 4/5, Loss: 0.3557203412055969\n",
            "Step 14980, Epoch 4/5, Loss: 0.266368567943573\n",
            "Step 14984, Epoch 4/5, Loss: 0.37583550810813904\n",
            "Step 14988, Epoch 4/5, Loss: 0.3374069333076477\n",
            "Step 14992, Epoch 4/5, Loss: 0.3392017036676407\n",
            "Step 14996, Epoch 4/5, Loss: 0.2918977588415146\n",
            "Step 15000, Epoch 4/5, Loss: 0.24509411677718163\n",
            "Step 15004, Epoch 4/5, Loss: 0.31534335389733315\n",
            "Step 15008, Epoch 4/5, Loss: 0.3418211415410042\n",
            "Step 15012, Epoch 4/5, Loss: 0.4002102091908455\n",
            "Step 15016, Epoch 4/5, Loss: 0.355506993830204\n",
            "Step 15020, Epoch 4/5, Loss: 0.4587607979774475\n",
            "Step 15024, Epoch 4/5, Loss: 0.35719362273812294\n",
            "Step 15028, Epoch 4/5, Loss: 0.2914033755660057\n",
            "Step 15032, Epoch 4/5, Loss: 0.40025511384010315\n",
            "Step 15036, Epoch 4/5, Loss: 0.3509306162595749\n",
            "Step 15040, Epoch 4/5, Loss: 0.4094918742775917\n",
            "Step 15044, Epoch 4/5, Loss: 0.3973945900797844\n",
            "Step 15048, Epoch 4/5, Loss: 0.33296459168195724\n",
            "Step 15052, Epoch 4/5, Loss: 0.3744973987340927\n",
            "Step 15056, Epoch 4/5, Loss: 0.3941534087061882\n",
            "Step 15060, Epoch 4/5, Loss: 0.38005537539720535\n",
            "Step 15064, Epoch 4/5, Loss: 0.39956410974264145\n",
            "Step 15068, Epoch 4/5, Loss: 0.4055309519171715\n",
            "Step 15072, Epoch 4/5, Loss: 0.2566090002655983\n",
            "Step 15076, Epoch 4/5, Loss: 0.36479270458221436\n",
            "Step 15080, Epoch 4/5, Loss: 0.3088361769914627\n",
            "Step 15084, Epoch 4/5, Loss: 0.3519454076886177\n",
            "Step 15088, Epoch 4/5, Loss: 0.28198089823126793\n",
            "Step 15092, Epoch 4/5, Loss: 0.3239065706729889\n",
            "Step 15096, Epoch 4/5, Loss: 0.2998279631137848\n",
            "Step 15100, Epoch 4/5, Loss: 0.3368084654211998\n",
            "Step 15104, Epoch 4/5, Loss: 0.2971349023282528\n",
            "Step 15108, Epoch 4/5, Loss: 0.25281621515750885\n",
            "Step 15112, Epoch 4/5, Loss: 0.34568145126104355\n",
            "Step 15116, Epoch 4/5, Loss: 0.2912570834159851\n",
            "Step 15120, Epoch 4/5, Loss: 0.35773756355047226\n",
            "Step 15124, Epoch 4/5, Loss: 0.4145684614777565\n",
            "Step 15128, Epoch 4/5, Loss: 0.2224455662071705\n",
            "Step 15132, Epoch 4/5, Loss: 0.3064301162958145\n",
            "Step 15136, Epoch 4/5, Loss: 0.3629046231508255\n",
            "Step 15140, Epoch 4/5, Loss: 0.3294157162308693\n",
            "Step 15144, Epoch 4/5, Loss: 0.3246541768312454\n",
            "Step 15148, Epoch 4/5, Loss: 0.29245565459132195\n",
            "Step 15152, Epoch 4/5, Loss: 0.3170842416584492\n",
            "Step 15156, Epoch 4/5, Loss: 0.3151917792856693\n",
            "Step 15160, Epoch 4/5, Loss: 0.3309473693370819\n",
            "Step 15164, Epoch 4/5, Loss: 0.35607465356588364\n",
            "Step 15168, Epoch 4/5, Loss: 0.35932019352912903\n",
            "Step 15172, Epoch 4/5, Loss: 0.31516749411821365\n",
            "Step 15176, Epoch 4/5, Loss: 0.30430177971720695\n",
            "Step 15180, Epoch 4/5, Loss: 0.25379205867648125\n",
            "Step 15184, Epoch 4/5, Loss: 0.3128940761089325\n",
            "Step 15188, Epoch 4/5, Loss: 0.32740963250398636\n",
            "Step 15192, Epoch 4/5, Loss: 0.3369862362742424\n",
            "Step 15196, Epoch 4/5, Loss: 0.28613346070051193\n",
            "Step 15200, Epoch 4/5, Loss: 0.37018242478370667\n",
            "Step 15204, Epoch 4/5, Loss: 0.2917175628244877\n",
            "Step 15208, Epoch 4/5, Loss: 0.3152993731200695\n",
            "Step 15212, Epoch 4/5, Loss: 0.3190496116876602\n",
            "Step 15216, Epoch 4/5, Loss: 0.41624824702739716\n",
            "Step 15220, Epoch 4/5, Loss: 0.2935795895755291\n",
            "Step 15224, Epoch 4/5, Loss: 0.32876087352633476\n",
            "Step 15228, Epoch 4/5, Loss: 0.3206491991877556\n",
            "Step 15232, Epoch 4/5, Loss: 0.27221766859292984\n",
            "Step 15236, Epoch 4/5, Loss: 0.3528817258775234\n",
            "Step 15240, Epoch 4/5, Loss: 0.3595483973622322\n",
            "Step 15244, Epoch 4/5, Loss: 0.42435190081596375\n",
            "Step 15248, Epoch 4/5, Loss: 0.30036137998104095\n",
            "Step 15252, Epoch 4/5, Loss: 0.2977043613791466\n",
            "Step 15256, Epoch 4/5, Loss: 0.31712260842323303\n",
            "Step 15260, Epoch 4/5, Loss: 0.34306641668081284\n",
            "Step 15264, Epoch 4/5, Loss: 0.34970996528863907\n",
            "Step 15268, Epoch 4/5, Loss: 0.35054779052734375\n",
            "Step 15272, Epoch 4/5, Loss: 0.36956101655960083\n",
            "Step 15276, Epoch 4/5, Loss: 0.2618919312953949\n",
            "Step 15280, Epoch 4/5, Loss: 0.2858920730650425\n",
            "Step 15284, Epoch 4/5, Loss: 0.33045898377895355\n",
            "Step 15288, Epoch 4/5, Loss: 0.3448648862540722\n",
            "Step 15292, Epoch 4/5, Loss: 0.3217959478497505\n",
            "Step 15296, Epoch 4/5, Loss: 0.3572867773473263\n",
            "Step 15300, Epoch 4/5, Loss: 0.41795430332422256\n",
            "Step 15304, Epoch 4/5, Loss: 0.3456239625811577\n",
            "Step 15308, Epoch 4/5, Loss: 0.3838023319840431\n",
            "Step 15312, Epoch 4/5, Loss: 0.3133779987692833\n",
            "Step 15316, Epoch 4/5, Loss: 0.3623713105916977\n",
            "Step 15320, Epoch 4/5, Loss: 0.3764359652996063\n",
            "Step 15324, Epoch 4/5, Loss: 0.3288973942399025\n",
            "Step 15328, Epoch 4/5, Loss: 0.3802950456738472\n",
            "Step 15332, Epoch 4/5, Loss: 0.2620467394590378\n",
            "Step 15336, Epoch 4/5, Loss: 0.34554750472307205\n",
            "Step 15340, Epoch 4/5, Loss: 0.32389162853360176\n",
            "Step 15344, Epoch 4/5, Loss: 0.27766524627804756\n",
            "Step 15348, Epoch 4/5, Loss: 0.36529194191098213\n",
            "Step 15352, Epoch 4/5, Loss: 0.3768855519592762\n",
            "Step 15356, Epoch 4/5, Loss: 0.36521683633327484\n",
            "Step 15360, Epoch 4/5, Loss: 0.24893102794885635\n",
            "Step 15364, Epoch 4/5, Loss: 0.3880722001194954\n",
            "Step 15368, Epoch 4/5, Loss: 0.3060249499976635\n",
            "Step 15372, Epoch 4/5, Loss: 0.35341984778642654\n",
            "Step 15376, Epoch 4/5, Loss: 0.30478837341070175\n",
            "Step 15380, Epoch 4/5, Loss: 0.3287479616701603\n",
            "Step 15384, Epoch 4/5, Loss: 0.3232807144522667\n",
            "Step 15388, Epoch 4/5, Loss: 0.3690776228904724\n",
            "Step 15392, Epoch 4/5, Loss: 0.29381589964032173\n",
            "Step 15396, Epoch 4/5, Loss: 0.31415750831365585\n",
            "Step 15400, Epoch 4/5, Loss: 0.39475739002227783\n",
            "Step 15404, Epoch 4/5, Loss: 0.2703639045357704\n",
            "Step 15408, Epoch 4/5, Loss: 0.27884000912308693\n",
            "Step 15412, Epoch 4/5, Loss: 0.32061564177274704\n",
            "Step 15416, Epoch 4/5, Loss: 0.28305821493268013\n",
            "Step 15420, Epoch 4/5, Loss: 0.3542439863085747\n",
            "Step 15424, Epoch 4/5, Loss: 0.428088515996933\n",
            "Step 15428, Epoch 4/5, Loss: 0.27748385071754456\n",
            "Step 15432, Epoch 4/5, Loss: 0.2954488582909107\n",
            "Step 15436, Epoch 4/5, Loss: 0.31302956864237785\n",
            "Step 15440, Epoch 4/5, Loss: 0.33965668082237244\n",
            "Step 15444, Epoch 4/5, Loss: 0.3068359047174454\n",
            "Step 15448, Epoch 4/5, Loss: 0.3993867039680481\n",
            "Step 15452, Epoch 4/5, Loss: 0.3179547041654587\n",
            "Step 15456, Epoch 4/5, Loss: 0.3779921755194664\n",
            "Step 15460, Epoch 4/5, Loss: 0.3540002480149269\n",
            "Step 15464, Epoch 4/5, Loss: 0.33777882903814316\n",
            "Step 15468, Epoch 4/5, Loss: 0.30530451238155365\n",
            "Step 15472, Epoch 4/5, Loss: 0.2518647350370884\n",
            "Step 15476, Epoch 4/5, Loss: 0.3633055239915848\n",
            "Step 15480, Epoch 4/5, Loss: 0.4342106133699417\n",
            "Step 15484, Epoch 4/5, Loss: 0.25488538667559624\n",
            "Step 15488, Epoch 4/5, Loss: 0.3204203397035599\n",
            "Step 15492, Epoch 4/5, Loss: 0.3395332023501396\n",
            "Step 15496, Epoch 4/5, Loss: 0.36486033350229263\n",
            "Step 15500, Epoch 4/5, Loss: 0.3644515872001648\n",
            "Step 15504, Epoch 4/5, Loss: 0.22147411853075027\n",
            "Step 15508, Epoch 4/5, Loss: 0.2682515010237694\n",
            "Step 15512, Epoch 4/5, Loss: 0.31268422678112984\n",
            "Step 15516, Epoch 4/5, Loss: 0.36580467224121094\n",
            "Step 15520, Epoch 4/5, Loss: 0.4025705009698868\n",
            "Step 15524, Epoch 4/5, Loss: 0.4637897163629532\n",
            "Step 15528, Epoch 4/5, Loss: 0.41849318891763687\n",
            "Step 15532, Epoch 4/5, Loss: 0.34699125587940216\n",
            "Step 15536, Epoch 4/5, Loss: 0.2957896292209625\n",
            "Step 15540, Epoch 4/5, Loss: 0.38642996549606323\n",
            "Step 15544, Epoch 4/5, Loss: 0.3494217321276665\n",
            "Step 15548, Epoch 4/5, Loss: 0.41009100526571274\n",
            "Step 15552, Epoch 4/5, Loss: 0.4020436331629753\n",
            "Step 15556, Epoch 4/5, Loss: 0.2920212522149086\n",
            "Step 15560, Epoch 4/5, Loss: 0.3241330571472645\n",
            "Step 15564, Epoch 4/5, Loss: 0.400207556784153\n",
            "Step 15568, Epoch 4/5, Loss: 0.3563584089279175\n",
            "Step 15572, Epoch 4/5, Loss: 0.33840030059218407\n",
            "Step 15576, Epoch 4/5, Loss: 0.37793372943997383\n",
            "Step 15580, Epoch 4/5, Loss: 0.33372578769922256\n",
            "Step 15584, Epoch 4/5, Loss: 0.3679574579000473\n",
            "Step 15588, Epoch 4/5, Loss: 0.3022257015109062\n",
            "Step 15592, Epoch 4/5, Loss: 0.4070261940360069\n",
            "Step 15596, Epoch 4/5, Loss: 0.276216022670269\n",
            "Step 15600, Epoch 4/5, Loss: 0.32636531442403793\n",
            "Step 15604, Epoch 4/5, Loss: 0.28901393339037895\n",
            "Step 15608, Epoch 4/5, Loss: 0.3755591996014118\n",
            "Step 15612, Epoch 4/5, Loss: 0.38873039186000824\n",
            "Step 15616, Epoch 4/5, Loss: 0.40828684717416763\n",
            "Step 15620, Epoch 4/5, Loss: 0.2895793206989765\n",
            "Step 15624, Epoch 4/5, Loss: 0.2516564317047596\n",
            "Step 15628, Epoch 4/5, Loss: 0.24887259304523468\n",
            "Step 15632, Epoch 4/5, Loss: 0.3379334732890129\n",
            "Step 4, Epoch 5/5, Loss: 0.2625005394220352\n",
            "Step 8, Epoch 5/5, Loss: 0.2796621173620224\n",
            "Step 12, Epoch 5/5, Loss: 0.362451896071434\n",
            "Step 16, Epoch 5/5, Loss: 0.30765893310308456\n",
            "Step 20, Epoch 5/5, Loss: 0.36818648502230644\n",
            "Step 24, Epoch 5/5, Loss: 0.34347523376345634\n",
            "Step 28, Epoch 5/5, Loss: 0.2972041815519333\n",
            "Step 32, Epoch 5/5, Loss: 0.27701400965452194\n",
            "Step 36, Epoch 5/5, Loss: 0.34123458713293076\n",
            "Step 40, Epoch 5/5, Loss: 0.2996874041855335\n",
            "Step 44, Epoch 5/5, Loss: 0.3054898679256439\n",
            "Step 48, Epoch 5/5, Loss: 0.3368705064058304\n",
            "Step 52, Epoch 5/5, Loss: 0.28437497094273567\n",
            "Step 56, Epoch 5/5, Loss: 0.30874983593821526\n",
            "Step 60, Epoch 5/5, Loss: 0.3002081364393234\n",
            "Step 64, Epoch 5/5, Loss: 0.279951274394989\n",
            "Step 68, Epoch 5/5, Loss: 0.3202498219907284\n",
            "Step 72, Epoch 5/5, Loss: 0.37102095782756805\n",
            "Step 76, Epoch 5/5, Loss: 0.3800838589668274\n",
            "Step 80, Epoch 5/5, Loss: 0.27864570915699005\n",
            "Step 84, Epoch 5/5, Loss: 0.3407977223396301\n",
            "Step 88, Epoch 5/5, Loss: 0.26561540365219116\n",
            "Step 92, Epoch 5/5, Loss: 0.35446225106716156\n",
            "Step 96, Epoch 5/5, Loss: 0.32234618812799454\n",
            "Step 100, Epoch 5/5, Loss: 0.35390323773026466\n",
            "Step 104, Epoch 5/5, Loss: 0.2989651672542095\n",
            "Step 108, Epoch 5/5, Loss: 0.3475470468401909\n",
            "Step 112, Epoch 5/5, Loss: 0.35055824369192123\n",
            "Step 116, Epoch 5/5, Loss: 0.24581078812479973\n",
            "Step 120, Epoch 5/5, Loss: 0.2858918383717537\n",
            "Step 124, Epoch 5/5, Loss: 0.2857861742377281\n",
            "Step 128, Epoch 5/5, Loss: 0.3259127289056778\n",
            "Step 132, Epoch 5/5, Loss: 0.2771126478910446\n",
            "Step 136, Epoch 5/5, Loss: 0.3561582788825035\n",
            "Step 140, Epoch 5/5, Loss: 0.24446789547801018\n",
            "Step 144, Epoch 5/5, Loss: 0.33224309235811234\n",
            "Step 148, Epoch 5/5, Loss: 0.30659082904458046\n",
            "Step 152, Epoch 5/5, Loss: 0.3371749371290207\n",
            "Step 156, Epoch 5/5, Loss: 0.27621398866176605\n",
            "Step 160, Epoch 5/5, Loss: 0.2895994037389755\n",
            "Step 164, Epoch 5/5, Loss: 0.2813953272998333\n",
            "Step 168, Epoch 5/5, Loss: 0.3080391585826874\n",
            "Step 172, Epoch 5/5, Loss: 0.29572805389761925\n",
            "Step 176, Epoch 5/5, Loss: 0.24799079447984695\n",
            "Step 180, Epoch 5/5, Loss: 0.2913375534117222\n",
            "Step 184, Epoch 5/5, Loss: 0.33793918788433075\n",
            "Step 188, Epoch 5/5, Loss: 0.3352803699672222\n",
            "Step 192, Epoch 5/5, Loss: 0.2742193229496479\n",
            "Step 196, Epoch 5/5, Loss: 0.3517661467194557\n",
            "Step 200, Epoch 5/5, Loss: 0.3147030957043171\n",
            "Step 204, Epoch 5/5, Loss: 0.3147556968033314\n",
            "Step 208, Epoch 5/5, Loss: 0.26532768830657005\n",
            "Step 212, Epoch 5/5, Loss: 0.36126943677663803\n",
            "Step 216, Epoch 5/5, Loss: 0.34380438178777695\n",
            "Step 220, Epoch 5/5, Loss: 0.28724052757024765\n",
            "Step 224, Epoch 5/5, Loss: 0.30507782846689224\n",
            "Step 228, Epoch 5/5, Loss: 0.3536992743611336\n",
            "Step 232, Epoch 5/5, Loss: 0.33615052327513695\n",
            "Step 236, Epoch 5/5, Loss: 0.3695696219801903\n",
            "Step 240, Epoch 5/5, Loss: 0.3111230731010437\n",
            "Step 244, Epoch 5/5, Loss: 0.36579612642526627\n",
            "Step 248, Epoch 5/5, Loss: 0.27336061000823975\n",
            "Step 252, Epoch 5/5, Loss: 0.34561702981591225\n",
            "Step 256, Epoch 5/5, Loss: 0.3571288511157036\n",
            "Step 260, Epoch 5/5, Loss: 0.4072937145829201\n",
            "Step 264, Epoch 5/5, Loss: 0.24662284180521965\n",
            "Step 268, Epoch 5/5, Loss: 0.2734591141343117\n",
            "Step 272, Epoch 5/5, Loss: 0.3419737182557583\n",
            "Step 276, Epoch 5/5, Loss: 0.34077128395438194\n",
            "Step 280, Epoch 5/5, Loss: 0.34117957949638367\n",
            "Step 284, Epoch 5/5, Loss: 0.3067461587488651\n",
            "Step 288, Epoch 5/5, Loss: 0.3250579461455345\n",
            "Step 292, Epoch 5/5, Loss: 0.3022901564836502\n",
            "Step 296, Epoch 5/5, Loss: 0.3168409615755081\n",
            "Step 300, Epoch 5/5, Loss: 0.34964095056056976\n",
            "Step 304, Epoch 5/5, Loss: 0.3657638877630234\n",
            "Step 308, Epoch 5/5, Loss: 0.3210684135556221\n",
            "Step 312, Epoch 5/5, Loss: 0.3653602749109268\n",
            "Step 316, Epoch 5/5, Loss: 0.29072948917746544\n",
            "Step 320, Epoch 5/5, Loss: 0.25722210109233856\n",
            "Step 324, Epoch 5/5, Loss: 0.31442078948020935\n",
            "Step 328, Epoch 5/5, Loss: 0.25391723588109016\n",
            "Step 332, Epoch 5/5, Loss: 0.2991382107138634\n",
            "Step 336, Epoch 5/5, Loss: 0.4090743735432625\n",
            "Step 340, Epoch 5/5, Loss: 0.3007597178220749\n",
            "Step 344, Epoch 5/5, Loss: 0.2740492485463619\n",
            "Step 348, Epoch 5/5, Loss: 0.2801787331700325\n",
            "Step 352, Epoch 5/5, Loss: 0.3192168399691582\n",
            "Step 356, Epoch 5/5, Loss: 0.319985993206501\n",
            "Step 360, Epoch 5/5, Loss: 0.3282410800457001\n",
            "Step 364, Epoch 5/5, Loss: 0.2681788429617882\n",
            "Step 368, Epoch 5/5, Loss: 0.35505010932683945\n",
            "Step 372, Epoch 5/5, Loss: 0.20740889012813568\n",
            "Step 376, Epoch 5/5, Loss: 0.38225270062685013\n",
            "Step 380, Epoch 5/5, Loss: 0.40327462553977966\n",
            "Step 384, Epoch 5/5, Loss: 0.3407290652394295\n",
            "Step 388, Epoch 5/5, Loss: 0.2991788312792778\n",
            "Step 392, Epoch 5/5, Loss: 0.35180605947971344\n",
            "Step 396, Epoch 5/5, Loss: 0.29906756430864334\n",
            "Step 400, Epoch 5/5, Loss: 0.3361895903944969\n",
            "Step 404, Epoch 5/5, Loss: 0.3057805523276329\n",
            "Step 408, Epoch 5/5, Loss: 0.321983739733696\n",
            "Step 412, Epoch 5/5, Loss: 0.23376762866973877\n",
            "Step 416, Epoch 5/5, Loss: 0.3349306136369705\n",
            "Step 420, Epoch 5/5, Loss: 0.32820670679211617\n",
            "Step 424, Epoch 5/5, Loss: 0.3125406578183174\n",
            "Step 428, Epoch 5/5, Loss: 0.35716747492551804\n",
            "Step 432, Epoch 5/5, Loss: 0.32396797090768814\n",
            "Step 436, Epoch 5/5, Loss: 0.2942243441939354\n",
            "Step 440, Epoch 5/5, Loss: 0.30413559451699257\n",
            "Step 444, Epoch 5/5, Loss: 0.29362547770142555\n",
            "Step 448, Epoch 5/5, Loss: 0.34305161982774734\n",
            "Step 452, Epoch 5/5, Loss: 0.31500962749123573\n",
            "Step 456, Epoch 5/5, Loss: 0.3381032422184944\n",
            "Step 460, Epoch 5/5, Loss: 0.29273878037929535\n",
            "Step 464, Epoch 5/5, Loss: 0.3384070545434952\n",
            "Step 468, Epoch 5/5, Loss: 0.22250564396381378\n",
            "Step 472, Epoch 5/5, Loss: 0.309750072658062\n",
            "Step 476, Epoch 5/5, Loss: 0.3134286254644394\n",
            "Step 480, Epoch 5/5, Loss: 0.3360210284590721\n",
            "Step 484, Epoch 5/5, Loss: 0.3655788153409958\n",
            "Step 488, Epoch 5/5, Loss: 0.3589225746691227\n",
            "Step 492, Epoch 5/5, Loss: 0.35841815918684006\n",
            "Step 496, Epoch 5/5, Loss: 0.3880786597728729\n",
            "Step 500, Epoch 5/5, Loss: 0.27117040380835533\n",
            "Step 504, Epoch 5/5, Loss: 0.36346250772476196\n",
            "Step 508, Epoch 5/5, Loss: 0.3501823619008064\n",
            "Step 512, Epoch 5/5, Loss: 0.2788461893796921\n",
            "Step 516, Epoch 5/5, Loss: 0.287108588963747\n",
            "Step 520, Epoch 5/5, Loss: 0.2780892141163349\n",
            "Step 524, Epoch 5/5, Loss: 0.30401787906885147\n",
            "Step 528, Epoch 5/5, Loss: 0.3392648249864578\n",
            "Step 532, Epoch 5/5, Loss: 0.31472573429346085\n",
            "Step 536, Epoch 5/5, Loss: 0.32504013925790787\n",
            "Step 540, Epoch 5/5, Loss: 0.34874720126390457\n",
            "Step 544, Epoch 5/5, Loss: 0.3404058963060379\n",
            "Step 548, Epoch 5/5, Loss: 0.2767702117562294\n",
            "Step 552, Epoch 5/5, Loss: 0.2829999513924122\n",
            "Step 556, Epoch 5/5, Loss: 0.37016192078590393\n",
            "Step 560, Epoch 5/5, Loss: 0.29795166105031967\n",
            "Step 564, Epoch 5/5, Loss: 0.37065591663122177\n",
            "Step 568, Epoch 5/5, Loss: 0.3663400039076805\n",
            "Step 572, Epoch 5/5, Loss: 0.2868795208632946\n",
            "Step 576, Epoch 5/5, Loss: 0.334634967148304\n",
            "Step 580, Epoch 5/5, Loss: 0.36865121871232986\n",
            "Step 584, Epoch 5/5, Loss: 0.30697596818208694\n",
            "Step 588, Epoch 5/5, Loss: 0.37439387291669846\n",
            "Step 592, Epoch 5/5, Loss: 0.32643380761146545\n",
            "Step 596, Epoch 5/5, Loss: 0.31878170743584633\n",
            "Step 600, Epoch 5/5, Loss: 0.27334238588809967\n",
            "Step 604, Epoch 5/5, Loss: 0.33037491142749786\n",
            "Step 608, Epoch 5/5, Loss: 0.34805556386709213\n",
            "Step 612, Epoch 5/5, Loss: 0.3317325823009014\n",
            "Step 616, Epoch 5/5, Loss: 0.31075824052095413\n",
            "Step 620, Epoch 5/5, Loss: 0.29342006146907806\n",
            "Step 624, Epoch 5/5, Loss: 0.36342835426330566\n",
            "Step 628, Epoch 5/5, Loss: 0.28273872286081314\n",
            "Step 632, Epoch 5/5, Loss: 0.2715272456407547\n",
            "Step 636, Epoch 5/5, Loss: 0.37465012818574905\n",
            "Step 640, Epoch 5/5, Loss: 0.394982174038887\n",
            "Step 644, Epoch 5/5, Loss: 0.2799847945570946\n",
            "Step 648, Epoch 5/5, Loss: 0.31163768097758293\n",
            "Step 652, Epoch 5/5, Loss: 0.28637585788965225\n",
            "Step 656, Epoch 5/5, Loss: 0.3063933253288269\n",
            "Step 660, Epoch 5/5, Loss: 0.27891238406300545\n",
            "Step 664, Epoch 5/5, Loss: 0.29934658482670784\n",
            "Step 668, Epoch 5/5, Loss: 0.32709595561027527\n",
            "Step 672, Epoch 5/5, Loss: 0.32108594477176666\n",
            "Step 676, Epoch 5/5, Loss: 0.3747026100754738\n",
            "Step 680, Epoch 5/5, Loss: 0.2942100465297699\n",
            "Step 684, Epoch 5/5, Loss: 0.330282237380743\n",
            "Step 688, Epoch 5/5, Loss: 0.301281176507473\n",
            "Step 692, Epoch 5/5, Loss: 0.29090752825140953\n",
            "Step 696, Epoch 5/5, Loss: 0.3698618933558464\n",
            "Step 700, Epoch 5/5, Loss: 0.3795924261212349\n",
            "Step 704, Epoch 5/5, Loss: 0.3266921043395996\n",
            "Step 708, Epoch 5/5, Loss: 0.23298583179712296\n",
            "Step 712, Epoch 5/5, Loss: 0.2854575328528881\n",
            "Step 716, Epoch 5/5, Loss: 0.2740139998495579\n",
            "Step 720, Epoch 5/5, Loss: 0.2807876504957676\n",
            "Step 724, Epoch 5/5, Loss: 0.35958681255578995\n",
            "Step 728, Epoch 5/5, Loss: 0.38507241755723953\n",
            "Step 732, Epoch 5/5, Loss: 0.2638547085225582\n",
            "Step 736, Epoch 5/5, Loss: 0.29113794490695\n",
            "Step 740, Epoch 5/5, Loss: 0.34884013235569\n",
            "Step 744, Epoch 5/5, Loss: 0.2657172419130802\n",
            "Step 748, Epoch 5/5, Loss: 0.2988784797489643\n",
            "Step 752, Epoch 5/5, Loss: 0.3209760971367359\n",
            "Step 756, Epoch 5/5, Loss: 0.30825892090797424\n",
            "Step 760, Epoch 5/5, Loss: 0.3223532848060131\n",
            "Step 764, Epoch 5/5, Loss: 0.3294244445860386\n",
            "Step 768, Epoch 5/5, Loss: 0.29129959270358086\n",
            "Step 772, Epoch 5/5, Loss: 0.3184274546802044\n",
            "Step 776, Epoch 5/5, Loss: 0.31797922402620316\n",
            "Step 780, Epoch 5/5, Loss: 0.33389127627015114\n",
            "Step 784, Epoch 5/5, Loss: 0.33191099762916565\n",
            "Step 788, Epoch 5/5, Loss: 0.34438467025756836\n",
            "Step 792, Epoch 5/5, Loss: 0.32827065140008926\n",
            "Step 796, Epoch 5/5, Loss: 0.2974010556936264\n",
            "Step 800, Epoch 5/5, Loss: 0.2907269671559334\n",
            "Step 804, Epoch 5/5, Loss: 0.34802793338894844\n",
            "Step 808, Epoch 5/5, Loss: 0.3526423051953316\n",
            "Step 812, Epoch 5/5, Loss: 0.29152267053723335\n",
            "Step 816, Epoch 5/5, Loss: 0.2975528948009014\n",
            "Step 820, Epoch 5/5, Loss: 0.27653855830430984\n",
            "Step 824, Epoch 5/5, Loss: 0.3359452113509178\n",
            "Step 828, Epoch 5/5, Loss: 0.26577796041965485\n",
            "Step 832, Epoch 5/5, Loss: 0.2568247839808464\n",
            "Step 836, Epoch 5/5, Loss: 0.28905943781137466\n",
            "Step 840, Epoch 5/5, Loss: 0.3175966888666153\n",
            "Step 844, Epoch 5/5, Loss: 0.2354080080986023\n",
            "Step 848, Epoch 5/5, Loss: 0.2900063209235668\n",
            "Step 852, Epoch 5/5, Loss: 0.31586358696222305\n",
            "Step 856, Epoch 5/5, Loss: 0.27987832203507423\n",
            "Step 860, Epoch 5/5, Loss: 0.3089306764304638\n",
            "Step 864, Epoch 5/5, Loss: 0.31442953646183014\n",
            "Step 868, Epoch 5/5, Loss: 0.271883774548769\n",
            "Step 872, Epoch 5/5, Loss: 0.3969113156199455\n",
            "Step 876, Epoch 5/5, Loss: 0.33684585243463516\n",
            "Step 880, Epoch 5/5, Loss: 0.29797112941741943\n",
            "Step 884, Epoch 5/5, Loss: 0.30726324394345284\n",
            "Step 888, Epoch 5/5, Loss: 0.3421517461538315\n",
            "Step 892, Epoch 5/5, Loss: 0.3209613636136055\n",
            "Step 896, Epoch 5/5, Loss: 0.30297164991497993\n",
            "Step 900, Epoch 5/5, Loss: 0.3869843855500221\n",
            "Step 904, Epoch 5/5, Loss: 0.2844082713127136\n",
            "Step 908, Epoch 5/5, Loss: 0.29812614619731903\n",
            "Step 912, Epoch 5/5, Loss: 0.286869578063488\n",
            "Step 916, Epoch 5/5, Loss: 0.31454675644636154\n",
            "Step 920, Epoch 5/5, Loss: 0.3316769301891327\n",
            "Step 924, Epoch 5/5, Loss: 0.32916831225156784\n",
            "Step 928, Epoch 5/5, Loss: 0.3090035244822502\n",
            "Step 932, Epoch 5/5, Loss: 0.2908833250403404\n",
            "Step 936, Epoch 5/5, Loss: 0.2986610233783722\n",
            "Step 940, Epoch 5/5, Loss: 0.30146829038858414\n",
            "Step 944, Epoch 5/5, Loss: 0.2579484395682812\n",
            "Step 948, Epoch 5/5, Loss: 0.2966604344546795\n",
            "Step 952, Epoch 5/5, Loss: 0.28294603899121284\n",
            "Step 956, Epoch 5/5, Loss: 0.30273034423589706\n",
            "Step 960, Epoch 5/5, Loss: 0.26243747025728226\n",
            "Step 964, Epoch 5/5, Loss: 0.27531157806515694\n",
            "Step 968, Epoch 5/5, Loss: 0.36337073892354965\n",
            "Step 972, Epoch 5/5, Loss: 0.2836613357067108\n",
            "Step 976, Epoch 5/5, Loss: 0.36059022694826126\n",
            "Step 980, Epoch 5/5, Loss: 0.25165706500411034\n",
            "Step 984, Epoch 5/5, Loss: 0.3111580200493336\n",
            "Step 988, Epoch 5/5, Loss: 0.3459063656628132\n",
            "Step 992, Epoch 5/5, Loss: 0.34615955501794815\n",
            "Step 996, Epoch 5/5, Loss: 0.36526478454470634\n",
            "Step 1000, Epoch 5/5, Loss: 0.4022149480879307\n",
            "Step 1004, Epoch 5/5, Loss: 0.30023692920804024\n",
            "Step 1008, Epoch 5/5, Loss: 0.3902243301272392\n",
            "Step 1012, Epoch 5/5, Loss: 0.276607021689415\n",
            "Step 1016, Epoch 5/5, Loss: 0.3191192001104355\n",
            "Step 1020, Epoch 5/5, Loss: 0.3733864799141884\n",
            "Step 1024, Epoch 5/5, Loss: 0.29159722477197647\n",
            "Step 1028, Epoch 5/5, Loss: 0.2908264845609665\n",
            "Step 1032, Epoch 5/5, Loss: 0.3225477784872055\n",
            "Step 1036, Epoch 5/5, Loss: 0.32714227959513664\n",
            "Step 1040, Epoch 5/5, Loss: 0.26919037848711014\n",
            "Step 1044, Epoch 5/5, Loss: 0.3390779122710228\n",
            "Step 1048, Epoch 5/5, Loss: 0.2482614554464817\n",
            "Step 1052, Epoch 5/5, Loss: 0.28469347953796387\n",
            "Step 1056, Epoch 5/5, Loss: 0.40145543217658997\n",
            "Step 1060, Epoch 5/5, Loss: 0.34421638771891594\n",
            "Step 1064, Epoch 5/5, Loss: 0.26906925812363625\n",
            "Step 1068, Epoch 5/5, Loss: 0.4073408544063568\n",
            "Step 1072, Epoch 5/5, Loss: 0.29831988736987114\n",
            "Step 1076, Epoch 5/5, Loss: 0.2797723263502121\n",
            "Step 1080, Epoch 5/5, Loss: 0.34052587673068047\n",
            "Step 1084, Epoch 5/5, Loss: 0.2974501997232437\n",
            "Step 1088, Epoch 5/5, Loss: 0.3863818868994713\n",
            "Step 1092, Epoch 5/5, Loss: 0.2388325296342373\n",
            "Step 1096, Epoch 5/5, Loss: 0.34907930716872215\n",
            "Step 1100, Epoch 5/5, Loss: 0.3065325506031513\n",
            "Step 1104, Epoch 5/5, Loss: 0.361776702105999\n",
            "Step 1108, Epoch 5/5, Loss: 0.3405027501285076\n",
            "Step 1112, Epoch 5/5, Loss: 0.24628782272338867\n",
            "Step 1116, Epoch 5/5, Loss: 0.37873724848032\n",
            "Step 1120, Epoch 5/5, Loss: 0.23653381690382957\n",
            "Step 1124, Epoch 5/5, Loss: 0.3742997795343399\n",
            "Step 1128, Epoch 5/5, Loss: 0.2887495309114456\n",
            "Step 1132, Epoch 5/5, Loss: 0.2787068262696266\n",
            "Step 1136, Epoch 5/5, Loss: 0.374400295317173\n",
            "Step 1140, Epoch 5/5, Loss: 0.29406026005744934\n",
            "Step 1144, Epoch 5/5, Loss: 0.4006052240729332\n",
            "Step 1148, Epoch 5/5, Loss: 0.3505493104457855\n",
            "Step 1152, Epoch 5/5, Loss: 0.28644026815891266\n",
            "Step 1156, Epoch 5/5, Loss: 0.36962079256772995\n",
            "Step 1160, Epoch 5/5, Loss: 0.3744216337800026\n",
            "Step 1164, Epoch 5/5, Loss: 0.24024230614304543\n",
            "Step 1168, Epoch 5/5, Loss: 0.3716847598552704\n",
            "Step 1172, Epoch 5/5, Loss: 0.3865172192454338\n",
            "Step 1176, Epoch 5/5, Loss: 0.27414603903889656\n",
            "Step 1180, Epoch 5/5, Loss: 0.3082367777824402\n",
            "Step 1184, Epoch 5/5, Loss: 0.35895417630672455\n",
            "Step 1188, Epoch 5/5, Loss: 0.30977144092321396\n",
            "Step 1192, Epoch 5/5, Loss: 0.30167145654559135\n",
            "Step 1196, Epoch 5/5, Loss: 0.3024917095899582\n",
            "Step 1200, Epoch 5/5, Loss: 0.298122800886631\n",
            "Step 1204, Epoch 5/5, Loss: 0.3156699314713478\n",
            "Step 1208, Epoch 5/5, Loss: 0.35951605439186096\n",
            "Step 1212, Epoch 5/5, Loss: 0.35388053581118584\n",
            "Step 1216, Epoch 5/5, Loss: 0.2709493152797222\n",
            "Step 1220, Epoch 5/5, Loss: 0.3330034501850605\n",
            "Step 1224, Epoch 5/5, Loss: 0.3600209206342697\n",
            "Step 1228, Epoch 5/5, Loss: 0.3127462714910507\n",
            "Step 1232, Epoch 5/5, Loss: 0.26265429705381393\n",
            "Step 1236, Epoch 5/5, Loss: 0.32333799451589584\n",
            "Step 1240, Epoch 5/5, Loss: 0.26091402769088745\n",
            "Step 1244, Epoch 5/5, Loss: 0.2595336511731148\n",
            "Step 1248, Epoch 5/5, Loss: 0.3255956545472145\n",
            "Step 1252, Epoch 5/5, Loss: 0.34120694547891617\n",
            "Step 1256, Epoch 5/5, Loss: 0.2913426235318184\n",
            "Step 1260, Epoch 5/5, Loss: 0.3642556592822075\n",
            "Step 1264, Epoch 5/5, Loss: 0.3041551187634468\n",
            "Step 1268, Epoch 5/5, Loss: 0.34420906007289886\n",
            "Step 1272, Epoch 5/5, Loss: 0.2746407799422741\n",
            "Step 1276, Epoch 5/5, Loss: 0.3390014283359051\n",
            "Step 1280, Epoch 5/5, Loss: 0.34421201050281525\n",
            "Step 1284, Epoch 5/5, Loss: 0.28503861650824547\n",
            "Step 1288, Epoch 5/5, Loss: 0.3254777044057846\n",
            "Step 1292, Epoch 5/5, Loss: 0.282449372112751\n",
            "Step 1296, Epoch 5/5, Loss: 0.34925657510757446\n",
            "Step 1300, Epoch 5/5, Loss: 0.3366442993283272\n",
            "Step 1304, Epoch 5/5, Loss: 0.347364641726017\n",
            "Step 1308, Epoch 5/5, Loss: 0.3473336920142174\n",
            "Step 1312, Epoch 5/5, Loss: 0.35223689675331116\n",
            "Step 1316, Epoch 5/5, Loss: 0.3016773760318756\n",
            "Step 1320, Epoch 5/5, Loss: 0.3394855111837387\n",
            "Step 1324, Epoch 5/5, Loss: 0.28704261034727097\n",
            "Step 1328, Epoch 5/5, Loss: 0.4241800680756569\n",
            "Step 1332, Epoch 5/5, Loss: 0.32133983075618744\n",
            "Step 1336, Epoch 5/5, Loss: 0.3086816556751728\n",
            "Step 1340, Epoch 5/5, Loss: 0.32414353638887405\n",
            "Step 1344, Epoch 5/5, Loss: 0.29391833022236824\n",
            "Step 1348, Epoch 5/5, Loss: 0.2367459423840046\n",
            "Step 1352, Epoch 5/5, Loss: 0.292232695966959\n",
            "Step 1356, Epoch 5/5, Loss: 0.34867528080940247\n",
            "Step 1360, Epoch 5/5, Loss: 0.32933177798986435\n",
            "Step 1364, Epoch 5/5, Loss: 0.3336803764104843\n",
            "Step 1368, Epoch 5/5, Loss: 0.341531440615654\n",
            "Step 1372, Epoch 5/5, Loss: 0.32091281563043594\n",
            "Step 1376, Epoch 5/5, Loss: 0.338064968585968\n",
            "Step 1380, Epoch 5/5, Loss: 0.39452318102121353\n",
            "Step 1384, Epoch 5/5, Loss: 0.2624547556042671\n",
            "Step 1388, Epoch 5/5, Loss: 0.3243609443306923\n",
            "Step 1392, Epoch 5/5, Loss: 0.31618939340114594\n",
            "Step 1396, Epoch 5/5, Loss: 0.3051251322031021\n",
            "Step 1400, Epoch 5/5, Loss: 0.3523796610534191\n",
            "Step 1404, Epoch 5/5, Loss: 0.33129600435495377\n",
            "Step 1408, Epoch 5/5, Loss: 0.3316819630563259\n",
            "Step 1412, Epoch 5/5, Loss: 0.2708548419177532\n",
            "Step 1416, Epoch 5/5, Loss: 0.39245758578181267\n",
            "Step 1420, Epoch 5/5, Loss: 0.24930526688694954\n",
            "Step 1424, Epoch 5/5, Loss: 0.27802545577287674\n",
            "Step 1428, Epoch 5/5, Loss: 0.29821523278951645\n",
            "Step 1432, Epoch 5/5, Loss: 0.2987046614289284\n",
            "Step 1436, Epoch 5/5, Loss: 0.22442473471164703\n",
            "Step 1440, Epoch 5/5, Loss: 0.2978600561618805\n",
            "Step 1444, Epoch 5/5, Loss: 0.2893143780529499\n",
            "Step 1448, Epoch 5/5, Loss: 0.32491399720311165\n",
            "Step 1452, Epoch 5/5, Loss: 0.32141489535570145\n",
            "Step 1456, Epoch 5/5, Loss: 0.38145263493061066\n",
            "Step 1460, Epoch 5/5, Loss: 0.33141861110925674\n",
            "Step 1464, Epoch 5/5, Loss: 0.3974531218409538\n",
            "Step 1468, Epoch 5/5, Loss: 0.3700786828994751\n",
            "Step 1472, Epoch 5/5, Loss: 0.3090004250407219\n",
            "Step 1476, Epoch 5/5, Loss: 0.4057285636663437\n",
            "Step 1480, Epoch 5/5, Loss: 0.28678257018327713\n",
            "Step 1484, Epoch 5/5, Loss: 0.30713365972042084\n",
            "Step 1488, Epoch 5/5, Loss: 0.29261840134859085\n",
            "Step 1492, Epoch 5/5, Loss: 0.31628672033548355\n",
            "Step 1496, Epoch 5/5, Loss: 0.32335685938596725\n",
            "Step 1500, Epoch 5/5, Loss: 0.3047525882720947\n",
            "Step 1504, Epoch 5/5, Loss: 0.2225455678999424\n",
            "Step 1508, Epoch 5/5, Loss: 0.3492932766675949\n",
            "Step 1512, Epoch 5/5, Loss: 0.3605157732963562\n",
            "Step 1516, Epoch 5/5, Loss: 0.2680676765739918\n",
            "Step 1520, Epoch 5/5, Loss: 0.29117974638938904\n",
            "Step 1524, Epoch 5/5, Loss: 0.2854698784649372\n",
            "Step 1528, Epoch 5/5, Loss: 0.30994463711977005\n",
            "Step 1532, Epoch 5/5, Loss: 0.31976449117064476\n",
            "Step 1536, Epoch 5/5, Loss: 0.3442620597779751\n",
            "Step 1540, Epoch 5/5, Loss: 0.23265837505459785\n",
            "Step 1544, Epoch 5/5, Loss: 0.3007986694574356\n",
            "Step 1548, Epoch 5/5, Loss: 0.2962675578892231\n",
            "Step 1552, Epoch 5/5, Loss: 0.3666727878153324\n",
            "Step 1556, Epoch 5/5, Loss: 0.27992304041981697\n",
            "Step 1560, Epoch 5/5, Loss: 0.4144458770751953\n",
            "Step 1564, Epoch 5/5, Loss: 0.35369738936424255\n",
            "Step 1568, Epoch 5/5, Loss: 0.34002137929201126\n",
            "Step 1572, Epoch 5/5, Loss: 0.19472724944353104\n",
            "Step 1576, Epoch 5/5, Loss: 0.27861272171139717\n",
            "Step 1580, Epoch 5/5, Loss: 0.3180388882756233\n",
            "Step 1584, Epoch 5/5, Loss: 0.3424189053475857\n",
            "Step 1588, Epoch 5/5, Loss: 0.3504168167710304\n",
            "Step 1592, Epoch 5/5, Loss: 0.29480262100696564\n",
            "Step 1596, Epoch 5/5, Loss: 0.3047640770673752\n",
            "Step 1600, Epoch 5/5, Loss: 0.2523176111280918\n",
            "Step 1604, Epoch 5/5, Loss: 0.31080589443445206\n",
            "Step 1608, Epoch 5/5, Loss: 0.3036106526851654\n",
            "Step 1612, Epoch 5/5, Loss: 0.34871822968125343\n",
            "Step 1616, Epoch 5/5, Loss: 0.309915229678154\n",
            "Step 1620, Epoch 5/5, Loss: 0.29486071318387985\n",
            "Step 1624, Epoch 5/5, Loss: 0.35157598555088043\n",
            "Step 1628, Epoch 5/5, Loss: 0.32212333753705025\n",
            "Step 1632, Epoch 5/5, Loss: 0.2877640686929226\n",
            "Step 1636, Epoch 5/5, Loss: 0.39475684612989426\n",
            "Step 1640, Epoch 5/5, Loss: 0.29538168385624886\n",
            "Step 1644, Epoch 5/5, Loss: 0.35098836570978165\n",
            "Step 1648, Epoch 5/5, Loss: 0.3097384236752987\n",
            "Step 1652, Epoch 5/5, Loss: 0.2906724326312542\n",
            "Step 1656, Epoch 5/5, Loss: 0.35761161148548126\n",
            "Step 1660, Epoch 5/5, Loss: 0.3321552090346813\n",
            "Step 1664, Epoch 5/5, Loss: 0.24839097633957863\n",
            "Step 1668, Epoch 5/5, Loss: 0.3301354646682739\n",
            "Step 1672, Epoch 5/5, Loss: 0.31449144333601\n",
            "Step 1676, Epoch 5/5, Loss: 0.2928452789783478\n",
            "Step 1680, Epoch 5/5, Loss: 0.3639574646949768\n",
            "Step 1684, Epoch 5/5, Loss: 0.3911013677716255\n",
            "Step 1688, Epoch 5/5, Loss: 0.2576882876455784\n",
            "Step 1692, Epoch 5/5, Loss: 0.31485072895884514\n",
            "Step 1696, Epoch 5/5, Loss: 0.29259542003273964\n",
            "Step 1700, Epoch 5/5, Loss: 0.3918189965188503\n",
            "Step 1704, Epoch 5/5, Loss: 0.2488451786339283\n",
            "Step 1708, Epoch 5/5, Loss: 0.34589381515979767\n",
            "Step 1712, Epoch 5/5, Loss: 0.3102632611989975\n",
            "Step 1716, Epoch 5/5, Loss: 0.33661460131406784\n",
            "Step 1720, Epoch 5/5, Loss: 0.2786227837204933\n",
            "Step 1724, Epoch 5/5, Loss: 0.36756519228219986\n",
            "Step 1728, Epoch 5/5, Loss: 0.2830419987440109\n",
            "Step 1732, Epoch 5/5, Loss: 0.3133426606655121\n",
            "Step 1736, Epoch 5/5, Loss: 0.3599367216229439\n",
            "Step 1740, Epoch 5/5, Loss: 0.33095625787973404\n",
            "Step 1744, Epoch 5/5, Loss: 0.3095436692237854\n",
            "Step 1748, Epoch 5/5, Loss: 0.3600936830043793\n",
            "Step 1752, Epoch 5/5, Loss: 0.2853078283369541\n",
            "Step 1756, Epoch 5/5, Loss: 0.32342270016670227\n",
            "Step 1760, Epoch 5/5, Loss: 0.28321997821331024\n",
            "Step 1764, Epoch 5/5, Loss: 0.2617265395820141\n",
            "Step 1768, Epoch 5/5, Loss: 0.31479131057858467\n",
            "Step 1772, Epoch 5/5, Loss: 0.35088159888982773\n",
            "Step 1776, Epoch 5/5, Loss: 0.3271651305258274\n",
            "Step 1780, Epoch 5/5, Loss: 0.3812197893857956\n",
            "Step 1784, Epoch 5/5, Loss: 0.372233796864748\n",
            "Step 1788, Epoch 5/5, Loss: 0.2751037999987602\n",
            "Step 1792, Epoch 5/5, Loss: 0.32483965903520584\n",
            "Step 1796, Epoch 5/5, Loss: 0.3201075457036495\n",
            "Step 1800, Epoch 5/5, Loss: 0.30376577004790306\n",
            "Step 1804, Epoch 5/5, Loss: 0.3317016251385212\n",
            "Step 1808, Epoch 5/5, Loss: 0.3175835497677326\n",
            "Step 1812, Epoch 5/5, Loss: 0.36223628371953964\n",
            "Step 1816, Epoch 5/5, Loss: 0.352195605635643\n",
            "Step 1820, Epoch 5/5, Loss: 0.3308896869421005\n",
            "Step 1824, Epoch 5/5, Loss: 0.3757571056485176\n",
            "Step 1828, Epoch 5/5, Loss: 0.3468799665570259\n",
            "Step 1832, Epoch 5/5, Loss: 0.3028482012450695\n",
            "Step 1836, Epoch 5/5, Loss: 0.34813641756772995\n",
            "Step 1840, Epoch 5/5, Loss: 0.3145870566368103\n",
            "Step 1844, Epoch 5/5, Loss: 0.29448315501213074\n",
            "Step 1848, Epoch 5/5, Loss: 0.2578035555779934\n",
            "Step 1852, Epoch 5/5, Loss: 0.25960683077573776\n",
            "Step 1856, Epoch 5/5, Loss: 0.2770608067512512\n",
            "Step 1860, Epoch 5/5, Loss: 0.3625989556312561\n",
            "Step 1864, Epoch 5/5, Loss: 0.3155239596962929\n",
            "Step 1868, Epoch 5/5, Loss: 0.3919924199581146\n",
            "Step 1872, Epoch 5/5, Loss: 0.3523474782705307\n",
            "Step 1876, Epoch 5/5, Loss: 0.35842016339302063\n",
            "Step 1880, Epoch 5/5, Loss: 0.299722395837307\n",
            "Step 1884, Epoch 5/5, Loss: 0.3220721520483494\n",
            "Step 1888, Epoch 5/5, Loss: 0.3113408349454403\n",
            "Step 1892, Epoch 5/5, Loss: 0.3708808273077011\n",
            "Step 1896, Epoch 5/5, Loss: 0.35775966942310333\n",
            "Step 1900, Epoch 5/5, Loss: 0.3993748649954796\n",
            "Step 1904, Epoch 5/5, Loss: 0.2865118160843849\n",
            "Step 1908, Epoch 5/5, Loss: 0.3043539747595787\n",
            "Step 1912, Epoch 5/5, Loss: 0.20596028119325638\n",
            "Step 1916, Epoch 5/5, Loss: 0.3392784483730793\n",
            "Step 1920, Epoch 5/5, Loss: 0.32816480845212936\n",
            "Step 1924, Epoch 5/5, Loss: 0.3639810308814049\n",
            "Step 1928, Epoch 5/5, Loss: 0.3654172122478485\n",
            "Step 1932, Epoch 5/5, Loss: 0.2620309926569462\n",
            "Step 1936, Epoch 5/5, Loss: 0.2602618783712387\n",
            "Step 1940, Epoch 5/5, Loss: 0.2810468524694443\n",
            "Step 1944, Epoch 5/5, Loss: 0.2867085710167885\n",
            "Step 1948, Epoch 5/5, Loss: 0.35141339898109436\n",
            "Step 1952, Epoch 5/5, Loss: 0.2698369361460209\n",
            "Step 1956, Epoch 5/5, Loss: 0.296999778598547\n",
            "Step 1960, Epoch 5/5, Loss: 0.295481838285923\n",
            "Step 1964, Epoch 5/5, Loss: 0.3619993105530739\n",
            "Step 1968, Epoch 5/5, Loss: 0.34801480919122696\n",
            "Step 1972, Epoch 5/5, Loss: 0.3548985719680786\n",
            "Step 1976, Epoch 5/5, Loss: 0.34518105909228325\n",
            "Step 1980, Epoch 5/5, Loss: 0.27694520354270935\n",
            "Step 1984, Epoch 5/5, Loss: 0.3781547546386719\n",
            "Step 1988, Epoch 5/5, Loss: 0.22946635261178017\n",
            "Step 1992, Epoch 5/5, Loss: 0.25072548538446426\n",
            "Step 1996, Epoch 5/5, Loss: 0.25889740511775017\n",
            "Step 2000, Epoch 5/5, Loss: 0.32036711648106575\n",
            "Step 2004, Epoch 5/5, Loss: 0.315641313791275\n",
            "Step 2008, Epoch 5/5, Loss: 0.3060191720724106\n",
            "Step 2012, Epoch 5/5, Loss: 0.27247531712055206\n",
            "Step 2016, Epoch 5/5, Loss: 0.33652620762586594\n",
            "Step 2020, Epoch 5/5, Loss: 0.35758906602859497\n",
            "Step 2024, Epoch 5/5, Loss: 0.30876709520816803\n",
            "Step 2028, Epoch 5/5, Loss: 0.3280548118054867\n",
            "Step 2032, Epoch 5/5, Loss: 0.2884223610162735\n",
            "Step 2036, Epoch 5/5, Loss: 0.3293023183941841\n",
            "Step 2040, Epoch 5/5, Loss: 0.41862041503190994\n",
            "Step 2044, Epoch 5/5, Loss: 0.35700780898332596\n",
            "Step 2048, Epoch 5/5, Loss: 0.29178957268595695\n",
            "Step 2052, Epoch 5/5, Loss: 0.31057992577552795\n",
            "Step 2056, Epoch 5/5, Loss: 0.35931605845689774\n",
            "Step 2060, Epoch 5/5, Loss: 0.3107500448822975\n",
            "Step 2064, Epoch 5/5, Loss: 0.3192158639431\n",
            "Step 2068, Epoch 5/5, Loss: 0.3159998282790184\n",
            "Step 2072, Epoch 5/5, Loss: 0.3227592557668686\n",
            "Step 2076, Epoch 5/5, Loss: 0.23691590130329132\n",
            "Step 2080, Epoch 5/5, Loss: 0.3603066951036453\n",
            "Step 2084, Epoch 5/5, Loss: 0.3012194186449051\n",
            "Step 2088, Epoch 5/5, Loss: 0.2979995086789131\n",
            "Step 2092, Epoch 5/5, Loss: 0.2963188663125038\n",
            "Step 2096, Epoch 5/5, Loss: 0.34800928086042404\n",
            "Step 2100, Epoch 5/5, Loss: 0.2920881062746048\n",
            "Step 2104, Epoch 5/5, Loss: 0.3542395420372486\n",
            "Step 2108, Epoch 5/5, Loss: 0.32687221467494965\n",
            "Step 2112, Epoch 5/5, Loss: 0.3521547466516495\n",
            "Step 2116, Epoch 5/5, Loss: 0.2774065025150776\n",
            "Step 2120, Epoch 5/5, Loss: 0.35598819702863693\n",
            "Step 2124, Epoch 5/5, Loss: 0.3299906775355339\n",
            "Step 2128, Epoch 5/5, Loss: 0.2669866420328617\n",
            "Step 2132, Epoch 5/5, Loss: 0.35668641328811646\n",
            "Step 2136, Epoch 5/5, Loss: 0.350554883480072\n",
            "Step 2140, Epoch 5/5, Loss: 0.33839981257915497\n",
            "Step 2144, Epoch 5/5, Loss: 0.28802400827407837\n",
            "Step 2148, Epoch 5/5, Loss: 0.3515729531645775\n",
            "Step 2152, Epoch 5/5, Loss: 0.33490876853466034\n",
            "Step 2156, Epoch 5/5, Loss: 0.32645779848098755\n",
            "Step 2160, Epoch 5/5, Loss: 0.3791709132492542\n",
            "Step 2164, Epoch 5/5, Loss: 0.2885757014155388\n",
            "Step 2168, Epoch 5/5, Loss: 0.324037279933691\n",
            "Step 2172, Epoch 5/5, Loss: 0.3499350771307945\n",
            "Step 2176, Epoch 5/5, Loss: 0.3174353688955307\n",
            "Step 2180, Epoch 5/5, Loss: 0.3181336410343647\n",
            "Step 2184, Epoch 5/5, Loss: 0.2848881371319294\n",
            "Step 2188, Epoch 5/5, Loss: 0.3302048072218895\n",
            "Step 2192, Epoch 5/5, Loss: 0.34781888127326965\n",
            "Step 2196, Epoch 5/5, Loss: 0.34993263334035873\n",
            "Step 2200, Epoch 5/5, Loss: 0.3343089036643505\n",
            "Step 2204, Epoch 5/5, Loss: 0.3821016475558281\n",
            "Step 2208, Epoch 5/5, Loss: 0.3625664710998535\n",
            "Step 2212, Epoch 5/5, Loss: 0.3460287004709244\n",
            "Step 2216, Epoch 5/5, Loss: 0.2975468635559082\n",
            "Step 2220, Epoch 5/5, Loss: 0.3307884633541107\n",
            "Step 2224, Epoch 5/5, Loss: 0.33057547360658646\n",
            "Step 2228, Epoch 5/5, Loss: 0.3073209375143051\n",
            "Step 2232, Epoch 5/5, Loss: 0.37574585527181625\n",
            "Step 2236, Epoch 5/5, Loss: 0.3329601623117924\n",
            "Step 2240, Epoch 5/5, Loss: 0.3401954770088196\n",
            "Step 2244, Epoch 5/5, Loss: 0.2616031840443611\n",
            "Step 2248, Epoch 5/5, Loss: 0.32119763270020485\n",
            "Step 2252, Epoch 5/5, Loss: 0.27276160567998886\n",
            "Step 2256, Epoch 5/5, Loss: 0.31893353909254074\n",
            "Step 2260, Epoch 5/5, Loss: 0.2553224228322506\n",
            "Step 2264, Epoch 5/5, Loss: 0.3103179484605789\n",
            "Step 2268, Epoch 5/5, Loss: 0.3545638993382454\n",
            "Step 2272, Epoch 5/5, Loss: 0.30197394266724586\n",
            "Step 2276, Epoch 5/5, Loss: 0.27467772364616394\n",
            "Step 2280, Epoch 5/5, Loss: 0.3345304951071739\n",
            "Step 2284, Epoch 5/5, Loss: 0.23780585825443268\n",
            "Step 2288, Epoch 5/5, Loss: 0.30794715508818626\n",
            "Step 2292, Epoch 5/5, Loss: 0.3084840476512909\n",
            "Step 2296, Epoch 5/5, Loss: 0.3212679550051689\n",
            "Step 2300, Epoch 5/5, Loss: 0.3697703257203102\n",
            "Step 2304, Epoch 5/5, Loss: 0.25963692367076874\n",
            "Step 2308, Epoch 5/5, Loss: 0.35514652729034424\n",
            "Step 2312, Epoch 5/5, Loss: 0.4007645919919014\n",
            "Step 2316, Epoch 5/5, Loss: 0.32256725430488586\n",
            "Step 2320, Epoch 5/5, Loss: 0.3476182222366333\n",
            "Step 2324, Epoch 5/5, Loss: 0.30868666619062424\n",
            "Step 2328, Epoch 5/5, Loss: 0.26630282774567604\n",
            "Step 2332, Epoch 5/5, Loss: 0.3335517644882202\n",
            "Step 2336, Epoch 5/5, Loss: 0.3962820991873741\n",
            "Step 2340, Epoch 5/5, Loss: 0.2798793278634548\n",
            "Step 2344, Epoch 5/5, Loss: 0.3123692572116852\n",
            "Step 2348, Epoch 5/5, Loss: 0.2898123003542423\n",
            "Step 2352, Epoch 5/5, Loss: 0.3226338177919388\n",
            "Step 2356, Epoch 5/5, Loss: 0.24605974927544594\n",
            "Step 2360, Epoch 5/5, Loss: 0.3420026823878288\n",
            "Step 2364, Epoch 5/5, Loss: 0.2805190123617649\n",
            "Step 2368, Epoch 5/5, Loss: 0.2931838855147362\n",
            "Step 2372, Epoch 5/5, Loss: 0.26205163449048996\n",
            "Step 2376, Epoch 5/5, Loss: 0.33479761332273483\n",
            "Step 2380, Epoch 5/5, Loss: 0.324474822729826\n",
            "Step 2384, Epoch 5/5, Loss: 0.2811276912689209\n",
            "Step 2388, Epoch 5/5, Loss: 0.2945343479514122\n",
            "Step 2392, Epoch 5/5, Loss: 0.3563140369951725\n",
            "Step 2396, Epoch 5/5, Loss: 0.31182079017162323\n",
            "Step 2400, Epoch 5/5, Loss: 0.30973152443766594\n",
            "Step 2404, Epoch 5/5, Loss: 0.38950590789318085\n",
            "Step 2408, Epoch 5/5, Loss: 0.27694540470838547\n",
            "Step 2412, Epoch 5/5, Loss: 0.35813307762145996\n",
            "Step 2416, Epoch 5/5, Loss: 0.33714434877038\n",
            "Step 2420, Epoch 5/5, Loss: 0.3524087816476822\n",
            "Step 2424, Epoch 5/5, Loss: 0.3520434536039829\n",
            "Step 2428, Epoch 5/5, Loss: 0.28729215636849403\n",
            "Step 2432, Epoch 5/5, Loss: 0.2659515254199505\n",
            "Step 2436, Epoch 5/5, Loss: 0.3714258223772049\n",
            "Step 2440, Epoch 5/5, Loss: 0.4253353327512741\n",
            "Step 2444, Epoch 5/5, Loss: 0.26353900879621506\n",
            "Step 2448, Epoch 5/5, Loss: 0.3340442255139351\n",
            "Step 2452, Epoch 5/5, Loss: 0.2949104867875576\n",
            "Step 2456, Epoch 5/5, Loss: 0.46063192933797836\n",
            "Step 2460, Epoch 5/5, Loss: 0.31670719385147095\n",
            "Step 2464, Epoch 5/5, Loss: 0.36840643733739853\n",
            "Step 2468, Epoch 5/5, Loss: 0.2839641571044922\n",
            "Step 2472, Epoch 5/5, Loss: 0.29761600866913795\n",
            "Step 2476, Epoch 5/5, Loss: 0.29668644815683365\n",
            "Step 2480, Epoch 5/5, Loss: 0.34209658950567245\n",
            "Step 2484, Epoch 5/5, Loss: 0.4169335961341858\n",
            "Step 2488, Epoch 5/5, Loss: 0.3565703257918358\n",
            "Step 2492, Epoch 5/5, Loss: 0.29858384653925896\n",
            "Step 2496, Epoch 5/5, Loss: 0.2769431993365288\n",
            "Step 2500, Epoch 5/5, Loss: 0.3588474728167057\n",
            "Step 2504, Epoch 5/5, Loss: 0.3199327290058136\n",
            "Step 2508, Epoch 5/5, Loss: 0.37713368237018585\n",
            "Step 2512, Epoch 5/5, Loss: 0.31613415479660034\n",
            "Step 2516, Epoch 5/5, Loss: 0.3049851171672344\n",
            "Step 2520, Epoch 5/5, Loss: 0.3166397996246815\n",
            "Step 2524, Epoch 5/5, Loss: 0.29820576682686806\n",
            "Step 2528, Epoch 5/5, Loss: 0.3488868996500969\n",
            "Step 2532, Epoch 5/5, Loss: 0.30295126140117645\n",
            "Step 2536, Epoch 5/5, Loss: 0.36965474486351013\n",
            "Step 2540, Epoch 5/5, Loss: 0.33476497605443\n",
            "Step 2544, Epoch 5/5, Loss: 0.2931743897497654\n",
            "Step 2548, Epoch 5/5, Loss: 0.28813038021326065\n",
            "Step 2552, Epoch 5/5, Loss: 0.24284345284104347\n",
            "Step 2556, Epoch 5/5, Loss: 0.3595319353044033\n",
            "Step 2560, Epoch 5/5, Loss: 0.26806218549609184\n",
            "Step 2564, Epoch 5/5, Loss: 0.29408135265111923\n",
            "Step 2568, Epoch 5/5, Loss: 0.3114440478384495\n",
            "Step 2572, Epoch 5/5, Loss: 0.37033307552337646\n",
            "Step 2576, Epoch 5/5, Loss: 0.3404381051659584\n",
            "Step 2580, Epoch 5/5, Loss: 0.3221711367368698\n",
            "Step 2584, Epoch 5/5, Loss: 0.35688646510243416\n",
            "Step 2588, Epoch 5/5, Loss: 0.3029073625802994\n",
            "Step 2592, Epoch 5/5, Loss: 0.3127208389341831\n",
            "Step 2596, Epoch 5/5, Loss: 0.26279300451278687\n",
            "Step 2600, Epoch 5/5, Loss: 0.27711082249879837\n",
            "Step 2604, Epoch 5/5, Loss: 0.3729584813117981\n",
            "Step 2608, Epoch 5/5, Loss: 0.3255856856703758\n",
            "Step 2612, Epoch 5/5, Loss: 0.4295926094055176\n",
            "Step 2616, Epoch 5/5, Loss: 0.22836632654070854\n",
            "Step 2620, Epoch 5/5, Loss: 0.23972096294164658\n",
            "Step 2624, Epoch 5/5, Loss: 0.2791859731078148\n",
            "Step 2628, Epoch 5/5, Loss: 0.30312637612223625\n",
            "Step 2632, Epoch 5/5, Loss: 0.33569101989269257\n",
            "Step 2636, Epoch 5/5, Loss: 0.35726844519376755\n",
            "Step 2640, Epoch 5/5, Loss: 0.2582680322229862\n",
            "Step 2644, Epoch 5/5, Loss: 0.34870532527565956\n",
            "Step 2648, Epoch 5/5, Loss: 0.34647540003061295\n",
            "Step 2652, Epoch 5/5, Loss: 0.2857087589800358\n",
            "Step 2656, Epoch 5/5, Loss: 0.3667816296219826\n",
            "Step 2660, Epoch 5/5, Loss: 0.25432324409484863\n",
            "Step 2664, Epoch 5/5, Loss: 0.30561158433556557\n",
            "Step 2668, Epoch 5/5, Loss: 0.3377581685781479\n",
            "Step 2672, Epoch 5/5, Loss: 0.2896491549909115\n",
            "Step 2676, Epoch 5/5, Loss: 0.3187316991388798\n",
            "Step 2680, Epoch 5/5, Loss: 0.3389105275273323\n",
            "Step 2684, Epoch 5/5, Loss: 0.34550508111715317\n",
            "Step 2688, Epoch 5/5, Loss: 0.30476196855306625\n",
            "Step 2692, Epoch 5/5, Loss: 0.3151858188211918\n",
            "Step 2696, Epoch 5/5, Loss: 0.3884139880537987\n",
            "Step 2700, Epoch 5/5, Loss: 0.24750975891947746\n",
            "Step 2704, Epoch 5/5, Loss: 0.3812243118882179\n",
            "Step 2708, Epoch 5/5, Loss: 0.37435876578092575\n",
            "Step 2712, Epoch 5/5, Loss: 0.2830002047121525\n",
            "Step 2716, Epoch 5/5, Loss: 0.34895260632038116\n",
            "Step 2720, Epoch 5/5, Loss: 0.37317340075969696\n",
            "Step 2724, Epoch 5/5, Loss: 0.372374027967453\n",
            "Step 2728, Epoch 5/5, Loss: 0.33567114546895027\n",
            "Step 2732, Epoch 5/5, Loss: 0.39750394225120544\n",
            "Step 2736, Epoch 5/5, Loss: 0.3486291468143463\n",
            "Step 2740, Epoch 5/5, Loss: 0.2872252091765404\n",
            "Step 2744, Epoch 5/5, Loss: 0.3305486813187599\n",
            "Step 2748, Epoch 5/5, Loss: 0.26059340685606003\n",
            "Step 2752, Epoch 5/5, Loss: 0.32853246480226517\n",
            "Step 2756, Epoch 5/5, Loss: 0.3267076946794987\n",
            "Step 2760, Epoch 5/5, Loss: 0.35888200253248215\n",
            "Step 2764, Epoch 5/5, Loss: 0.4083511680364609\n",
            "Step 2768, Epoch 5/5, Loss: 0.35243774950504303\n",
            "Step 2772, Epoch 5/5, Loss: 0.30310600996017456\n",
            "Step 2776, Epoch 5/5, Loss: 0.38381268829107285\n",
            "Step 2780, Epoch 5/5, Loss: 0.3362915366888046\n",
            "Step 2784, Epoch 5/5, Loss: 0.3609441891312599\n",
            "Step 2788, Epoch 5/5, Loss: 0.35490817576646805\n",
            "Step 2792, Epoch 5/5, Loss: 0.30555402487516403\n",
            "Step 2796, Epoch 5/5, Loss: 0.3387465253472328\n",
            "Step 2800, Epoch 5/5, Loss: 0.34745755791664124\n",
            "Step 2804, Epoch 5/5, Loss: 0.2798793613910675\n",
            "Step 2808, Epoch 5/5, Loss: 0.2864902392029762\n",
            "Step 2812, Epoch 5/5, Loss: 0.3295505791902542\n",
            "Step 2816, Epoch 5/5, Loss: 0.3292202949523926\n",
            "Step 2820, Epoch 5/5, Loss: 0.40545809641480446\n",
            "Step 2824, Epoch 5/5, Loss: 0.32900379970669746\n",
            "Step 2828, Epoch 5/5, Loss: 0.33499135076999664\n",
            "Step 2832, Epoch 5/5, Loss: 0.3032248914241791\n",
            "Step 2836, Epoch 5/5, Loss: 0.3444557562470436\n",
            "Step 2840, Epoch 5/5, Loss: 0.32033466175198555\n",
            "Step 2844, Epoch 5/5, Loss: 0.32417111098766327\n",
            "Step 2848, Epoch 5/5, Loss: 0.3280486576259136\n",
            "Step 2852, Epoch 5/5, Loss: 0.3189710043370724\n",
            "Step 2856, Epoch 5/5, Loss: 0.37658510357141495\n",
            "Step 2860, Epoch 5/5, Loss: 0.29160645976662636\n",
            "Step 2864, Epoch 5/5, Loss: 0.3099955543875694\n",
            "Step 2868, Epoch 5/5, Loss: 0.35851170122623444\n",
            "Step 2872, Epoch 5/5, Loss: 0.3270447701215744\n",
            "Step 2876, Epoch 5/5, Loss: 0.37128181755542755\n",
            "Step 2880, Epoch 5/5, Loss: 0.324523001909256\n",
            "Step 2884, Epoch 5/5, Loss: 0.31557974964380264\n",
            "Step 2888, Epoch 5/5, Loss: 0.34733888506889343\n",
            "Step 2892, Epoch 5/5, Loss: 0.3208095096051693\n",
            "Step 2896, Epoch 5/5, Loss: 0.2846958115696907\n",
            "Step 2900, Epoch 5/5, Loss: 0.34973862767219543\n",
            "Step 2904, Epoch 5/5, Loss: 0.29012875631451607\n",
            "Step 2908, Epoch 5/5, Loss: 0.3402355685830116\n",
            "Step 2912, Epoch 5/5, Loss: 0.2903156131505966\n",
            "Step 2916, Epoch 5/5, Loss: 0.3381780534982681\n",
            "Step 2920, Epoch 5/5, Loss: 0.33163318410515785\n",
            "Step 2924, Epoch 5/5, Loss: 0.3213941156864166\n",
            "Step 2928, Epoch 5/5, Loss: 0.30211570858955383\n",
            "Step 2932, Epoch 5/5, Loss: 0.3245183452963829\n",
            "Step 2936, Epoch 5/5, Loss: 0.3669390082359314\n",
            "Step 2940, Epoch 5/5, Loss: 0.3091316446661949\n",
            "Step 2944, Epoch 5/5, Loss: 0.3201766386628151\n",
            "Step 2948, Epoch 5/5, Loss: 0.31956886500120163\n",
            "Step 2952, Epoch 5/5, Loss: 0.37665365636348724\n",
            "Step 2956, Epoch 5/5, Loss: 0.3157385624945164\n",
            "Step 2960, Epoch 5/5, Loss: 0.2749105617403984\n",
            "Step 2964, Epoch 5/5, Loss: 0.2993195839226246\n",
            "Step 2968, Epoch 5/5, Loss: 0.3042602762579918\n",
            "Step 2972, Epoch 5/5, Loss: 0.2745725028216839\n",
            "Step 2976, Epoch 5/5, Loss: 0.32761235535144806\n",
            "Step 2980, Epoch 5/5, Loss: 0.29220056533813477\n",
            "Step 2984, Epoch 5/5, Loss: 0.3779025599360466\n",
            "Step 2988, Epoch 5/5, Loss: 0.2587939351797104\n",
            "Step 2992, Epoch 5/5, Loss: 0.2598099522292614\n",
            "Step 2996, Epoch 5/5, Loss: 0.35622937232255936\n",
            "Step 3000, Epoch 5/5, Loss: 0.336364571005106\n",
            "Step 3004, Epoch 5/5, Loss: 0.3978514224290848\n",
            "Step 3008, Epoch 5/5, Loss: 0.30298736691474915\n",
            "Step 3012, Epoch 5/5, Loss: 0.2837136276066303\n",
            "Step 3016, Epoch 5/5, Loss: 0.3426762595772743\n",
            "Step 3020, Epoch 5/5, Loss: 0.31901686638593674\n",
            "Step 3024, Epoch 5/5, Loss: 0.3497271463274956\n",
            "Step 3028, Epoch 5/5, Loss: 0.3180728554725647\n",
            "Step 3032, Epoch 5/5, Loss: 0.31187818199396133\n",
            "Step 3036, Epoch 5/5, Loss: 0.31850138679146767\n",
            "Step 3040, Epoch 5/5, Loss: 0.3269294649362564\n",
            "Step 3044, Epoch 5/5, Loss: 0.3506505638360977\n",
            "Step 3048, Epoch 5/5, Loss: 0.325935285538435\n",
            "Step 3052, Epoch 5/5, Loss: 0.3311255946755409\n",
            "Step 3056, Epoch 5/5, Loss: 0.2854684218764305\n",
            "Step 3060, Epoch 5/5, Loss: 0.3233517147600651\n",
            "Step 3064, Epoch 5/5, Loss: 0.32967501878738403\n",
            "Step 3068, Epoch 5/5, Loss: 0.341285802423954\n",
            "Step 3072, Epoch 5/5, Loss: 0.25947561487555504\n",
            "Step 3076, Epoch 5/5, Loss: 0.31888286396861076\n",
            "Step 3080, Epoch 5/5, Loss: 0.2938349172472954\n",
            "Step 3084, Epoch 5/5, Loss: 0.299053180962801\n",
            "Step 3088, Epoch 5/5, Loss: 0.3456370420753956\n",
            "Step 3092, Epoch 5/5, Loss: 0.4004424437880516\n",
            "Step 3096, Epoch 5/5, Loss: 0.30715343728661537\n",
            "Step 3100, Epoch 5/5, Loss: 0.2898637168109417\n",
            "Step 3104, Epoch 5/5, Loss: 0.336404412984848\n",
            "Step 3108, Epoch 5/5, Loss: 0.34038447588682175\n",
            "Step 3112, Epoch 5/5, Loss: 0.3828887939453125\n",
            "Step 3116, Epoch 5/5, Loss: 0.3432034030556679\n",
            "Step 3120, Epoch 5/5, Loss: 0.3049590401351452\n",
            "Step 3124, Epoch 5/5, Loss: 0.3486732169985771\n",
            "Step 3128, Epoch 5/5, Loss: 0.37886639684438705\n",
            "Step 3132, Epoch 5/5, Loss: 0.27284911274909973\n",
            "Step 3136, Epoch 5/5, Loss: 0.3423890098929405\n",
            "Step 3140, Epoch 5/5, Loss: 0.33679474890232086\n",
            "Step 3144, Epoch 5/5, Loss: 0.28225230425596237\n",
            "Step 3148, Epoch 5/5, Loss: 0.34484153240919113\n",
            "Step 3152, Epoch 5/5, Loss: 0.3207429386675358\n",
            "Step 3156, Epoch 5/5, Loss: 0.2707185298204422\n",
            "Step 3160, Epoch 5/5, Loss: 0.2938213050365448\n",
            "Step 3164, Epoch 5/5, Loss: 0.2959025055170059\n",
            "Step 3168, Epoch 5/5, Loss: 0.31666211038827896\n",
            "Step 3172, Epoch 5/5, Loss: 0.295407772064209\n",
            "Step 3176, Epoch 5/5, Loss: 0.29690491780638695\n",
            "Step 3180, Epoch 5/5, Loss: 0.38127458840608597\n",
            "Step 3184, Epoch 5/5, Loss: 0.2693609222769737\n",
            "Step 3188, Epoch 5/5, Loss: 0.3305629566311836\n",
            "Step 3192, Epoch 5/5, Loss: 0.2800312004983425\n",
            "Step 3196, Epoch 5/5, Loss: 0.31689978763461113\n",
            "Step 3200, Epoch 5/5, Loss: 0.32033826783299446\n",
            "Step 3204, Epoch 5/5, Loss: 0.2998559772968292\n",
            "Step 3208, Epoch 5/5, Loss: 0.2719368636608124\n",
            "Step 3212, Epoch 5/5, Loss: 0.3386661931872368\n",
            "Step 3216, Epoch 5/5, Loss: 0.31685592606663704\n",
            "Step 3220, Epoch 5/5, Loss: 0.2863078713417053\n",
            "Step 3224, Epoch 5/5, Loss: 0.3390916660428047\n",
            "Step 3228, Epoch 5/5, Loss: 0.32422755286097527\n",
            "Step 3232, Epoch 5/5, Loss: 0.28617341816425323\n",
            "Step 3236, Epoch 5/5, Loss: 0.3114497810602188\n",
            "Step 3240, Epoch 5/5, Loss: 0.3189108669757843\n",
            "Step 3244, Epoch 5/5, Loss: 0.39442215859889984\n",
            "Step 3248, Epoch 5/5, Loss: 0.38149647042155266\n",
            "Step 3252, Epoch 5/5, Loss: 0.357216976583004\n",
            "Step 3256, Epoch 5/5, Loss: 0.32386231422424316\n",
            "Step 3260, Epoch 5/5, Loss: 0.26634606346488\n",
            "Step 3264, Epoch 5/5, Loss: 0.29281722754240036\n",
            "Step 3268, Epoch 5/5, Loss: 0.2987575940787792\n",
            "Step 3272, Epoch 5/5, Loss: 0.3300679922103882\n",
            "Step 3276, Epoch 5/5, Loss: 0.2969466373324394\n",
            "Step 3280, Epoch 5/5, Loss: 0.33871686086058617\n",
            "Step 3284, Epoch 5/5, Loss: 0.2984169088304043\n",
            "Step 3288, Epoch 5/5, Loss: 0.37980444729328156\n",
            "Step 3292, Epoch 5/5, Loss: 0.3745962157845497\n",
            "Step 3296, Epoch 5/5, Loss: 0.3372547775506973\n",
            "Step 3300, Epoch 5/5, Loss: 0.33532584086060524\n",
            "Step 3304, Epoch 5/5, Loss: 0.32320577651262283\n",
            "Step 3308, Epoch 5/5, Loss: 0.34687884896993637\n",
            "Step 3312, Epoch 5/5, Loss: 0.26738517731428146\n",
            "Step 3316, Epoch 5/5, Loss: 0.27294186130166054\n",
            "Step 3320, Epoch 5/5, Loss: 0.33898527175188065\n",
            "Step 3324, Epoch 5/5, Loss: 0.325021393597126\n",
            "Step 3328, Epoch 5/5, Loss: 0.27091189846396446\n",
            "Step 3332, Epoch 5/5, Loss: 0.3280843049287796\n",
            "Step 3336, Epoch 5/5, Loss: 0.32973363250494003\n",
            "Step 3340, Epoch 5/5, Loss: 0.32573843374848366\n",
            "Step 3344, Epoch 5/5, Loss: 0.2858858145773411\n",
            "Step 3348, Epoch 5/5, Loss: 0.31727561727166176\n",
            "Step 3352, Epoch 5/5, Loss: 0.3001874089241028\n",
            "Step 3356, Epoch 5/5, Loss: 0.39464806765317917\n",
            "Step 3360, Epoch 5/5, Loss: 0.2543861009180546\n",
            "Step 3364, Epoch 5/5, Loss: 0.31621314585208893\n",
            "Step 3368, Epoch 5/5, Loss: 0.32865801453590393\n",
            "Step 3372, Epoch 5/5, Loss: 0.3488791957497597\n",
            "Step 3376, Epoch 5/5, Loss: 0.3594598062336445\n",
            "Step 3380, Epoch 5/5, Loss: 0.3841232806444168\n",
            "Step 3384, Epoch 5/5, Loss: 0.403493233025074\n",
            "Step 3388, Epoch 5/5, Loss: 0.30405374243855476\n",
            "Step 3392, Epoch 5/5, Loss: 0.33497443050146103\n",
            "Step 3396, Epoch 5/5, Loss: 0.34140919148921967\n",
            "Step 3400, Epoch 5/5, Loss: 0.36775217205286026\n",
            "Step 3404, Epoch 5/5, Loss: 0.2846153452992439\n",
            "Step 3408, Epoch 5/5, Loss: 0.29849807918071747\n",
            "Step 3412, Epoch 5/5, Loss: 0.34321998432278633\n",
            "Step 3416, Epoch 5/5, Loss: 0.3478439636528492\n",
            "Step 3420, Epoch 5/5, Loss: 0.36281323432922363\n",
            "Step 3424, Epoch 5/5, Loss: 0.26964380592107773\n",
            "Step 3428, Epoch 5/5, Loss: 0.302724190056324\n",
            "Step 3432, Epoch 5/5, Loss: 0.32017137855291367\n",
            "Step 3436, Epoch 5/5, Loss: 0.34283018112182617\n",
            "Step 3440, Epoch 5/5, Loss: 0.3926684632897377\n",
            "Step 3444, Epoch 5/5, Loss: 0.3360176831483841\n",
            "Step 3448, Epoch 5/5, Loss: 0.35369791090488434\n",
            "Step 3452, Epoch 5/5, Loss: 0.333780013024807\n",
            "Step 3456, Epoch 5/5, Loss: 0.34653907641768456\n",
            "Step 3460, Epoch 5/5, Loss: 0.3111191838979721\n",
            "Step 3464, Epoch 5/5, Loss: 0.2821286916732788\n",
            "Step 3468, Epoch 5/5, Loss: 0.2838010713458061\n",
            "Step 3472, Epoch 5/5, Loss: 0.38355356454849243\n",
            "Step 3476, Epoch 5/5, Loss: 0.36316289752721786\n",
            "Step 3480, Epoch 5/5, Loss: 0.27686183899641037\n",
            "Step 3484, Epoch 5/5, Loss: 0.3715990036725998\n",
            "Step 3488, Epoch 5/5, Loss: 0.2824828624725342\n",
            "Step 3492, Epoch 5/5, Loss: 0.3385821729898453\n",
            "Step 3496, Epoch 5/5, Loss: 0.41599272936582565\n",
            "Step 3500, Epoch 5/5, Loss: 0.32376323640346527\n",
            "Step 3504, Epoch 5/5, Loss: 0.3290345072746277\n",
            "Step 3508, Epoch 5/5, Loss: 0.3587799444794655\n",
            "Step 3512, Epoch 5/5, Loss: 0.2926892973482609\n",
            "Step 3516, Epoch 5/5, Loss: 0.27600113302469254\n",
            "Step 3520, Epoch 5/5, Loss: 0.29637688398361206\n",
            "Step 3524, Epoch 5/5, Loss: 0.33380720019340515\n",
            "Step 3528, Epoch 5/5, Loss: 0.31898392736911774\n",
            "Step 3532, Epoch 5/5, Loss: 0.2873428612947464\n",
            "Step 3536, Epoch 5/5, Loss: 0.34292442351579666\n",
            "Step 3540, Epoch 5/5, Loss: 0.31159238517284393\n",
            "Step 3544, Epoch 5/5, Loss: 0.2862852215766907\n",
            "Step 3548, Epoch 5/5, Loss: 0.3314962387084961\n",
            "Step 3552, Epoch 5/5, Loss: 0.40339504182338715\n",
            "Step 3556, Epoch 5/5, Loss: 0.3434249609708786\n",
            "Step 3560, Epoch 5/5, Loss: 0.36897025257349014\n",
            "Step 3564, Epoch 5/5, Loss: 0.3547745421528816\n",
            "Step 3568, Epoch 5/5, Loss: 0.3804031163454056\n",
            "Step 3572, Epoch 5/5, Loss: 0.28001971542835236\n",
            "Step 3576, Epoch 5/5, Loss: 0.33468759804964066\n",
            "Step 3580, Epoch 5/5, Loss: 0.3087698742747307\n",
            "Step 3584, Epoch 5/5, Loss: 0.3110351711511612\n",
            "Step 3588, Epoch 5/5, Loss: 0.31417225301265717\n",
            "Step 3592, Epoch 5/5, Loss: 0.33599940687417984\n",
            "Step 3596, Epoch 5/5, Loss: 0.3338450789451599\n",
            "Step 3600, Epoch 5/5, Loss: 0.33545342832803726\n",
            "Step 3604, Epoch 5/5, Loss: 0.30519163981080055\n",
            "Step 3608, Epoch 5/5, Loss: 0.2662326954305172\n",
            "Step 3612, Epoch 5/5, Loss: 0.3288321681320667\n",
            "Step 3616, Epoch 5/5, Loss: 0.35647372156381607\n",
            "Step 3620, Epoch 5/5, Loss: 0.32778385281562805\n",
            "Step 3624, Epoch 5/5, Loss: 0.3111730143427849\n",
            "Step 3628, Epoch 5/5, Loss: 0.33741846680641174\n",
            "Step 3632, Epoch 5/5, Loss: 0.25298816338181496\n",
            "Step 3636, Epoch 5/5, Loss: 0.36968761682510376\n",
            "Step 3640, Epoch 5/5, Loss: 0.3146444000303745\n",
            "Step 3644, Epoch 5/5, Loss: 0.40542424470186234\n",
            "Step 3648, Epoch 5/5, Loss: 0.3967093825340271\n",
            "Step 3652, Epoch 5/5, Loss: 0.35574210807681084\n",
            "Step 3656, Epoch 5/5, Loss: 0.3416736051440239\n",
            "Step 3660, Epoch 5/5, Loss: 0.3294311761856079\n",
            "Step 3664, Epoch 5/5, Loss: 0.2794879414141178\n",
            "Step 3668, Epoch 5/5, Loss: 0.3130219802260399\n",
            "Step 3672, Epoch 5/5, Loss: 0.36260873824357986\n",
            "Step 3676, Epoch 5/5, Loss: 0.33540163934230804\n",
            "Step 3680, Epoch 5/5, Loss: 0.3209850713610649\n",
            "Step 3684, Epoch 5/5, Loss: 0.31227127090096474\n",
            "Step 3688, Epoch 5/5, Loss: 0.30237865075469017\n",
            "Step 3692, Epoch 5/5, Loss: 0.3416624441742897\n",
            "Step 3696, Epoch 5/5, Loss: 0.3278169482946396\n",
            "Step 3700, Epoch 5/5, Loss: 0.27538764104247093\n",
            "Step 3704, Epoch 5/5, Loss: 0.26227328926324844\n",
            "Step 3708, Epoch 5/5, Loss: 0.29119643941521645\n",
            "Step 3712, Epoch 5/5, Loss: 0.36154578626155853\n",
            "Step 3716, Epoch 5/5, Loss: 0.254737701267004\n",
            "Step 3720, Epoch 5/5, Loss: 0.3159491755068302\n",
            "Step 3724, Epoch 5/5, Loss: 0.32940711081027985\n",
            "Step 3728, Epoch 5/5, Loss: 0.3830735608935356\n",
            "Step 3732, Epoch 5/5, Loss: 0.3239879086613655\n",
            "Step 3736, Epoch 5/5, Loss: 0.3392355889081955\n",
            "Step 3740, Epoch 5/5, Loss: 0.29092617332935333\n",
            "Step 3744, Epoch 5/5, Loss: 0.30422940850257874\n",
            "Step 3748, Epoch 5/5, Loss: 0.2752969078719616\n",
            "Step 3752, Epoch 5/5, Loss: 0.3412434905767441\n",
            "Step 3756, Epoch 5/5, Loss: 0.35420313477516174\n",
            "Step 3760, Epoch 5/5, Loss: 0.35184072330594063\n",
            "Step 3764, Epoch 5/5, Loss: 0.31193074211478233\n",
            "Step 3768, Epoch 5/5, Loss: 0.3570930063724518\n",
            "Step 3772, Epoch 5/5, Loss: 0.32271799072623253\n",
            "Step 3776, Epoch 5/5, Loss: 0.24196195974946022\n",
            "Step 3780, Epoch 5/5, Loss: 0.2614049017429352\n",
            "Step 3784, Epoch 5/5, Loss: 0.3520672097802162\n",
            "Step 3788, Epoch 5/5, Loss: 0.24845610186457634\n",
            "Step 3792, Epoch 5/5, Loss: 0.384466290473938\n",
            "Step 3796, Epoch 5/5, Loss: 0.26426899805665016\n",
            "Step 3800, Epoch 5/5, Loss: 0.3274640887975693\n",
            "Step 3804, Epoch 5/5, Loss: 0.2932886779308319\n",
            "Step 3808, Epoch 5/5, Loss: 0.2909724712371826\n",
            "Step 3812, Epoch 5/5, Loss: 0.34012532234191895\n",
            "Step 3816, Epoch 5/5, Loss: 0.27320721372962\n",
            "Step 3820, Epoch 5/5, Loss: 0.44112253934144974\n",
            "Step 3824, Epoch 5/5, Loss: 0.28025104850530624\n",
            "Step 3828, Epoch 5/5, Loss: 0.3277006521821022\n",
            "Step 3832, Epoch 5/5, Loss: 0.2700803652405739\n",
            "Step 3836, Epoch 5/5, Loss: 0.3376931846141815\n",
            "Step 3840, Epoch 5/5, Loss: 0.372469961643219\n",
            "Step 3844, Epoch 5/5, Loss: 0.3568344861268997\n",
            "Step 3848, Epoch 5/5, Loss: 0.3271525129675865\n",
            "Step 3852, Epoch 5/5, Loss: 0.33399544283747673\n",
            "Step 3856, Epoch 5/5, Loss: 0.3312901519238949\n",
            "Step 3860, Epoch 5/5, Loss: 0.3292830064892769\n",
            "Step 3864, Epoch 5/5, Loss: 0.2749971114099026\n",
            "Step 3868, Epoch 5/5, Loss: 0.3180815130472183\n",
            "Step 3872, Epoch 5/5, Loss: 0.3370472863316536\n",
            "Step 3876, Epoch 5/5, Loss: 0.32235509529709816\n",
            "Step 3880, Epoch 5/5, Loss: 0.30110880732536316\n",
            "Step 3884, Epoch 5/5, Loss: 0.2809077873826027\n",
            "Step 3888, Epoch 5/5, Loss: 0.36658113449811935\n",
            "Step 3892, Epoch 5/5, Loss: 0.2793049290776253\n",
            "Step 3896, Epoch 5/5, Loss: 0.3025371581315994\n",
            "Step 3900, Epoch 5/5, Loss: 0.35495635122060776\n",
            "Step 3904, Epoch 5/5, Loss: 0.295316182076931\n",
            "Step 3908, Epoch 5/5, Loss: 0.31686993315815926\n",
            "Step 3912, Epoch 5/5, Loss: 0.2820979952812195\n",
            "Step 3916, Epoch 5/5, Loss: 0.35915226489305496\n",
            "Step 3920, Epoch 5/5, Loss: 0.32973067462444305\n",
            "Step 3924, Epoch 5/5, Loss: 0.3474205881357193\n",
            "Step 3928, Epoch 5/5, Loss: 0.2801593765616417\n",
            "Step 3932, Epoch 5/5, Loss: 0.3233824744820595\n",
            "Step 3936, Epoch 5/5, Loss: 0.2949737496674061\n",
            "Step 3940, Epoch 5/5, Loss: 0.35943643003702164\n",
            "Step 3944, Epoch 5/5, Loss: 0.30015750974416733\n",
            "Step 3948, Epoch 5/5, Loss: 0.3601214811205864\n",
            "Step 3952, Epoch 5/5, Loss: 0.3180338069796562\n",
            "Step 3956, Epoch 5/5, Loss: 0.30682477727532387\n",
            "Step 3960, Epoch 5/5, Loss: 0.3064226806163788\n",
            "Step 3964, Epoch 5/5, Loss: 0.3457022160291672\n",
            "Step 3968, Epoch 5/5, Loss: 0.3557206094264984\n",
            "Step 3972, Epoch 5/5, Loss: 0.30724263191223145\n",
            "Step 3976, Epoch 5/5, Loss: 0.2812103256583214\n",
            "Step 3980, Epoch 5/5, Loss: 0.3213285207748413\n",
            "Step 3984, Epoch 5/5, Loss: 0.3800530582666397\n",
            "Step 3988, Epoch 5/5, Loss: 0.31066595390439034\n",
            "Step 3992, Epoch 5/5, Loss: 0.37645287066698074\n",
            "Step 3996, Epoch 5/5, Loss: 0.3564685359597206\n",
            "Step 4000, Epoch 5/5, Loss: 0.3376106694340706\n",
            "Step 4004, Epoch 5/5, Loss: 0.34711817651987076\n",
            "Step 4008, Epoch 5/5, Loss: 0.34727664291858673\n",
            "Step 4012, Epoch 5/5, Loss: 0.35136493667960167\n",
            "Step 4016, Epoch 5/5, Loss: 0.2701009660959244\n",
            "Step 4020, Epoch 5/5, Loss: 0.3040158599615097\n",
            "Step 4024, Epoch 5/5, Loss: 0.3340005874633789\n",
            "Step 4028, Epoch 5/5, Loss: 0.31595826894044876\n",
            "Step 4032, Epoch 5/5, Loss: 0.3364628106355667\n",
            "Step 4036, Epoch 5/5, Loss: 0.3167763352394104\n",
            "Step 4040, Epoch 5/5, Loss: 0.3236510902643204\n",
            "Step 4044, Epoch 5/5, Loss: 0.37309812754392624\n",
            "Step 4048, Epoch 5/5, Loss: 0.34703560918569565\n",
            "Step 4052, Epoch 5/5, Loss: 0.3789277411997318\n",
            "Step 4056, Epoch 5/5, Loss: 0.3487539738416672\n",
            "Step 4060, Epoch 5/5, Loss: 0.2820834331214428\n",
            "Step 4064, Epoch 5/5, Loss: 0.3286169245839119\n",
            "Step 4068, Epoch 5/5, Loss: 0.432537704706192\n",
            "Step 4072, Epoch 5/5, Loss: 0.3618900924921036\n",
            "Step 4076, Epoch 5/5, Loss: 0.2968486435711384\n",
            "Step 4080, Epoch 5/5, Loss: 0.28561827540397644\n",
            "Step 4084, Epoch 5/5, Loss: 0.34009306132793427\n",
            "Step 4088, Epoch 5/5, Loss: 0.3363417610526085\n",
            "Step 4092, Epoch 5/5, Loss: 0.2631321921944618\n",
            "Step 4096, Epoch 5/5, Loss: 0.3757671192288399\n",
            "Step 4100, Epoch 5/5, Loss: 0.33926834911108017\n",
            "Step 4104, Epoch 5/5, Loss: 0.31943224370479584\n",
            "Step 4108, Epoch 5/5, Loss: 0.25691676139831543\n",
            "Step 4112, Epoch 5/5, Loss: 0.3476901724934578\n",
            "Step 4116, Epoch 5/5, Loss: 0.3517647050321102\n",
            "Step 4120, Epoch 5/5, Loss: 0.2570679038763046\n",
            "Step 4124, Epoch 5/5, Loss: 0.356807142496109\n",
            "Step 4128, Epoch 5/5, Loss: 0.3109204098582268\n",
            "Step 4132, Epoch 5/5, Loss: 0.3582284599542618\n",
            "Step 4136, Epoch 5/5, Loss: 0.31348108127713203\n",
            "Step 4140, Epoch 5/5, Loss: 0.2813778668642044\n",
            "Step 4144, Epoch 5/5, Loss: 0.347815316170454\n",
            "Step 4148, Epoch 5/5, Loss: 0.3489235080778599\n",
            "Step 4152, Epoch 5/5, Loss: 0.372833214700222\n",
            "Step 4156, Epoch 5/5, Loss: 0.2784975655376911\n",
            "Step 4160, Epoch 5/5, Loss: 0.29787974432110786\n",
            "Step 4164, Epoch 5/5, Loss: 0.30766311287879944\n",
            "Step 4168, Epoch 5/5, Loss: 0.3769071027636528\n",
            "Step 4172, Epoch 5/5, Loss: 0.268539123237133\n",
            "Step 4176, Epoch 5/5, Loss: 0.3278348818421364\n",
            "Step 4180, Epoch 5/5, Loss: 0.32698576897382736\n",
            "Step 4184, Epoch 5/5, Loss: 0.3668402135372162\n",
            "Step 4188, Epoch 5/5, Loss: 0.2973099760711193\n",
            "Step 4192, Epoch 5/5, Loss: 0.308596458286047\n",
            "Step 4196, Epoch 5/5, Loss: 0.31377502530813217\n",
            "Step 4200, Epoch 5/5, Loss: 0.38457686826586723\n",
            "Step 4204, Epoch 5/5, Loss: 0.3591291829943657\n",
            "Step 4208, Epoch 5/5, Loss: 0.304905753582716\n",
            "Step 4212, Epoch 5/5, Loss: 0.3001669682562351\n",
            "Step 4216, Epoch 5/5, Loss: 0.31065669655799866\n",
            "Step 4220, Epoch 5/5, Loss: 0.3730832263827324\n",
            "Step 4224, Epoch 5/5, Loss: 0.2579702101647854\n",
            "Step 4228, Epoch 5/5, Loss: 0.30743027478456497\n",
            "Step 4232, Epoch 5/5, Loss: 0.3274357244372368\n",
            "Step 4236, Epoch 5/5, Loss: 0.3425702191889286\n",
            "Step 4240, Epoch 5/5, Loss: 0.3569094240665436\n",
            "Step 4244, Epoch 5/5, Loss: 0.3465128690004349\n",
            "Step 4248, Epoch 5/5, Loss: 0.2994302175939083\n",
            "Step 4252, Epoch 5/5, Loss: 0.3647448644042015\n",
            "Step 4256, Epoch 5/5, Loss: 0.3487526550889015\n",
            "Step 4260, Epoch 5/5, Loss: 0.32986076548695564\n",
            "Step 4264, Epoch 5/5, Loss: 0.3180846646428108\n",
            "Step 4268, Epoch 5/5, Loss: 0.30347537621855736\n",
            "Step 4272, Epoch 5/5, Loss: 0.3872121125459671\n",
            "Step 4276, Epoch 5/5, Loss: 0.26192140206694603\n",
            "Step 4280, Epoch 5/5, Loss: 0.35128846019506454\n",
            "Step 4284, Epoch 5/5, Loss: 0.3579103797674179\n",
            "Step 4288, Epoch 5/5, Loss: 0.33162055164575577\n",
            "Step 4292, Epoch 5/5, Loss: 0.33303502202033997\n",
            "Step 4296, Epoch 5/5, Loss: 0.3506402298808098\n",
            "Step 4300, Epoch 5/5, Loss: 0.2873283214867115\n",
            "Step 4304, Epoch 5/5, Loss: 0.35308970510959625\n",
            "Step 4308, Epoch 5/5, Loss: 0.27753452956676483\n",
            "Step 4312, Epoch 5/5, Loss: 0.3245443180203438\n",
            "Step 4316, Epoch 5/5, Loss: 0.2590588331222534\n",
            "Step 4320, Epoch 5/5, Loss: 0.34235870093107224\n",
            "Step 4324, Epoch 5/5, Loss: 0.3082769736647606\n",
            "Step 4328, Epoch 5/5, Loss: 0.32018234580755234\n",
            "Step 4332, Epoch 5/5, Loss: 0.3854450285434723\n",
            "Step 4336, Epoch 5/5, Loss: 0.3018918111920357\n",
            "Step 4340, Epoch 5/5, Loss: 0.33072245866060257\n",
            "Step 4344, Epoch 5/5, Loss: 0.36087698489427567\n",
            "Step 4348, Epoch 5/5, Loss: 0.42030853033065796\n",
            "Step 4352, Epoch 5/5, Loss: 0.3592422977089882\n",
            "Step 4356, Epoch 5/5, Loss: 0.3326501026749611\n",
            "Step 4360, Epoch 5/5, Loss: 0.2811525911092758\n",
            "Step 4364, Epoch 5/5, Loss: 0.37117981165647507\n",
            "Step 4368, Epoch 5/5, Loss: 0.34194598346948624\n",
            "Step 4372, Epoch 5/5, Loss: 0.2969147711992264\n",
            "Step 4376, Epoch 5/5, Loss: 0.29654572531580925\n",
            "Step 4380, Epoch 5/5, Loss: 0.36698125302791595\n",
            "Step 4384, Epoch 5/5, Loss: 0.27626296132802963\n",
            "Step 4388, Epoch 5/5, Loss: 0.3251776695251465\n",
            "Step 4392, Epoch 5/5, Loss: 0.3594897612929344\n",
            "Step 4396, Epoch 5/5, Loss: 0.3275906965136528\n",
            "Step 4400, Epoch 5/5, Loss: 0.3374984785914421\n",
            "Step 4404, Epoch 5/5, Loss: 0.348171841353178\n",
            "Step 4408, Epoch 5/5, Loss: 0.3416686952114105\n",
            "Step 4412, Epoch 5/5, Loss: 0.30394332855939865\n",
            "Step 4416, Epoch 5/5, Loss: 0.2277783304452896\n",
            "Step 4420, Epoch 5/5, Loss: 0.4067890867590904\n",
            "Step 4424, Epoch 5/5, Loss: 0.41240695118904114\n",
            "Step 4428, Epoch 5/5, Loss: 0.3277459815144539\n",
            "Step 4432, Epoch 5/5, Loss: 0.40970342606306076\n",
            "Step 4436, Epoch 5/5, Loss: 0.3006940633058548\n",
            "Step 4440, Epoch 5/5, Loss: 0.30427901819348335\n",
            "Step 4444, Epoch 5/5, Loss: 0.2756146192550659\n",
            "Step 4448, Epoch 5/5, Loss: 0.29390525817871094\n",
            "Step 4452, Epoch 5/5, Loss: 0.2676093876361847\n",
            "Step 4456, Epoch 5/5, Loss: 0.2923361025750637\n",
            "Step 4460, Epoch 5/5, Loss: 0.3088876008987427\n",
            "Step 4464, Epoch 5/5, Loss: 0.3012699633836746\n",
            "Step 4468, Epoch 5/5, Loss: 0.29999085143208504\n",
            "Step 4472, Epoch 5/5, Loss: 0.36017610132694244\n",
            "Step 4476, Epoch 5/5, Loss: 0.25837983936071396\n",
            "Step 4480, Epoch 5/5, Loss: 0.3413913883268833\n",
            "Step 4484, Epoch 5/5, Loss: 0.2970460541546345\n",
            "Step 4488, Epoch 5/5, Loss: 0.3310063108801842\n",
            "Step 4492, Epoch 5/5, Loss: 0.3736041635274887\n",
            "Step 4496, Epoch 5/5, Loss: 0.31779925525188446\n",
            "Step 4500, Epoch 5/5, Loss: 0.3253725655376911\n",
            "Step 4504, Epoch 5/5, Loss: 0.38031840324401855\n",
            "Step 4508, Epoch 5/5, Loss: 0.3310670554637909\n",
            "Step 4512, Epoch 5/5, Loss: 0.32172365114092827\n",
            "Step 4516, Epoch 5/5, Loss: 0.3007841482758522\n",
            "Step 4520, Epoch 5/5, Loss: 0.321722399443388\n",
            "Step 4524, Epoch 5/5, Loss: 0.2653594948351383\n",
            "Step 4528, Epoch 5/5, Loss: 0.3291175179183483\n",
            "Step 4532, Epoch 5/5, Loss: 0.3320043161511421\n",
            "Step 4536, Epoch 5/5, Loss: 0.29777855426073074\n",
            "Step 4540, Epoch 5/5, Loss: 0.2515838146209717\n",
            "Step 4544, Epoch 5/5, Loss: 0.2724268101155758\n",
            "Step 4548, Epoch 5/5, Loss: 0.36315227672457695\n",
            "Step 4552, Epoch 5/5, Loss: 0.3280368745326996\n",
            "Step 4556, Epoch 5/5, Loss: 0.31637146323919296\n",
            "Step 4560, Epoch 5/5, Loss: 0.25771111249923706\n",
            "Step 4564, Epoch 5/5, Loss: 0.30487060546875\n",
            "Step 4568, Epoch 5/5, Loss: 0.36681151390075684\n",
            "Step 4572, Epoch 5/5, Loss: 0.26320135965943336\n",
            "Step 4576, Epoch 5/5, Loss: 0.256209347397089\n",
            "Step 4580, Epoch 5/5, Loss: 0.2856953330338001\n",
            "Step 4584, Epoch 5/5, Loss: 0.3639340102672577\n",
            "Step 4588, Epoch 5/5, Loss: 0.32746289670467377\n",
            "Step 4592, Epoch 5/5, Loss: 0.4083707109093666\n",
            "Step 4596, Epoch 5/5, Loss: 0.3144306242465973\n",
            "Step 4600, Epoch 5/5, Loss: 0.3074844032526016\n",
            "Step 4604, Epoch 5/5, Loss: 0.26316649094223976\n",
            "Step 4608, Epoch 5/5, Loss: 0.3246327266097069\n",
            "Step 4612, Epoch 5/5, Loss: 0.2805832400918007\n",
            "Step 4616, Epoch 5/5, Loss: 0.284038957208395\n",
            "Step 4620, Epoch 5/5, Loss: 0.35574429482221603\n",
            "Step 4624, Epoch 5/5, Loss: 0.2868664711713791\n",
            "Step 4628, Epoch 5/5, Loss: 0.3461063727736473\n",
            "Step 4632, Epoch 5/5, Loss: 0.2834141179919243\n",
            "Step 4636, Epoch 5/5, Loss: 0.3615976758301258\n",
            "Step 4640, Epoch 5/5, Loss: 0.3820033669471741\n",
            "Step 4644, Epoch 5/5, Loss: 0.33891668170690536\n",
            "Step 4648, Epoch 5/5, Loss: 0.30516043677926064\n",
            "Step 4652, Epoch 5/5, Loss: 0.30585213005542755\n",
            "Step 4656, Epoch 5/5, Loss: 0.3301311954855919\n",
            "Step 4660, Epoch 5/5, Loss: 0.294202234596014\n",
            "Step 4664, Epoch 5/5, Loss: 0.3091357946395874\n",
            "Step 4668, Epoch 5/5, Loss: 0.28206076845526695\n",
            "Step 4672, Epoch 5/5, Loss: 0.3230297639966011\n",
            "Step 4676, Epoch 5/5, Loss: 0.3471686467528343\n",
            "Step 4680, Epoch 5/5, Loss: 0.3461460992693901\n",
            "Step 4684, Epoch 5/5, Loss: 0.32590653747320175\n",
            "Step 4688, Epoch 5/5, Loss: 0.30356161296367645\n",
            "Step 4692, Epoch 5/5, Loss: 0.35941506177186966\n",
            "Step 4696, Epoch 5/5, Loss: 0.2671866714954376\n",
            "Step 4700, Epoch 5/5, Loss: 0.358893945813179\n",
            "Step 4704, Epoch 5/5, Loss: 0.2844965346157551\n",
            "Step 4708, Epoch 5/5, Loss: 0.3482787720859051\n",
            "Step 4712, Epoch 5/5, Loss: 0.37621986120939255\n",
            "Step 4716, Epoch 5/5, Loss: 0.36779438704252243\n",
            "Step 4720, Epoch 5/5, Loss: 0.30247971415519714\n",
            "Step 4724, Epoch 5/5, Loss: 0.3095897175371647\n",
            "Step 4728, Epoch 5/5, Loss: 0.3012201189994812\n",
            "Step 4732, Epoch 5/5, Loss: 0.3323194347321987\n",
            "Step 4736, Epoch 5/5, Loss: 0.30174050480127335\n",
            "Step 4740, Epoch 5/5, Loss: 0.30182788521051407\n",
            "Step 4744, Epoch 5/5, Loss: 0.3297992870211601\n",
            "Step 4748, Epoch 5/5, Loss: 0.3466174378991127\n",
            "Step 4752, Epoch 5/5, Loss: 0.31876982003450394\n",
            "Step 4756, Epoch 5/5, Loss: 0.2962825559079647\n",
            "Step 4760, Epoch 5/5, Loss: 0.2942781411111355\n",
            "Step 4764, Epoch 5/5, Loss: 0.2794381305575371\n",
            "Step 4768, Epoch 5/5, Loss: 0.30573075264692307\n",
            "Step 4772, Epoch 5/5, Loss: 0.30338865146040916\n",
            "Step 4776, Epoch 5/5, Loss: 0.3421194925904274\n",
            "Step 4780, Epoch 5/5, Loss: 0.3063560239970684\n",
            "Step 4784, Epoch 5/5, Loss: 0.26925161480903625\n",
            "Step 4788, Epoch 5/5, Loss: 0.37723881751298904\n",
            "Step 4792, Epoch 5/5, Loss: 0.3845129460096359\n",
            "Step 4796, Epoch 5/5, Loss: 0.38367509841918945\n",
            "Step 4800, Epoch 5/5, Loss: 0.36701274663209915\n",
            "Step 4804, Epoch 5/5, Loss: 0.4293270632624626\n",
            "Step 4808, Epoch 5/5, Loss: 0.3481091633439064\n",
            "Step 4812, Epoch 5/5, Loss: 0.31340186670422554\n",
            "Step 4816, Epoch 5/5, Loss: 0.30234522745013237\n",
            "Step 4820, Epoch 5/5, Loss: 0.32530589401721954\n",
            "Step 4824, Epoch 5/5, Loss: 0.33593442291021347\n",
            "Step 4828, Epoch 5/5, Loss: 0.4108063653111458\n",
            "Step 4832, Epoch 5/5, Loss: 0.2422875016927719\n",
            "Step 4836, Epoch 5/5, Loss: 0.32848765701055527\n",
            "Step 4840, Epoch 5/5, Loss: 0.32993683591485023\n",
            "Step 4844, Epoch 5/5, Loss: 0.333061546087265\n",
            "Step 4848, Epoch 5/5, Loss: 0.39632226526737213\n",
            "Step 4852, Epoch 5/5, Loss: 0.329118013381958\n",
            "Step 4856, Epoch 5/5, Loss: 0.36391571164131165\n",
            "Step 4860, Epoch 5/5, Loss: 0.2785196304321289\n",
            "Step 4864, Epoch 5/5, Loss: 0.36090758442878723\n",
            "Step 4868, Epoch 5/5, Loss: 0.30890224874019623\n",
            "Step 4872, Epoch 5/5, Loss: 0.31349919736385345\n",
            "Step 4876, Epoch 5/5, Loss: 0.3567439913749695\n",
            "Step 4880, Epoch 5/5, Loss: 0.35010284185409546\n",
            "Step 4884, Epoch 5/5, Loss: 0.33967723324894905\n",
            "Step 4888, Epoch 5/5, Loss: 0.34068286418914795\n",
            "Step 4892, Epoch 5/5, Loss: 0.3449433818459511\n",
            "Step 4896, Epoch 5/5, Loss: 0.29994671791791916\n",
            "Step 4900, Epoch 5/5, Loss: 0.397490493953228\n",
            "Step 4904, Epoch 5/5, Loss: 0.36421242356300354\n",
            "Step 4908, Epoch 5/5, Loss: 0.3484140634536743\n",
            "Step 4912, Epoch 5/5, Loss: 0.2700139656662941\n",
            "Step 4916, Epoch 5/5, Loss: 0.3405929207801819\n",
            "Step 4920, Epoch 5/5, Loss: 0.3830175958573818\n",
            "Step 4924, Epoch 5/5, Loss: 0.3000873401761055\n",
            "Step 4928, Epoch 5/5, Loss: 0.36966796964406967\n",
            "Step 4932, Epoch 5/5, Loss: 0.31408316269516945\n",
            "Step 4936, Epoch 5/5, Loss: 0.30463385209441185\n",
            "Step 4940, Epoch 5/5, Loss: 0.29043151810765266\n",
            "Step 4944, Epoch 5/5, Loss: 0.3332652226090431\n",
            "Step 4948, Epoch 5/5, Loss: 0.3437277749180794\n",
            "Step 4952, Epoch 5/5, Loss: 0.32586104422807693\n",
            "Step 4956, Epoch 5/5, Loss: 0.26184795424342155\n",
            "Step 4960, Epoch 5/5, Loss: 0.347632460296154\n",
            "Step 4964, Epoch 5/5, Loss: 0.3930438756942749\n",
            "Step 4968, Epoch 5/5, Loss: 0.29466694965958595\n",
            "Step 4972, Epoch 5/5, Loss: 0.24149176478385925\n",
            "Step 4976, Epoch 5/5, Loss: 0.35613255202770233\n",
            "Step 4980, Epoch 5/5, Loss: 0.28932927548885345\n",
            "Step 4984, Epoch 5/5, Loss: 0.32494914904236794\n",
            "Step 4988, Epoch 5/5, Loss: 0.29154692590236664\n",
            "Step 4992, Epoch 5/5, Loss: 0.3141291178762913\n",
            "Step 4996, Epoch 5/5, Loss: 0.301931906491518\n",
            "Step 5000, Epoch 5/5, Loss: 0.27843792364001274\n",
            "Step 5004, Epoch 5/5, Loss: 0.33040405809879303\n",
            "Step 5008, Epoch 5/5, Loss: 0.3313143476843834\n",
            "Step 5012, Epoch 5/5, Loss: 0.37043050676584244\n",
            "Step 5016, Epoch 5/5, Loss: 0.32330379635095596\n",
            "Step 5020, Epoch 5/5, Loss: 0.3831823989748955\n",
            "Step 5024, Epoch 5/5, Loss: 0.36544308066368103\n",
            "Step 5028, Epoch 5/5, Loss: 0.30728375166654587\n",
            "Step 5032, Epoch 5/5, Loss: 0.32842692732810974\n",
            "Step 5036, Epoch 5/5, Loss: 0.38032953441143036\n",
            "Step 5040, Epoch 5/5, Loss: 0.30238398537039757\n",
            "Step 5044, Epoch 5/5, Loss: 0.37411879748106003\n",
            "Step 5048, Epoch 5/5, Loss: 0.2396586388349533\n",
            "Step 5052, Epoch 5/5, Loss: 0.29576533660292625\n",
            "Step 5056, Epoch 5/5, Loss: 0.30614475160837173\n",
            "Step 5060, Epoch 5/5, Loss: 0.3287055939435959\n",
            "Step 5064, Epoch 5/5, Loss: 0.287340734153986\n",
            "Step 5068, Epoch 5/5, Loss: 0.3539118580520153\n",
            "Step 5072, Epoch 5/5, Loss: 0.2885403744876385\n",
            "Step 5076, Epoch 5/5, Loss: 0.38752225041389465\n",
            "Step 5080, Epoch 5/5, Loss: 0.29346852004528046\n",
            "Step 5084, Epoch 5/5, Loss: 0.3485788106918335\n",
            "Step 5088, Epoch 5/5, Loss: 0.3589877262711525\n",
            "Step 5092, Epoch 5/5, Loss: 0.3050250969827175\n",
            "Step 5096, Epoch 5/5, Loss: 0.3844858407974243\n",
            "Step 5100, Epoch 5/5, Loss: 0.374331571161747\n",
            "Step 5104, Epoch 5/5, Loss: 0.3161703273653984\n",
            "Step 5108, Epoch 5/5, Loss: 0.3207860365509987\n",
            "Step 5112, Epoch 5/5, Loss: 0.2824047841131687\n",
            "Step 5116, Epoch 5/5, Loss: 0.37008944153785706\n",
            "Step 5120, Epoch 5/5, Loss: 0.3467113971710205\n",
            "Step 5124, Epoch 5/5, Loss: 0.3186003789305687\n",
            "Step 5128, Epoch 5/5, Loss: 0.34841713309288025\n",
            "Step 5132, Epoch 5/5, Loss: 0.3575035557150841\n",
            "Step 5136, Epoch 5/5, Loss: 0.36351728439331055\n",
            "Step 5140, Epoch 5/5, Loss: 0.2886135205626488\n",
            "Step 5144, Epoch 5/5, Loss: 0.3169596791267395\n",
            "Step 5148, Epoch 5/5, Loss: 0.2931426651775837\n",
            "Step 5152, Epoch 5/5, Loss: 0.3712570369243622\n",
            "Step 5156, Epoch 5/5, Loss: 0.2918228432536125\n",
            "Step 5160, Epoch 5/5, Loss: 0.3633190169930458\n",
            "Step 5164, Epoch 5/5, Loss: 0.2813820093870163\n",
            "Step 5168, Epoch 5/5, Loss: 0.40797264873981476\n",
            "Step 5172, Epoch 5/5, Loss: 0.36337732523679733\n",
            "Step 5176, Epoch 5/5, Loss: 0.2451598420739174\n",
            "Step 5180, Epoch 5/5, Loss: 0.2587650828063488\n",
            "Step 5184, Epoch 5/5, Loss: 0.3740358129143715\n",
            "Step 5188, Epoch 5/5, Loss: 0.30488212406635284\n",
            "Step 5192, Epoch 5/5, Loss: 0.28755850717425346\n",
            "Step 5196, Epoch 5/5, Loss: 0.36821989715099335\n",
            "Step 5200, Epoch 5/5, Loss: 0.2853712923824787\n",
            "Step 5204, Epoch 5/5, Loss: 0.29341643303632736\n",
            "Step 5208, Epoch 5/5, Loss: 0.41029122471809387\n",
            "Step 5212, Epoch 5/5, Loss: 0.3431761935353279\n",
            "Step 5216, Epoch 5/5, Loss: 0.3128069266676903\n",
            "Step 5220, Epoch 5/5, Loss: 0.2665932886302471\n",
            "Step 5224, Epoch 5/5, Loss: 0.2904079481959343\n",
            "Step 5228, Epoch 5/5, Loss: 0.31035831198096275\n",
            "Step 5232, Epoch 5/5, Loss: 0.3313261494040489\n",
            "Step 5236, Epoch 5/5, Loss: 0.3899429962038994\n",
            "Step 5240, Epoch 5/5, Loss: 0.28969884663820267\n",
            "Step 5244, Epoch 5/5, Loss: 0.3648788034915924\n",
            "Step 5248, Epoch 5/5, Loss: 0.3207540474832058\n",
            "Step 5252, Epoch 5/5, Loss: 0.26950137317180634\n",
            "Step 5256, Epoch 5/5, Loss: 0.2708165794610977\n",
            "Step 5260, Epoch 5/5, Loss: 0.32950451225042343\n",
            "Step 5264, Epoch 5/5, Loss: 0.2714591398835182\n",
            "Step 5268, Epoch 5/5, Loss: 0.3393622189760208\n",
            "Step 5272, Epoch 5/5, Loss: 0.29818202555179596\n",
            "Step 5276, Epoch 5/5, Loss: 0.30446746945381165\n",
            "Step 5280, Epoch 5/5, Loss: 0.3311166502535343\n",
            "Step 5284, Epoch 5/5, Loss: 0.34205108508467674\n",
            "Step 5288, Epoch 5/5, Loss: 0.31634850427508354\n",
            "Step 5292, Epoch 5/5, Loss: 0.2787916772067547\n",
            "Step 5296, Epoch 5/5, Loss: 0.36344778537750244\n",
            "Step 5300, Epoch 5/5, Loss: 0.3021545261144638\n",
            "Step 5304, Epoch 5/5, Loss: 0.3817053809762001\n",
            "Step 5308, Epoch 5/5, Loss: 0.3200545683503151\n",
            "Step 5312, Epoch 5/5, Loss: 0.3208729214966297\n",
            "Step 5316, Epoch 5/5, Loss: 0.3606179282069206\n",
            "Step 5320, Epoch 5/5, Loss: 0.2530723884701729\n",
            "Step 5324, Epoch 5/5, Loss: 0.351448155939579\n",
            "Step 5328, Epoch 5/5, Loss: 0.34044450521469116\n",
            "Step 5332, Epoch 5/5, Loss: 0.33613571897149086\n",
            "Step 5336, Epoch 5/5, Loss: 0.335549995303154\n",
            "Step 5340, Epoch 5/5, Loss: 0.2261911928653717\n",
            "Step 5344, Epoch 5/5, Loss: 0.3183964937925339\n",
            "Step 5348, Epoch 5/5, Loss: 0.3991279751062393\n",
            "Step 5352, Epoch 5/5, Loss: 0.30847911909222603\n",
            "Step 5356, Epoch 5/5, Loss: 0.3303060308098793\n",
            "Step 5360, Epoch 5/5, Loss: 0.31758328527212143\n",
            "Step 5364, Epoch 5/5, Loss: 0.30698321014642715\n",
            "Step 5368, Epoch 5/5, Loss: 0.3622760847210884\n",
            "Step 5372, Epoch 5/5, Loss: 0.2392406202852726\n",
            "Step 5376, Epoch 5/5, Loss: 0.24051397293806076\n",
            "Step 5380, Epoch 5/5, Loss: 0.3894432671368122\n",
            "Step 5384, Epoch 5/5, Loss: 0.3673221096396446\n",
            "Step 5388, Epoch 5/5, Loss: 0.3566230610013008\n",
            "Step 5392, Epoch 5/5, Loss: 0.26110631227493286\n",
            "Step 5396, Epoch 5/5, Loss: 0.2864925190806389\n",
            "Step 5400, Epoch 5/5, Loss: 0.26119977980852127\n",
            "Step 5404, Epoch 5/5, Loss: 0.3338332995772362\n",
            "Step 5408, Epoch 5/5, Loss: 0.28720012679696083\n",
            "Step 5412, Epoch 5/5, Loss: 0.3360634222626686\n",
            "Step 5416, Epoch 5/5, Loss: 0.2956566661596298\n",
            "Step 5420, Epoch 5/5, Loss: 0.3361273482441902\n",
            "Step 5424, Epoch 5/5, Loss: 0.41437602043151855\n",
            "Step 5428, Epoch 5/5, Loss: 0.26055554673075676\n",
            "Step 5432, Epoch 5/5, Loss: 0.36479799449443817\n",
            "Step 5436, Epoch 5/5, Loss: 0.29073140397667885\n",
            "Step 5440, Epoch 5/5, Loss: 0.3688887655735016\n",
            "Step 5444, Epoch 5/5, Loss: 0.29895196110010147\n",
            "Step 5448, Epoch 5/5, Loss: 0.3096103370189667\n",
            "Step 5452, Epoch 5/5, Loss: 0.3715457171201706\n",
            "Step 5456, Epoch 5/5, Loss: 0.3487924076616764\n",
            "Step 5460, Epoch 5/5, Loss: 0.3550086282193661\n",
            "Step 5464, Epoch 5/5, Loss: 0.30934467539191246\n",
            "Step 5468, Epoch 5/5, Loss: 0.29167551547288895\n",
            "Step 5472, Epoch 5/5, Loss: 0.2787466458976269\n",
            "Step 5476, Epoch 5/5, Loss: 0.31903279200196266\n",
            "Step 5480, Epoch 5/5, Loss: 0.2974409945309162\n",
            "Step 5484, Epoch 5/5, Loss: 0.31412625685334206\n",
            "Step 5488, Epoch 5/5, Loss: 0.34311501681804657\n",
            "Step 5492, Epoch 5/5, Loss: 0.40313300490379333\n",
            "Step 5496, Epoch 5/5, Loss: 0.3270064480602741\n",
            "Step 5500, Epoch 5/5, Loss: 0.31534845754504204\n",
            "Step 5504, Epoch 5/5, Loss: 0.22643346711993217\n",
            "Step 5508, Epoch 5/5, Loss: 0.3818637952208519\n",
            "Step 5512, Epoch 5/5, Loss: 0.3376733586192131\n",
            "Step 5516, Epoch 5/5, Loss: 0.3048771172761917\n",
            "Step 5520, Epoch 5/5, Loss: 0.38438212871551514\n",
            "Step 5524, Epoch 5/5, Loss: 0.3656221032142639\n",
            "Step 5528, Epoch 5/5, Loss: 0.317487470805645\n",
            "Step 5532, Epoch 5/5, Loss: 0.3911752700805664\n",
            "Step 5536, Epoch 5/5, Loss: 0.35620516911149025\n",
            "Step 5540, Epoch 5/5, Loss: 0.3148743361234665\n",
            "Step 5544, Epoch 5/5, Loss: 0.3173382356762886\n",
            "Step 5548, Epoch 5/5, Loss: 0.3211156204342842\n",
            "Step 5552, Epoch 5/5, Loss: 0.34145645797252655\n",
            "Step 5556, Epoch 5/5, Loss: 0.36458060145378113\n",
            "Step 5560, Epoch 5/5, Loss: 0.32615406811237335\n",
            "Step 5564, Epoch 5/5, Loss: 0.3578067421913147\n",
            "Step 5568, Epoch 5/5, Loss: 0.33598770946264267\n",
            "Step 5572, Epoch 5/5, Loss: 0.34200436621904373\n",
            "Step 5576, Epoch 5/5, Loss: 0.32853102684020996\n",
            "Step 5580, Epoch 5/5, Loss: 0.31653495877981186\n",
            "Step 5584, Epoch 5/5, Loss: 0.3206774368882179\n",
            "Step 5588, Epoch 5/5, Loss: 0.32432708889245987\n",
            "Step 5592, Epoch 5/5, Loss: 0.3323369175195694\n",
            "Step 5596, Epoch 5/5, Loss: 0.3560200333595276\n",
            "Step 5600, Epoch 5/5, Loss: 0.2554772086441517\n",
            "Step 5604, Epoch 5/5, Loss: 0.3200839012861252\n",
            "Step 5608, Epoch 5/5, Loss: 0.2662987597286701\n",
            "Step 5612, Epoch 5/5, Loss: 0.2943009212613106\n",
            "Step 5616, Epoch 5/5, Loss: 0.3443465791642666\n",
            "Step 5620, Epoch 5/5, Loss: 0.39234568923711777\n",
            "Step 5624, Epoch 5/5, Loss: 0.29241012409329414\n",
            "Step 5628, Epoch 5/5, Loss: 0.24397839605808258\n",
            "Step 5632, Epoch 5/5, Loss: 0.31635457649827003\n",
            "Step 5636, Epoch 5/5, Loss: 0.3541376143693924\n",
            "Step 5640, Epoch 5/5, Loss: 0.3289171978831291\n",
            "Step 5644, Epoch 5/5, Loss: 0.27924971655011177\n",
            "Step 5648, Epoch 5/5, Loss: 0.31314588710665703\n",
            "Step 5652, Epoch 5/5, Loss: 0.36215126514434814\n",
            "Step 5656, Epoch 5/5, Loss: 0.3622211292386055\n",
            "Step 5660, Epoch 5/5, Loss: 0.3544926047325134\n",
            "Step 5664, Epoch 5/5, Loss: 0.2639210484921932\n",
            "Step 5668, Epoch 5/5, Loss: 0.2824890874326229\n",
            "Step 5672, Epoch 5/5, Loss: 0.33953240513801575\n",
            "Step 5676, Epoch 5/5, Loss: 0.30904949456453323\n",
            "Step 5680, Epoch 5/5, Loss: 0.35351214557886124\n",
            "Step 5684, Epoch 5/5, Loss: 0.3503121882677078\n",
            "Step 5688, Epoch 5/5, Loss: 0.345304012298584\n",
            "Step 5692, Epoch 5/5, Loss: 0.28888413682579994\n",
            "Step 5696, Epoch 5/5, Loss: 0.3233911879360676\n",
            "Step 5700, Epoch 5/5, Loss: 0.3397206589579582\n",
            "Step 5704, Epoch 5/5, Loss: 0.2574242353439331\n",
            "Step 5708, Epoch 5/5, Loss: 0.28046149760484695\n",
            "Step 5712, Epoch 5/5, Loss: 0.3791543059051037\n",
            "Step 5716, Epoch 5/5, Loss: 0.3031255416572094\n",
            "Step 5720, Epoch 5/5, Loss: 0.3336987644433975\n",
            "Step 5724, Epoch 5/5, Loss: 0.2978966385126114\n",
            "Step 5728, Epoch 5/5, Loss: 0.398395411670208\n",
            "Step 5732, Epoch 5/5, Loss: 0.2819797061383724\n",
            "Step 5736, Epoch 5/5, Loss: 0.30854402482509613\n",
            "Step 5740, Epoch 5/5, Loss: 0.33726103231310844\n",
            "Step 5744, Epoch 5/5, Loss: 0.33092930912971497\n",
            "Step 5748, Epoch 5/5, Loss: 0.2696806527674198\n",
            "Step 5752, Epoch 5/5, Loss: 0.2782496213912964\n",
            "Step 5756, Epoch 5/5, Loss: 0.33875922113657\n",
            "Step 5760, Epoch 5/5, Loss: 0.33363962918519974\n",
            "Step 5764, Epoch 5/5, Loss: 0.38712382316589355\n",
            "Step 5768, Epoch 5/5, Loss: 0.33548974990844727\n",
            "Step 5772, Epoch 5/5, Loss: 0.2784239090979099\n",
            "Step 5776, Epoch 5/5, Loss: 0.3536510542035103\n",
            "Step 5780, Epoch 5/5, Loss: 0.27628396078944206\n",
            "Step 5784, Epoch 5/5, Loss: 0.3534848242998123\n",
            "Step 5788, Epoch 5/5, Loss: 0.3357364907860756\n",
            "Step 5792, Epoch 5/5, Loss: 0.3342266157269478\n",
            "Step 5796, Epoch 5/5, Loss: 0.3605140820145607\n",
            "Step 5800, Epoch 5/5, Loss: 0.3266149088740349\n",
            "Step 5804, Epoch 5/5, Loss: 0.32898349314928055\n",
            "Step 5808, Epoch 5/5, Loss: 0.3790746405720711\n",
            "Step 5812, Epoch 5/5, Loss: 0.3089498467743397\n",
            "Step 5816, Epoch 5/5, Loss: 0.3793308511376381\n",
            "Step 5820, Epoch 5/5, Loss: 0.3717808797955513\n",
            "Step 5824, Epoch 5/5, Loss: 0.25201210007071495\n",
            "Step 5828, Epoch 5/5, Loss: 0.38086583465337753\n",
            "Step 5832, Epoch 5/5, Loss: 0.33241457119584084\n",
            "Step 5836, Epoch 5/5, Loss: 0.3397444859147072\n",
            "Step 5840, Epoch 5/5, Loss: 0.30573272705078125\n",
            "Step 5844, Epoch 5/5, Loss: 0.36363207548856735\n",
            "Step 5848, Epoch 5/5, Loss: 0.36921941488981247\n",
            "Step 5852, Epoch 5/5, Loss: 0.3595326840877533\n",
            "Step 5856, Epoch 5/5, Loss: 0.37205037474632263\n",
            "Step 5860, Epoch 5/5, Loss: 0.38142403215169907\n",
            "Step 5864, Epoch 5/5, Loss: 0.2964055947959423\n",
            "Step 5868, Epoch 5/5, Loss: 0.35182131081819534\n",
            "Step 5872, Epoch 5/5, Loss: 0.37171994894742966\n",
            "Step 5876, Epoch 5/5, Loss: 0.3059392720460892\n",
            "Step 5880, Epoch 5/5, Loss: 0.3189173489809036\n",
            "Step 5884, Epoch 5/5, Loss: 0.32155849784612656\n",
            "Step 5888, Epoch 5/5, Loss: 0.36873557046055794\n",
            "Step 5892, Epoch 5/5, Loss: 0.3226791024208069\n",
            "Step 5896, Epoch 5/5, Loss: 0.35421863198280334\n",
            "Step 5900, Epoch 5/5, Loss: 0.22342795133590698\n",
            "Step 5904, Epoch 5/5, Loss: 0.32934116944670677\n",
            "Step 5908, Epoch 5/5, Loss: 0.23879660665988922\n",
            "Step 5912, Epoch 5/5, Loss: 0.3263934776186943\n",
            "Step 5916, Epoch 5/5, Loss: 0.3223157227039337\n",
            "Step 5920, Epoch 5/5, Loss: 0.3282300606369972\n",
            "Step 5924, Epoch 5/5, Loss: 0.27906855940818787\n",
            "Step 5928, Epoch 5/5, Loss: 0.3509766384959221\n",
            "Step 5932, Epoch 5/5, Loss: 0.2840096279978752\n",
            "Step 5936, Epoch 5/5, Loss: 0.28531649708747864\n",
            "Step 5940, Epoch 5/5, Loss: 0.3128761909902096\n",
            "Step 5944, Epoch 5/5, Loss: 0.28815973922610283\n",
            "Step 5948, Epoch 5/5, Loss: 0.3114204406738281\n",
            "Step 5952, Epoch 5/5, Loss: 0.28974031656980515\n",
            "Step 5956, Epoch 5/5, Loss: 0.29480278119444847\n",
            "Step 5960, Epoch 5/5, Loss: 0.33912932872772217\n",
            "Step 5964, Epoch 5/5, Loss: 0.31575918570160866\n",
            "Step 5968, Epoch 5/5, Loss: 0.3199395164847374\n",
            "Step 5972, Epoch 5/5, Loss: 0.36113782972097397\n",
            "Step 5976, Epoch 5/5, Loss: 0.27179985120892525\n",
            "Step 5980, Epoch 5/5, Loss: 0.3075190633535385\n",
            "Step 5984, Epoch 5/5, Loss: 0.31994079053401947\n",
            "Step 5988, Epoch 5/5, Loss: 0.34014301747083664\n",
            "Step 5992, Epoch 5/5, Loss: 0.2581063248217106\n",
            "Step 5996, Epoch 5/5, Loss: 0.354475662112236\n",
            "Step 6000, Epoch 5/5, Loss: 0.24454167857766151\n",
            "Step 6004, Epoch 5/5, Loss: 0.3265245780348778\n",
            "Step 6008, Epoch 5/5, Loss: 0.32466547936201096\n",
            "Step 6012, Epoch 5/5, Loss: 0.3395281061530113\n",
            "Step 6016, Epoch 5/5, Loss: 0.31979208439588547\n",
            "Step 6020, Epoch 5/5, Loss: 0.35039760544896126\n",
            "Step 6024, Epoch 5/5, Loss: 0.24145688116550446\n",
            "Step 6028, Epoch 5/5, Loss: 0.3204285390675068\n",
            "Step 6032, Epoch 5/5, Loss: 0.300229087471962\n",
            "Step 6036, Epoch 5/5, Loss: 0.2742535285651684\n",
            "Step 6040, Epoch 5/5, Loss: 0.3334883525967598\n",
            "Step 6044, Epoch 5/5, Loss: 0.317342646420002\n",
            "Step 6048, Epoch 5/5, Loss: 0.3318144418299198\n",
            "Step 6052, Epoch 5/5, Loss: 0.3361736088991165\n",
            "Step 6056, Epoch 5/5, Loss: 0.30646275728940964\n",
            "Step 6060, Epoch 5/5, Loss: 0.3401245251297951\n",
            "Step 6064, Epoch 5/5, Loss: 0.3663416802883148\n",
            "Step 6068, Epoch 5/5, Loss: 0.30847084522247314\n",
            "Step 6072, Epoch 5/5, Loss: 0.34113309532403946\n",
            "Step 6076, Epoch 5/5, Loss: 0.33056100457906723\n",
            "Step 6080, Epoch 5/5, Loss: 0.4105569124221802\n",
            "Step 6084, Epoch 5/5, Loss: 0.3289077877998352\n",
            "Step 6088, Epoch 5/5, Loss: 0.30051058158278465\n",
            "Step 6092, Epoch 5/5, Loss: 0.35616563633084297\n",
            "Step 6096, Epoch 5/5, Loss: 0.304281871765852\n",
            "Step 6100, Epoch 5/5, Loss: 0.3564242720603943\n",
            "Step 6104, Epoch 5/5, Loss: 0.29308219999074936\n",
            "Step 6108, Epoch 5/5, Loss: 0.3282928094267845\n",
            "Step 6112, Epoch 5/5, Loss: 0.2900633402168751\n",
            "Step 6116, Epoch 5/5, Loss: 0.2398989051580429\n",
            "Step 6120, Epoch 5/5, Loss: 0.3747986666858196\n",
            "Step 6124, Epoch 5/5, Loss: 0.3116690143942833\n",
            "Step 6128, Epoch 5/5, Loss: 0.3331884816288948\n",
            "Step 6132, Epoch 5/5, Loss: 0.3353971131145954\n",
            "Step 6136, Epoch 5/5, Loss: 0.31998486816883087\n",
            "Step 6140, Epoch 5/5, Loss: 0.2673867233097553\n",
            "Step 6144, Epoch 5/5, Loss: 0.34968823939561844\n",
            "Step 6148, Epoch 5/5, Loss: 0.3657021000981331\n",
            "Step 6152, Epoch 5/5, Loss: 0.2898859716951847\n",
            "Step 6156, Epoch 5/5, Loss: 0.24679026007652283\n",
            "Step 6160, Epoch 5/5, Loss: 0.31940164417028427\n",
            "Step 6164, Epoch 5/5, Loss: 0.34491413086652756\n",
            "Step 6168, Epoch 5/5, Loss: 0.3328254744410515\n",
            "Step 6172, Epoch 5/5, Loss: 0.34729527682065964\n",
            "Step 6176, Epoch 5/5, Loss: 0.3465012386441231\n",
            "Step 6180, Epoch 5/5, Loss: 0.32707640528678894\n",
            "Step 6184, Epoch 5/5, Loss: 0.2977311462163925\n",
            "Step 6188, Epoch 5/5, Loss: 0.3046244792640209\n",
            "Step 6192, Epoch 5/5, Loss: 0.3418041057884693\n",
            "Step 6196, Epoch 5/5, Loss: 0.2638131007552147\n",
            "Step 6200, Epoch 5/5, Loss: 0.2950381189584732\n",
            "Step 6204, Epoch 5/5, Loss: 0.3500855416059494\n",
            "Step 6208, Epoch 5/5, Loss: 0.28216105699539185\n",
            "Step 6212, Epoch 5/5, Loss: 0.26962826773524284\n",
            "Step 6216, Epoch 5/5, Loss: 0.28245699405670166\n",
            "Step 6220, Epoch 5/5, Loss: 0.2678043581545353\n",
            "Step 6224, Epoch 5/5, Loss: 0.33724724501371384\n",
            "Step 6228, Epoch 5/5, Loss: 0.31261609122157097\n",
            "Step 6232, Epoch 5/5, Loss: 0.3531830310821533\n",
            "Step 6236, Epoch 5/5, Loss: 0.2361157238483429\n",
            "Step 6240, Epoch 5/5, Loss: 0.3412408232688904\n",
            "Step 6244, Epoch 5/5, Loss: 0.3132551796734333\n",
            "Step 6248, Epoch 5/5, Loss: 0.3249499574303627\n",
            "Step 6252, Epoch 5/5, Loss: 0.34938201680779457\n",
            "Step 6256, Epoch 5/5, Loss: 0.3195125386118889\n",
            "Step 6260, Epoch 5/5, Loss: 0.2986745312809944\n",
            "Step 6264, Epoch 5/5, Loss: 0.3679530769586563\n",
            "Step 6268, Epoch 5/5, Loss: 0.358593687415123\n",
            "Step 6272, Epoch 5/5, Loss: 0.27617688477039337\n",
            "Step 6276, Epoch 5/5, Loss: 0.32577670738101006\n",
            "Step 6280, Epoch 5/5, Loss: 0.30033718049526215\n",
            "Step 6284, Epoch 5/5, Loss: 0.36931097507476807\n",
            "Step 6288, Epoch 5/5, Loss: 0.3498324975371361\n",
            "Step 6292, Epoch 5/5, Loss: 0.23439408093690872\n",
            "Step 6296, Epoch 5/5, Loss: 0.30653925612568855\n",
            "Step 6300, Epoch 5/5, Loss: 0.2867448441684246\n",
            "Step 6304, Epoch 5/5, Loss: 0.3605768531560898\n",
            "Step 6308, Epoch 5/5, Loss: 0.36076201498508453\n",
            "Step 6312, Epoch 5/5, Loss: 0.3117224909365177\n",
            "Step 6316, Epoch 5/5, Loss: 0.388446643948555\n",
            "Step 6320, Epoch 5/5, Loss: 0.3099276199936867\n",
            "Step 6324, Epoch 5/5, Loss: 0.26525380834937096\n",
            "Step 6328, Epoch 5/5, Loss: 0.3741540163755417\n",
            "Step 6332, Epoch 5/5, Loss: 0.3122735992074013\n",
            "Step 6336, Epoch 5/5, Loss: 0.3752078264951706\n",
            "Step 6340, Epoch 5/5, Loss: 0.30077462643384933\n",
            "Step 6344, Epoch 5/5, Loss: 0.2907116860151291\n",
            "Step 6348, Epoch 5/5, Loss: 0.3172805421054363\n",
            "Step 6352, Epoch 5/5, Loss: 0.33277707546949387\n",
            "Step 6356, Epoch 5/5, Loss: 0.33832037076354027\n",
            "Step 6360, Epoch 5/5, Loss: 0.3324376344680786\n",
            "Step 6364, Epoch 5/5, Loss: 0.3672964721918106\n",
            "Step 6368, Epoch 5/5, Loss: 0.30989107489585876\n",
            "Step 6372, Epoch 5/5, Loss: 0.34285878390073776\n",
            "Step 6376, Epoch 5/5, Loss: 0.29413850232958794\n",
            "Step 6380, Epoch 5/5, Loss: 0.33493299037218094\n",
            "Step 6384, Epoch 5/5, Loss: 0.30468229949474335\n",
            "Step 6388, Epoch 5/5, Loss: 0.2716744542121887\n",
            "Step 6392, Epoch 5/5, Loss: 0.3054751567542553\n",
            "Step 6396, Epoch 5/5, Loss: 0.3314936123788357\n",
            "Step 6400, Epoch 5/5, Loss: 0.31606317684054375\n",
            "Step 6404, Epoch 5/5, Loss: 0.27459247782826424\n",
            "Step 6408, Epoch 5/5, Loss: 0.3281358331441879\n",
            "Step 6412, Epoch 5/5, Loss: 0.3560692071914673\n",
            "Step 6416, Epoch 5/5, Loss: 0.36608656495809555\n",
            "Step 6420, Epoch 5/5, Loss: 0.26593058183789253\n",
            "Step 6424, Epoch 5/5, Loss: 0.3007109574973583\n",
            "Step 6428, Epoch 5/5, Loss: 0.256901778280735\n",
            "Step 6432, Epoch 5/5, Loss: 0.33252618834376335\n",
            "Step 6436, Epoch 5/5, Loss: 0.35239358246326447\n",
            "Step 6440, Epoch 5/5, Loss: 0.3242631070315838\n",
            "Step 6444, Epoch 5/5, Loss: 0.275287926197052\n",
            "Step 6448, Epoch 5/5, Loss: 0.35660170763731003\n",
            "Step 6452, Epoch 5/5, Loss: 0.2768356092274189\n",
            "Step 6456, Epoch 5/5, Loss: 0.35937072336673737\n",
            "Step 6460, Epoch 5/5, Loss: 0.30289793759584427\n",
            "Step 6464, Epoch 5/5, Loss: 0.3915131241083145\n",
            "Step 6468, Epoch 5/5, Loss: 0.3024076484143734\n",
            "Step 6472, Epoch 5/5, Loss: 0.37738940119743347\n",
            "Step 6476, Epoch 5/5, Loss: 0.2843644246459007\n",
            "Step 6480, Epoch 5/5, Loss: 0.3071388192474842\n",
            "Step 6484, Epoch 5/5, Loss: 0.33524511754512787\n",
            "Step 6488, Epoch 5/5, Loss: 0.43340950459241867\n",
            "Step 6492, Epoch 5/5, Loss: 0.3508545905351639\n",
            "Step 6496, Epoch 5/5, Loss: 0.34736068546772003\n",
            "Step 6500, Epoch 5/5, Loss: 0.35044949501752853\n",
            "Step 6504, Epoch 5/5, Loss: 0.3158860355615616\n",
            "Step 6508, Epoch 5/5, Loss: 0.41089722514152527\n",
            "Step 6512, Epoch 5/5, Loss: 0.31751520931720734\n",
            "Step 6516, Epoch 5/5, Loss: 0.2683580219745636\n",
            "Step 6520, Epoch 5/5, Loss: 0.3056965470314026\n",
            "Step 6524, Epoch 5/5, Loss: 0.28718696534633636\n",
            "Step 6528, Epoch 5/5, Loss: 0.3177947886288166\n",
            "Step 6532, Epoch 5/5, Loss: 0.28896354883909225\n",
            "Step 6536, Epoch 5/5, Loss: 0.3227650746703148\n",
            "Step 6540, Epoch 5/5, Loss: 0.31918859481811523\n",
            "Step 6544, Epoch 5/5, Loss: 0.3446504920721054\n",
            "Step 6548, Epoch 5/5, Loss: 0.28215479850769043\n",
            "Step 6552, Epoch 5/5, Loss: 0.2779863402247429\n",
            "Step 6556, Epoch 5/5, Loss: 0.2762141227722168\n",
            "Step 6560, Epoch 5/5, Loss: 0.3540170192718506\n",
            "Step 6564, Epoch 5/5, Loss: 0.30874329805374146\n",
            "Step 6568, Epoch 5/5, Loss: 0.2796652801334858\n",
            "Step 6572, Epoch 5/5, Loss: 0.44001761823892593\n",
            "Step 6576, Epoch 5/5, Loss: 0.27076228708028793\n",
            "Step 6580, Epoch 5/5, Loss: 0.28939659148454666\n",
            "Step 6584, Epoch 5/5, Loss: 0.302643071860075\n",
            "Step 6588, Epoch 5/5, Loss: 0.2992272824048996\n",
            "Step 6592, Epoch 5/5, Loss: 0.28743981942534447\n",
            "Step 6596, Epoch 5/5, Loss: 0.32775603607296944\n",
            "Step 6600, Epoch 5/5, Loss: 0.32278119772672653\n",
            "Step 6604, Epoch 5/5, Loss: 0.3371231406927109\n",
            "Step 6608, Epoch 5/5, Loss: 0.3170243985950947\n",
            "Step 6612, Epoch 5/5, Loss: 0.29147591814398766\n",
            "Step 6616, Epoch 5/5, Loss: 0.3119104281067848\n",
            "Step 6620, Epoch 5/5, Loss: 0.3128523826599121\n",
            "Step 6624, Epoch 5/5, Loss: 0.30196690559387207\n",
            "Step 6628, Epoch 5/5, Loss: 0.27473077923059464\n",
            "Step 6632, Epoch 5/5, Loss: 0.3869437351822853\n",
            "Step 6636, Epoch 5/5, Loss: 0.36713286116719246\n",
            "Step 6640, Epoch 5/5, Loss: 0.26524802297353745\n",
            "Step 6644, Epoch 5/5, Loss: 0.358624167740345\n",
            "Step 6648, Epoch 5/5, Loss: 0.26326117292046547\n",
            "Step 6652, Epoch 5/5, Loss: 0.3450055494904518\n",
            "Step 6656, Epoch 5/5, Loss: 0.3503546118736267\n",
            "Step 6660, Epoch 5/5, Loss: 0.3116573542356491\n",
            "Step 6664, Epoch 5/5, Loss: 0.2930818758904934\n",
            "Step 6668, Epoch 5/5, Loss: 0.34163859486579895\n",
            "Step 6672, Epoch 5/5, Loss: 0.3548833876848221\n",
            "Step 6676, Epoch 5/5, Loss: 0.3742651343345642\n",
            "Step 6680, Epoch 5/5, Loss: 0.2508244588971138\n",
            "Step 6684, Epoch 5/5, Loss: 0.28597724810242653\n",
            "Step 6688, Epoch 5/5, Loss: 0.3668695241212845\n",
            "Step 6692, Epoch 5/5, Loss: 0.37751833349466324\n",
            "Step 6696, Epoch 5/5, Loss: 0.24594425037503242\n",
            "Step 6700, Epoch 5/5, Loss: 0.3932325094938278\n",
            "Step 6704, Epoch 5/5, Loss: 0.4322359934449196\n",
            "Step 6708, Epoch 5/5, Loss: 0.33829668164253235\n",
            "Step 6712, Epoch 5/5, Loss: 0.4194963872432709\n",
            "Step 6716, Epoch 5/5, Loss: 0.3466217964887619\n",
            "Step 6720, Epoch 5/5, Loss: 0.3079673461616039\n",
            "Step 6724, Epoch 5/5, Loss: 0.23515065386891365\n",
            "Step 6728, Epoch 5/5, Loss: 0.3191230520606041\n",
            "Step 6732, Epoch 5/5, Loss: 0.326977476477623\n",
            "Step 6736, Epoch 5/5, Loss: 0.3095924071967602\n",
            "Step 6740, Epoch 5/5, Loss: 0.33527974784374237\n",
            "Step 6744, Epoch 5/5, Loss: 0.2824866957962513\n",
            "Step 6748, Epoch 5/5, Loss: 0.4024299755692482\n",
            "Step 6752, Epoch 5/5, Loss: 0.3479895368218422\n",
            "Step 6756, Epoch 5/5, Loss: 0.3637162819504738\n",
            "Step 6760, Epoch 5/5, Loss: 0.36785079538822174\n",
            "Step 6764, Epoch 5/5, Loss: 0.35027096047997475\n",
            "Step 6768, Epoch 5/5, Loss: 0.3710971251130104\n",
            "Step 6772, Epoch 5/5, Loss: 0.3879852741956711\n",
            "Step 6776, Epoch 5/5, Loss: 0.351129412651062\n",
            "Step 6780, Epoch 5/5, Loss: 0.3157680854201317\n",
            "Step 6784, Epoch 5/5, Loss: 0.29313974827528\n",
            "Step 6788, Epoch 5/5, Loss: 0.31037088111042976\n",
            "Step 6792, Epoch 5/5, Loss: 0.3377956971526146\n",
            "Step 6796, Epoch 5/5, Loss: 0.3504558727145195\n",
            "Step 6800, Epoch 5/5, Loss: 0.32718347012996674\n",
            "Step 6804, Epoch 5/5, Loss: 0.3501097857952118\n",
            "Step 6808, Epoch 5/5, Loss: 0.33784374222159386\n",
            "Step 6812, Epoch 5/5, Loss: 0.3385477438569069\n",
            "Step 6816, Epoch 5/5, Loss: 0.337372325360775\n",
            "Step 6820, Epoch 5/5, Loss: 0.2889855019748211\n",
            "Step 6824, Epoch 5/5, Loss: 0.337962843477726\n",
            "Step 6828, Epoch 5/5, Loss: 0.35541289299726486\n",
            "Step 6832, Epoch 5/5, Loss: 0.29389746487140656\n",
            "Step 6836, Epoch 5/5, Loss: 0.32405080646276474\n",
            "Step 6840, Epoch 5/5, Loss: 0.33289047330617905\n",
            "Step 6844, Epoch 5/5, Loss: 0.32848992943763733\n",
            "Step 6848, Epoch 5/5, Loss: 0.3628774359822273\n",
            "Step 6852, Epoch 5/5, Loss: 0.3373735249042511\n",
            "Step 6856, Epoch 5/5, Loss: 0.3383570834994316\n",
            "Step 6860, Epoch 5/5, Loss: 0.33847445994615555\n",
            "Step 6864, Epoch 5/5, Loss: 0.33087584003806114\n",
            "Step 6868, Epoch 5/5, Loss: 0.3947184905409813\n",
            "Step 6872, Epoch 5/5, Loss: 0.3380119800567627\n",
            "Step 6876, Epoch 5/5, Loss: 0.24227260798215866\n",
            "Step 6880, Epoch 5/5, Loss: 0.35480252653360367\n",
            "Step 6884, Epoch 5/5, Loss: 0.25774314254522324\n",
            "Step 6888, Epoch 5/5, Loss: 0.32104603573679924\n",
            "Step 6892, Epoch 5/5, Loss: 0.338011771440506\n",
            "Step 6896, Epoch 5/5, Loss: 0.3599158599972725\n",
            "Step 6900, Epoch 5/5, Loss: 0.31942179799079895\n",
            "Step 6904, Epoch 5/5, Loss: 0.2649884782731533\n",
            "Step 6908, Epoch 5/5, Loss: 0.30263737216591835\n",
            "Step 6912, Epoch 5/5, Loss: 0.33930379152297974\n",
            "Step 6916, Epoch 5/5, Loss: 0.34356312453746796\n",
            "Step 6920, Epoch 5/5, Loss: 0.3125646524131298\n",
            "Step 6924, Epoch 5/5, Loss: 0.3024880327284336\n",
            "Step 6928, Epoch 5/5, Loss: 0.2845160774886608\n",
            "Step 6932, Epoch 5/5, Loss: 0.24300935864448547\n",
            "Step 6936, Epoch 5/5, Loss: 0.3404792621731758\n",
            "Step 6940, Epoch 5/5, Loss: 0.2855676934123039\n",
            "Step 6944, Epoch 5/5, Loss: 0.32471907138824463\n",
            "Step 6948, Epoch 5/5, Loss: 0.33360791951417923\n",
            "Step 6952, Epoch 5/5, Loss: 0.3141515851020813\n",
            "Step 6956, Epoch 5/5, Loss: 0.2681303508579731\n",
            "Step 6960, Epoch 5/5, Loss: 0.3557417765259743\n",
            "Step 6964, Epoch 5/5, Loss: 0.34803248941898346\n",
            "Step 6968, Epoch 5/5, Loss: 0.2936331294476986\n",
            "Step 6972, Epoch 5/5, Loss: 0.32754193991422653\n",
            "Step 6976, Epoch 5/5, Loss: 0.33670346811413765\n",
            "Step 6980, Epoch 5/5, Loss: 0.25911248475313187\n",
            "Step 6984, Epoch 5/5, Loss: 0.2929856590926647\n",
            "Step 6988, Epoch 5/5, Loss: 0.3786187469959259\n",
            "Step 6992, Epoch 5/5, Loss: 0.35054072737693787\n",
            "Step 6996, Epoch 5/5, Loss: 0.32898521050810814\n",
            "Step 7000, Epoch 5/5, Loss: 0.3144865743815899\n",
            "Step 7004, Epoch 5/5, Loss: 0.32293368875980377\n",
            "Step 7008, Epoch 5/5, Loss: 0.3489380180835724\n",
            "Step 7012, Epoch 5/5, Loss: 0.363869771361351\n",
            "Step 7016, Epoch 5/5, Loss: 0.2956616096198559\n",
            "Step 7020, Epoch 5/5, Loss: 0.3483128771185875\n",
            "Step 7024, Epoch 5/5, Loss: 0.31099478155374527\n",
            "Step 7028, Epoch 5/5, Loss: 0.35531676933169365\n",
            "Step 7032, Epoch 5/5, Loss: 0.32108249142766\n",
            "Step 7036, Epoch 5/5, Loss: 0.2404724545776844\n",
            "Step 7040, Epoch 5/5, Loss: 0.3564915582537651\n",
            "Step 7044, Epoch 5/5, Loss: 0.3079044297337532\n",
            "Step 7048, Epoch 5/5, Loss: 0.38555050268769264\n",
            "Step 7052, Epoch 5/5, Loss: 0.32564936950802803\n",
            "Step 7056, Epoch 5/5, Loss: 0.32813655212521553\n",
            "Step 7060, Epoch 5/5, Loss: 0.331124659627676\n",
            "Step 7064, Epoch 5/5, Loss: 0.37023521959781647\n",
            "Step 7068, Epoch 5/5, Loss: 0.27027221769094467\n",
            "Step 7072, Epoch 5/5, Loss: 0.3494260758161545\n",
            "Step 7076, Epoch 5/5, Loss: 0.3144785463809967\n",
            "Step 7080, Epoch 5/5, Loss: 0.31572823226451874\n",
            "Step 7084, Epoch 5/5, Loss: 0.33536261320114136\n",
            "Step 7088, Epoch 5/5, Loss: 0.4025486037135124\n",
            "Step 7092, Epoch 5/5, Loss: 0.35920633375644684\n",
            "Step 7096, Epoch 5/5, Loss: 0.2979172244668007\n",
            "Step 7100, Epoch 5/5, Loss: 0.3384001851081848\n",
            "Step 7104, Epoch 5/5, Loss: 0.30344678461551666\n",
            "Step 7108, Epoch 5/5, Loss: 0.2412034347653389\n",
            "Step 7112, Epoch 5/5, Loss: 0.41422688215970993\n",
            "Step 7116, Epoch 5/5, Loss: 0.3548353239893913\n",
            "Step 7120, Epoch 5/5, Loss: 0.3236479312181473\n",
            "Step 7124, Epoch 5/5, Loss: 0.29459216073155403\n",
            "Step 7128, Epoch 5/5, Loss: 0.3902408182621002\n",
            "Step 7132, Epoch 5/5, Loss: 0.3714030086994171\n",
            "Step 7136, Epoch 5/5, Loss: 0.265124149620533\n",
            "Step 7140, Epoch 5/5, Loss: 0.36225900053977966\n",
            "Step 7144, Epoch 5/5, Loss: 0.3626837953925133\n",
            "Step 7148, Epoch 5/5, Loss: 0.3508630059659481\n",
            "Step 7152, Epoch 5/5, Loss: 0.29152893275022507\n",
            "Step 7156, Epoch 5/5, Loss: 0.22294075414538383\n",
            "Step 7160, Epoch 5/5, Loss: 0.27064335718750954\n",
            "Step 7164, Epoch 5/5, Loss: 0.2845586948096752\n",
            "Step 7168, Epoch 5/5, Loss: 0.3912120535969734\n",
            "Step 7172, Epoch 5/5, Loss: 0.3564237132668495\n",
            "Step 7176, Epoch 5/5, Loss: 0.29278403148055077\n",
            "Step 7180, Epoch 5/5, Loss: 0.3286057151854038\n",
            "Step 7184, Epoch 5/5, Loss: 0.33850254118442535\n",
            "Step 7188, Epoch 5/5, Loss: 0.3736509531736374\n",
            "Step 7192, Epoch 5/5, Loss: 0.32996467500925064\n",
            "Step 7196, Epoch 5/5, Loss: 0.26696643605828285\n",
            "Step 7200, Epoch 5/5, Loss: 0.3023773469030857\n",
            "Step 7204, Epoch 5/5, Loss: 0.26918620243668556\n",
            "Step 7208, Epoch 5/5, Loss: 0.2854328267276287\n",
            "Step 7212, Epoch 5/5, Loss: 0.29830339923501015\n",
            "Step 7216, Epoch 5/5, Loss: 0.3170999437570572\n",
            "Step 7220, Epoch 5/5, Loss: 0.3593924678862095\n",
            "Step 7224, Epoch 5/5, Loss: 0.3515569716691971\n",
            "Step 7228, Epoch 5/5, Loss: 0.28983893245458603\n",
            "Step 7232, Epoch 5/5, Loss: 0.3882755637168884\n",
            "Step 7236, Epoch 5/5, Loss: 0.34291962161660194\n",
            "Step 7240, Epoch 5/5, Loss: 0.35063669085502625\n",
            "Step 7244, Epoch 5/5, Loss: 0.3342962861061096\n",
            "Step 7248, Epoch 5/5, Loss: 0.2981649786233902\n",
            "Step 7252, Epoch 5/5, Loss: 0.32953373342752457\n",
            "Step 7256, Epoch 5/5, Loss: 0.30136504769325256\n",
            "Step 7260, Epoch 5/5, Loss: 0.2945833206176758\n",
            "Step 7264, Epoch 5/5, Loss: 0.3866090327501297\n",
            "Step 7268, Epoch 5/5, Loss: 0.41798288375139236\n",
            "Step 7272, Epoch 5/5, Loss: 0.2865397781133652\n",
            "Step 7276, Epoch 5/5, Loss: 0.3424961417913437\n",
            "Step 7280, Epoch 5/5, Loss: 0.3524480536580086\n",
            "Step 7284, Epoch 5/5, Loss: 0.3036778122186661\n",
            "Step 7288, Epoch 5/5, Loss: 0.3552282080054283\n",
            "Step 7292, Epoch 5/5, Loss: 0.37488389760255814\n",
            "Step 7296, Epoch 5/5, Loss: 0.3028591386973858\n",
            "Step 7300, Epoch 5/5, Loss: 0.2860964238643646\n",
            "Step 7304, Epoch 5/5, Loss: 0.39175137132406235\n",
            "Step 7308, Epoch 5/5, Loss: 0.29972466453909874\n",
            "Step 7312, Epoch 5/5, Loss: 0.2969752885401249\n",
            "Step 7316, Epoch 5/5, Loss: 0.3820996880531311\n",
            "Step 7320, Epoch 5/5, Loss: 0.3337613046169281\n",
            "Step 7324, Epoch 5/5, Loss: 0.334457203745842\n",
            "Step 7328, Epoch 5/5, Loss: 0.28773946315050125\n",
            "Step 7332, Epoch 5/5, Loss: 0.375105794519186\n",
            "Step 7336, Epoch 5/5, Loss: 0.28673137351870537\n",
            "Step 7340, Epoch 5/5, Loss: 0.4175093024969101\n",
            "Step 7344, Epoch 5/5, Loss: 0.3388375900685787\n",
            "Step 7348, Epoch 5/5, Loss: 0.3986385464668274\n",
            "Step 7352, Epoch 5/5, Loss: 0.3374062851071358\n",
            "Step 7356, Epoch 5/5, Loss: 0.28947788849473\n",
            "Step 7360, Epoch 5/5, Loss: 0.31325968354940414\n",
            "Step 7364, Epoch 5/5, Loss: 0.39730868488550186\n",
            "Step 7368, Epoch 5/5, Loss: 0.2612168677151203\n",
            "Step 7372, Epoch 5/5, Loss: 0.337118536233902\n",
            "Step 7376, Epoch 5/5, Loss: 0.3524225950241089\n",
            "Step 7380, Epoch 5/5, Loss: 0.284766111522913\n",
            "Step 7384, Epoch 5/5, Loss: 0.29547689110040665\n",
            "Step 7388, Epoch 5/5, Loss: 0.31311219185590744\n",
            "Step 7392, Epoch 5/5, Loss: 0.36984100192785263\n",
            "Step 7396, Epoch 5/5, Loss: 0.3478667140007019\n",
            "Step 7400, Epoch 5/5, Loss: 0.3514501266181469\n",
            "Step 7404, Epoch 5/5, Loss: 0.30074314773082733\n",
            "Step 7408, Epoch 5/5, Loss: 0.3283297270536423\n",
            "Step 7412, Epoch 5/5, Loss: 0.2988918833434582\n",
            "Step 7416, Epoch 5/5, Loss: 0.3363722339272499\n",
            "Step 7420, Epoch 5/5, Loss: 0.27224769443273544\n",
            "Step 7424, Epoch 5/5, Loss: 0.39254090934991837\n",
            "Step 7428, Epoch 5/5, Loss: 0.20522338896989822\n",
            "Step 7432, Epoch 5/5, Loss: 0.35338103771209717\n",
            "Step 7436, Epoch 5/5, Loss: 0.36078236997127533\n",
            "Step 7440, Epoch 5/5, Loss: 0.3363451026380062\n",
            "Step 7444, Epoch 5/5, Loss: 0.3437332212924957\n",
            "Step 7448, Epoch 5/5, Loss: 0.3814905881881714\n",
            "Step 7452, Epoch 5/5, Loss: 0.3004017770290375\n",
            "Step 7456, Epoch 5/5, Loss: 0.2958705201745033\n",
            "Step 7460, Epoch 5/5, Loss: 0.30358220264315605\n",
            "Step 7464, Epoch 5/5, Loss: 0.35515371710062027\n",
            "Step 7468, Epoch 5/5, Loss: 0.33251935988664627\n",
            "Step 7472, Epoch 5/5, Loss: 0.3686666116118431\n",
            "Step 7476, Epoch 5/5, Loss: 0.3105218671262264\n",
            "Step 7480, Epoch 5/5, Loss: 0.32467125356197357\n",
            "Step 7484, Epoch 5/5, Loss: 0.3763606622815132\n",
            "Step 7488, Epoch 5/5, Loss: 0.3672230839729309\n",
            "Step 7492, Epoch 5/5, Loss: 0.3414190262556076\n",
            "Step 7496, Epoch 5/5, Loss: 0.3062598779797554\n",
            "Step 7500, Epoch 5/5, Loss: 0.39215000718832016\n",
            "Step 7504, Epoch 5/5, Loss: 0.30199916660785675\n",
            "Step 7508, Epoch 5/5, Loss: 0.2830081954598427\n",
            "Step 7512, Epoch 5/5, Loss: 0.39678893238306046\n",
            "Step 7516, Epoch 5/5, Loss: 0.3821660950779915\n",
            "Step 7520, Epoch 5/5, Loss: 0.26392682641744614\n",
            "Step 7524, Epoch 5/5, Loss: 0.2972560450434685\n",
            "Step 7528, Epoch 5/5, Loss: 0.23000268638134003\n",
            "Step 7532, Epoch 5/5, Loss: 0.2814026102423668\n",
            "Step 7536, Epoch 5/5, Loss: 0.2728444039821625\n",
            "Step 7540, Epoch 5/5, Loss: 0.2772046625614166\n",
            "Step 7544, Epoch 5/5, Loss: 0.3438321575522423\n",
            "Step 7548, Epoch 5/5, Loss: 0.34387779980897903\n",
            "Step 7552, Epoch 5/5, Loss: 0.2634199373424053\n",
            "Step 7556, Epoch 5/5, Loss: 0.3153546079993248\n",
            "Step 7560, Epoch 5/5, Loss: 0.3663250505924225\n",
            "Step 7564, Epoch 5/5, Loss: 0.3128650300204754\n",
            "Step 7568, Epoch 5/5, Loss: 0.28227797895669937\n",
            "Step 7572, Epoch 5/5, Loss: 0.30153022333979607\n",
            "Step 7576, Epoch 5/5, Loss: 0.37133824825286865\n",
            "Step 7580, Epoch 5/5, Loss: 0.3795711621642113\n",
            "Step 7584, Epoch 5/5, Loss: 0.35205262154340744\n",
            "Step 7588, Epoch 5/5, Loss: 0.31002775207161903\n",
            "Step 7592, Epoch 5/5, Loss: 0.28200896456837654\n",
            "Step 7596, Epoch 5/5, Loss: 0.31998416036367416\n",
            "Step 7600, Epoch 5/5, Loss: 0.32728248834609985\n",
            "Step 7604, Epoch 5/5, Loss: 0.27650684118270874\n",
            "Step 7608, Epoch 5/5, Loss: 0.2894480936229229\n",
            "Step 7612, Epoch 5/5, Loss: 0.3717533200979233\n",
            "Step 7616, Epoch 5/5, Loss: 0.2946626767516136\n",
            "Step 7620, Epoch 5/5, Loss: 0.27598732709884644\n",
            "Step 7624, Epoch 5/5, Loss: 0.2973172813653946\n",
            "Step 7628, Epoch 5/5, Loss: 0.3130545802414417\n",
            "Step 7632, Epoch 5/5, Loss: 0.28573738038539886\n",
            "Step 7636, Epoch 5/5, Loss: 0.33876387402415276\n",
            "Step 7640, Epoch 5/5, Loss: 0.33879561722278595\n",
            "Step 7644, Epoch 5/5, Loss: 0.33696217834949493\n",
            "Step 7648, Epoch 5/5, Loss: 0.32989882677793503\n",
            "Step 7652, Epoch 5/5, Loss: 0.37993617355823517\n",
            "Step 7656, Epoch 5/5, Loss: 0.3391035571694374\n",
            "Step 7660, Epoch 5/5, Loss: 0.3316272608935833\n",
            "Step 7664, Epoch 5/5, Loss: 0.318250086158514\n",
            "Step 7668, Epoch 5/5, Loss: 0.37691880762577057\n",
            "Step 7672, Epoch 5/5, Loss: 0.297796081751585\n",
            "Step 7676, Epoch 5/5, Loss: 0.2605065889656544\n",
            "Step 7680, Epoch 5/5, Loss: 0.29208746924996376\n",
            "Step 7684, Epoch 5/5, Loss: 0.31746046245098114\n",
            "Step 7688, Epoch 5/5, Loss: 0.2619525268673897\n",
            "Step 7692, Epoch 5/5, Loss: 0.3412562534213066\n",
            "Step 7696, Epoch 5/5, Loss: 0.33037513867020607\n",
            "Step 7700, Epoch 5/5, Loss: 0.37762919068336487\n",
            "Step 7704, Epoch 5/5, Loss: 0.29092343151569366\n",
            "Step 7708, Epoch 5/5, Loss: 0.38887379318475723\n",
            "Step 7712, Epoch 5/5, Loss: 0.33892299979925156\n",
            "Step 7716, Epoch 5/5, Loss: 0.2978488877415657\n",
            "Step 7720, Epoch 5/5, Loss: 0.2842494323849678\n",
            "Step 7724, Epoch 5/5, Loss: 0.3561004213988781\n",
            "Step 7728, Epoch 5/5, Loss: 0.3041777089238167\n",
            "Step 7732, Epoch 5/5, Loss: 0.2969841733574867\n",
            "Step 7736, Epoch 5/5, Loss: 0.31085630878806114\n",
            "Step 7740, Epoch 5/5, Loss: 0.33736319839954376\n",
            "Step 7744, Epoch 5/5, Loss: 0.3161129355430603\n",
            "Step 7748, Epoch 5/5, Loss: 0.29235532134771347\n",
            "Step 7752, Epoch 5/5, Loss: 0.25241120532155037\n",
            "Step 7756, Epoch 5/5, Loss: 0.28213823586702347\n",
            "Step 7760, Epoch 5/5, Loss: 0.312105480581522\n",
            "Step 7764, Epoch 5/5, Loss: 0.43376708775758743\n",
            "Step 7768, Epoch 5/5, Loss: 0.24145332723855972\n",
            "Step 7772, Epoch 5/5, Loss: 0.2804235965013504\n",
            "Step 7776, Epoch 5/5, Loss: 0.29583320766687393\n",
            "Step 7780, Epoch 5/5, Loss: 0.2870209440588951\n",
            "Step 7784, Epoch 5/5, Loss: 0.32362593337893486\n",
            "Step 7788, Epoch 5/5, Loss: 0.3538390100002289\n",
            "Step 7792, Epoch 5/5, Loss: 0.36964618414640427\n",
            "Step 7796, Epoch 5/5, Loss: 0.30969133973121643\n",
            "Step 7800, Epoch 5/5, Loss: 0.3767097741365433\n",
            "Step 7804, Epoch 5/5, Loss: 0.37389106303453445\n",
            "Step 7808, Epoch 5/5, Loss: 0.37493397295475006\n",
            "Step 7812, Epoch 5/5, Loss: 0.3210149481892586\n",
            "Step 7816, Epoch 5/5, Loss: 0.3323606103658676\n",
            "Step 7820, Epoch 5/5, Loss: 0.36240358650684357\n",
            "Step 7824, Epoch 5/5, Loss: 0.27376962825655937\n",
            "Step 7828, Epoch 5/5, Loss: 0.34321344643831253\n",
            "Step 7832, Epoch 5/5, Loss: 0.32305556535720825\n",
            "Step 7836, Epoch 5/5, Loss: 0.3158081956207752\n",
            "Step 7840, Epoch 5/5, Loss: 0.3181607462465763\n",
            "Step 7844, Epoch 5/5, Loss: 0.32138485834002495\n",
            "Step 7848, Epoch 5/5, Loss: 0.2942216470837593\n",
            "Step 7852, Epoch 5/5, Loss: 0.2470618411898613\n",
            "Step 7856, Epoch 5/5, Loss: 0.3953842893242836\n",
            "Step 7860, Epoch 5/5, Loss: 0.34473397210240364\n",
            "Step 7864, Epoch 5/5, Loss: 0.2486961893737316\n",
            "Step 7868, Epoch 5/5, Loss: 0.28690551221370697\n",
            "Step 7872, Epoch 5/5, Loss: 0.2836405634880066\n",
            "Step 7876, Epoch 5/5, Loss: 0.3062722831964493\n",
            "Step 7880, Epoch 5/5, Loss: 0.3451857678592205\n",
            "Step 7884, Epoch 5/5, Loss: 0.29106026887893677\n",
            "Step 7888, Epoch 5/5, Loss: 0.31776729226112366\n",
            "Step 7892, Epoch 5/5, Loss: 0.29961393028497696\n",
            "Step 7896, Epoch 5/5, Loss: 0.3831915557384491\n",
            "Step 7900, Epoch 5/5, Loss: 0.3383881151676178\n",
            "Step 7904, Epoch 5/5, Loss: 0.3495324105024338\n",
            "Step 7908, Epoch 5/5, Loss: 0.3425143249332905\n",
            "Step 7912, Epoch 5/5, Loss: 0.3193076029419899\n",
            "Step 7916, Epoch 5/5, Loss: 0.2898070178925991\n",
            "Step 7920, Epoch 5/5, Loss: 0.31692734360694885\n",
            "Step 7924, Epoch 5/5, Loss: 0.3230004608631134\n",
            "Step 7928, Epoch 5/5, Loss: 0.28124985098838806\n",
            "Step 7932, Epoch 5/5, Loss: 0.28214510530233383\n",
            "Step 7936, Epoch 5/5, Loss: 0.34548286348581314\n",
            "Step 7940, Epoch 5/5, Loss: 0.30170290172100067\n",
            "Step 7944, Epoch 5/5, Loss: 0.29149654507637024\n",
            "Step 7948, Epoch 5/5, Loss: 0.3157040625810623\n",
            "Step 7952, Epoch 5/5, Loss: 0.3792738765478134\n",
            "Step 7956, Epoch 5/5, Loss: 0.3317093178629875\n",
            "Step 7960, Epoch 5/5, Loss: 0.2648635245859623\n",
            "Step 7964, Epoch 5/5, Loss: 0.2069261036813259\n",
            "Step 7968, Epoch 5/5, Loss: 0.3407755121588707\n",
            "Step 7972, Epoch 5/5, Loss: 0.4072628915309906\n",
            "Step 7976, Epoch 5/5, Loss: 0.2608399949967861\n",
            "Step 7980, Epoch 5/5, Loss: 0.29911743104457855\n",
            "Step 7984, Epoch 5/5, Loss: 0.3754069097340107\n",
            "Step 7988, Epoch 5/5, Loss: 0.31846393644809723\n",
            "Step 7992, Epoch 5/5, Loss: 0.37728654593229294\n",
            "Step 7996, Epoch 5/5, Loss: 0.27467067539691925\n",
            "Step 8000, Epoch 5/5, Loss: 0.37269704043865204\n",
            "Step 8004, Epoch 5/5, Loss: 0.30284032225608826\n",
            "Step 8008, Epoch 5/5, Loss: 0.29557717591524124\n",
            "Step 8012, Epoch 5/5, Loss: 0.2763740234076977\n",
            "Step 8016, Epoch 5/5, Loss: 0.34413840249180794\n",
            "Step 8020, Epoch 5/5, Loss: 0.3354044705629349\n",
            "Step 8024, Epoch 5/5, Loss: 0.28560418635606766\n",
            "Step 8028, Epoch 5/5, Loss: 0.2984665744006634\n",
            "Step 8032, Epoch 5/5, Loss: 0.3376081585884094\n",
            "Step 8036, Epoch 5/5, Loss: 0.3383626639842987\n",
            "Step 8040, Epoch 5/5, Loss: 0.30266618728637695\n",
            "Step 8044, Epoch 5/5, Loss: 0.2549012079834938\n",
            "Step 8048, Epoch 5/5, Loss: 0.31348681822419167\n",
            "Step 8052, Epoch 5/5, Loss: 0.329479843378067\n",
            "Step 8056, Epoch 5/5, Loss: 0.3237842731177807\n",
            "Step 8060, Epoch 5/5, Loss: 0.3309469632804394\n",
            "Step 8064, Epoch 5/5, Loss: 0.35168639570474625\n",
            "Step 8068, Epoch 5/5, Loss: 0.30416566506028175\n",
            "Step 8072, Epoch 5/5, Loss: 0.28518344834446907\n",
            "Step 8076, Epoch 5/5, Loss: 0.37586669623851776\n",
            "Step 8080, Epoch 5/5, Loss: 0.30337586998939514\n",
            "Step 8084, Epoch 5/5, Loss: 0.2727360166609287\n",
            "Step 8088, Epoch 5/5, Loss: 0.3279654383659363\n",
            "Step 8092, Epoch 5/5, Loss: 0.26938091218471527\n",
            "Step 8096, Epoch 5/5, Loss: 0.2783973067998886\n",
            "Step 8100, Epoch 5/5, Loss: 0.3831065222620964\n",
            "Step 8104, Epoch 5/5, Loss: 0.31887664645910263\n",
            "Step 8108, Epoch 5/5, Loss: 0.2574695385992527\n",
            "Step 8112, Epoch 5/5, Loss: 0.35641684383153915\n",
            "Step 8116, Epoch 5/5, Loss: 0.3281105197966099\n",
            "Step 8120, Epoch 5/5, Loss: 0.3316018804907799\n",
            "Step 8124, Epoch 5/5, Loss: 0.28597940877079964\n",
            "Step 8128, Epoch 5/5, Loss: 0.3372560553252697\n",
            "Step 8132, Epoch 5/5, Loss: 0.28128955140709877\n",
            "Step 8136, Epoch 5/5, Loss: 0.26679639518260956\n",
            "Step 8140, Epoch 5/5, Loss: 0.2647903747856617\n",
            "Step 8144, Epoch 5/5, Loss: 0.26949517801404\n",
            "Step 8148, Epoch 5/5, Loss: 0.356611467897892\n",
            "Step 8152, Epoch 5/5, Loss: 0.3093714974820614\n",
            "Step 8156, Epoch 5/5, Loss: 0.2833288945257664\n",
            "Step 8160, Epoch 5/5, Loss: 0.3549899607896805\n",
            "Step 8164, Epoch 5/5, Loss: 0.35263829678297043\n",
            "Step 8168, Epoch 5/5, Loss: 0.3627418652176857\n",
            "Step 8172, Epoch 5/5, Loss: 0.3599195256829262\n",
            "Step 8176, Epoch 5/5, Loss: 0.35858408361673355\n",
            "Step 8180, Epoch 5/5, Loss: 0.32305216044187546\n",
            "Step 8184, Epoch 5/5, Loss: 0.30953678488731384\n",
            "Step 8188, Epoch 5/5, Loss: 0.3395904563367367\n",
            "Step 8192, Epoch 5/5, Loss: 0.33604617416858673\n",
            "Step 8196, Epoch 5/5, Loss: 0.3091420345008373\n",
            "Step 8200, Epoch 5/5, Loss: 0.33817601576447487\n",
            "Step 8204, Epoch 5/5, Loss: 0.4125209450721741\n",
            "Step 8208, Epoch 5/5, Loss: 0.36129120737314224\n",
            "Step 8212, Epoch 5/5, Loss: 0.2902555391192436\n",
            "Step 8216, Epoch 5/5, Loss: 0.3448801413178444\n",
            "Step 8220, Epoch 5/5, Loss: 0.31180086359381676\n",
            "Step 8224, Epoch 5/5, Loss: 0.27050334215164185\n",
            "Step 8228, Epoch 5/5, Loss: 0.34961048513650894\n",
            "Step 8232, Epoch 5/5, Loss: 0.35483434051275253\n",
            "Step 8236, Epoch 5/5, Loss: 0.2592454142868519\n",
            "Step 8240, Epoch 5/5, Loss: 0.3135424964129925\n",
            "Step 8244, Epoch 5/5, Loss: 0.341754462569952\n",
            "Step 8248, Epoch 5/5, Loss: 0.28067202121019363\n",
            "Step 8252, Epoch 5/5, Loss: 0.3445268049836159\n",
            "Step 8256, Epoch 5/5, Loss: 0.4085988774895668\n",
            "Step 8260, Epoch 5/5, Loss: 0.32183075696229935\n",
            "Step 8264, Epoch 5/5, Loss: 0.3520646244287491\n",
            "Step 8268, Epoch 5/5, Loss: 0.3160149119794369\n",
            "Step 8272, Epoch 5/5, Loss: 0.32512201741337776\n",
            "Step 8276, Epoch 5/5, Loss: 0.321556456387043\n",
            "Step 8280, Epoch 5/5, Loss: 0.33857161551713943\n",
            "Step 8284, Epoch 5/5, Loss: 0.32757196947932243\n",
            "Step 8288, Epoch 5/5, Loss: 0.31239383667707443\n",
            "Step 8292, Epoch 5/5, Loss: 0.2545095831155777\n",
            "Step 8296, Epoch 5/5, Loss: 0.2771371304988861\n",
            "Step 8300, Epoch 5/5, Loss: 0.2912389896810055\n",
            "Step 8304, Epoch 5/5, Loss: 0.29456792771816254\n",
            "Step 8308, Epoch 5/5, Loss: 0.3172469772398472\n",
            "Step 8312, Epoch 5/5, Loss: 0.32963620871305466\n",
            "Step 8316, Epoch 5/5, Loss: 0.2566818967461586\n",
            "Step 8320, Epoch 5/5, Loss: 0.39849328249692917\n",
            "Step 8324, Epoch 5/5, Loss: 0.37436025589704514\n",
            "Step 8328, Epoch 5/5, Loss: 0.25287820771336555\n",
            "Step 8332, Epoch 5/5, Loss: 0.34911107271909714\n",
            "Step 8336, Epoch 5/5, Loss: 0.29055264219641685\n",
            "Step 8340, Epoch 5/5, Loss: 0.3109978102147579\n",
            "Step 8344, Epoch 5/5, Loss: 0.2886369898915291\n",
            "Step 8348, Epoch 5/5, Loss: 0.30779605358839035\n",
            "Step 8352, Epoch 5/5, Loss: 0.2599310837686062\n",
            "Step 8356, Epoch 5/5, Loss: 0.3825526386499405\n",
            "Step 8360, Epoch 5/5, Loss: 0.2901807464659214\n",
            "Step 8364, Epoch 5/5, Loss: 0.3299398683011532\n",
            "Step 8368, Epoch 5/5, Loss: 0.3128429353237152\n",
            "Step 8372, Epoch 5/5, Loss: 0.33517859876155853\n",
            "Step 8376, Epoch 5/5, Loss: 0.3213348686695099\n",
            "Step 8380, Epoch 5/5, Loss: 0.3881199508905411\n",
            "Step 8384, Epoch 5/5, Loss: 0.31367822736501694\n",
            "Step 8388, Epoch 5/5, Loss: 0.3999992832541466\n",
            "Step 8392, Epoch 5/5, Loss: 0.24876099452376366\n",
            "Step 8396, Epoch 5/5, Loss: 0.289389219135046\n",
            "Step 8400, Epoch 5/5, Loss: 0.39311427623033524\n",
            "Step 8404, Epoch 5/5, Loss: 0.39088955521583557\n",
            "Step 8408, Epoch 5/5, Loss: 0.2999148778617382\n",
            "Step 8412, Epoch 5/5, Loss: 0.2955228164792061\n",
            "Step 8416, Epoch 5/5, Loss: 0.2989330478012562\n",
            "Step 8420, Epoch 5/5, Loss: 0.3389040306210518\n",
            "Step 8424, Epoch 5/5, Loss: 0.3866897523403168\n",
            "Step 8428, Epoch 5/5, Loss: 0.2877642437815666\n",
            "Step 8432, Epoch 5/5, Loss: 0.34352416545152664\n",
            "Step 8436, Epoch 5/5, Loss: 0.33650699257850647\n",
            "Step 8440, Epoch 5/5, Loss: 0.33555810898542404\n",
            "Step 8444, Epoch 5/5, Loss: 0.3450387418270111\n",
            "Step 8448, Epoch 5/5, Loss: 0.42434217035770416\n",
            "Step 8452, Epoch 5/5, Loss: 0.3091265559196472\n",
            "Step 8456, Epoch 5/5, Loss: 0.33594778180122375\n",
            "Step 8460, Epoch 5/5, Loss: 0.37902767211198807\n",
            "Step 8464, Epoch 5/5, Loss: 0.317734032869339\n",
            "Step 8468, Epoch 5/5, Loss: 0.2544976882636547\n",
            "Step 8472, Epoch 5/5, Loss: 0.28407589346170425\n",
            "Step 8476, Epoch 5/5, Loss: 0.346233032643795\n",
            "Step 8480, Epoch 5/5, Loss: 0.34297916293144226\n",
            "Step 8484, Epoch 5/5, Loss: 0.2902405671775341\n",
            "Step 8488, Epoch 5/5, Loss: 0.3060498833656311\n",
            "Step 8492, Epoch 5/5, Loss: 0.36613156646490097\n",
            "Step 8496, Epoch 5/5, Loss: 0.33770840242505074\n",
            "Step 8500, Epoch 5/5, Loss: 0.35467324405908585\n",
            "Step 8504, Epoch 5/5, Loss: 0.367525652050972\n",
            "Step 8508, Epoch 5/5, Loss: 0.3434269279241562\n",
            "Step 8512, Epoch 5/5, Loss: 0.33996615558862686\n",
            "Step 8516, Epoch 5/5, Loss: 0.3364233262836933\n",
            "Step 8520, Epoch 5/5, Loss: 0.35462667793035507\n",
            "Step 8524, Epoch 5/5, Loss: 0.23697489872574806\n",
            "Step 8528, Epoch 5/5, Loss: 0.3055614270269871\n",
            "Step 8532, Epoch 5/5, Loss: 0.36521704494953156\n",
            "Step 8536, Epoch 5/5, Loss: 0.3096579574048519\n",
            "Step 8540, Epoch 5/5, Loss: 0.25430453941226006\n",
            "Step 8544, Epoch 5/5, Loss: 0.3556339293718338\n",
            "Step 8548, Epoch 5/5, Loss: 0.31734222918748856\n",
            "Step 8552, Epoch 5/5, Loss: 0.3276655003428459\n",
            "Step 8556, Epoch 5/5, Loss: 0.30094899237155914\n",
            "Step 8560, Epoch 5/5, Loss: 0.294657114893198\n",
            "Step 8564, Epoch 5/5, Loss: 0.30750809237360954\n",
            "Step 8568, Epoch 5/5, Loss: 0.2804087735712528\n",
            "Step 8572, Epoch 5/5, Loss: 0.2611791826784611\n",
            "Step 8576, Epoch 5/5, Loss: 0.36211785301566124\n",
            "Step 8580, Epoch 5/5, Loss: 0.3562697172164917\n",
            "Step 8584, Epoch 5/5, Loss: 0.2720204219222069\n",
            "Step 8588, Epoch 5/5, Loss: 0.371061347424984\n",
            "Step 8592, Epoch 5/5, Loss: 0.33397670835256577\n",
            "Step 8596, Epoch 5/5, Loss: 0.3081333413720131\n",
            "Step 8600, Epoch 5/5, Loss: 0.3031401187181473\n",
            "Step 8604, Epoch 5/5, Loss: 0.30508072674274445\n",
            "Step 8608, Epoch 5/5, Loss: 0.3352028951048851\n",
            "Step 8612, Epoch 5/5, Loss: 0.3017328083515167\n",
            "Step 8616, Epoch 5/5, Loss: 0.2720164805650711\n",
            "Step 8620, Epoch 5/5, Loss: 0.31257428228855133\n",
            "Step 8624, Epoch 5/5, Loss: 0.35678404569625854\n",
            "Step 8628, Epoch 5/5, Loss: 0.4041309729218483\n",
            "Step 8632, Epoch 5/5, Loss: 0.32466334849596024\n",
            "Step 8636, Epoch 5/5, Loss: 0.33094164729118347\n",
            "Step 8640, Epoch 5/5, Loss: 0.29489587247371674\n",
            "Step 8644, Epoch 5/5, Loss: 0.23314423114061356\n",
            "Step 8648, Epoch 5/5, Loss: 0.2791604958474636\n",
            "Step 8652, Epoch 5/5, Loss: 0.2138659991323948\n",
            "Step 8656, Epoch 5/5, Loss: 0.3292403221130371\n",
            "Step 8660, Epoch 5/5, Loss: 0.36337798088788986\n",
            "Step 8664, Epoch 5/5, Loss: 0.34327202290296555\n",
            "Step 8668, Epoch 5/5, Loss: 0.37051495909690857\n",
            "Step 8672, Epoch 5/5, Loss: 0.2937439940869808\n",
            "Step 8676, Epoch 5/5, Loss: 0.3302570767700672\n",
            "Step 8680, Epoch 5/5, Loss: 0.26026497036218643\n",
            "Step 8684, Epoch 5/5, Loss: 0.361302450299263\n",
            "Step 8688, Epoch 5/5, Loss: 0.28780264034867287\n",
            "Step 8692, Epoch 5/5, Loss: 0.32585619017481804\n",
            "Step 8696, Epoch 5/5, Loss: 0.2980733886361122\n",
            "Step 8700, Epoch 5/5, Loss: 0.34145287424325943\n",
            "Step 8704, Epoch 5/5, Loss: 0.3233441337943077\n",
            "Step 8708, Epoch 5/5, Loss: 0.3322775177657604\n",
            "Step 8712, Epoch 5/5, Loss: 0.3233020268380642\n",
            "Step 8716, Epoch 5/5, Loss: 0.34941359609365463\n",
            "Step 8720, Epoch 5/5, Loss: 0.3269970268011093\n",
            "Step 8724, Epoch 5/5, Loss: 0.2725759483873844\n",
            "Step 8728, Epoch 5/5, Loss: 0.3315074145793915\n",
            "Step 8732, Epoch 5/5, Loss: 0.3399682119488716\n",
            "Step 8736, Epoch 5/5, Loss: 0.3435709550976753\n",
            "Step 8740, Epoch 5/5, Loss: 0.3387114256620407\n",
            "Step 8744, Epoch 5/5, Loss: 0.26712385192513466\n",
            "Step 8748, Epoch 5/5, Loss: 0.37613270431756973\n",
            "Step 8752, Epoch 5/5, Loss: 0.24493689462542534\n",
            "Step 8756, Epoch 5/5, Loss: 0.40150248259305954\n",
            "Step 8760, Epoch 5/5, Loss: 0.3308003321290016\n",
            "Step 8764, Epoch 5/5, Loss: 0.2923138365149498\n",
            "Step 8768, Epoch 5/5, Loss: 0.3848069794476032\n",
            "Step 8772, Epoch 5/5, Loss: 0.3213096857070923\n",
            "Step 8776, Epoch 5/5, Loss: 0.35188037902116776\n",
            "Step 8780, Epoch 5/5, Loss: 0.31103915721178055\n",
            "Step 8784, Epoch 5/5, Loss: 0.34397004544734955\n",
            "Step 8788, Epoch 5/5, Loss: 0.321399062871933\n",
            "Step 8792, Epoch 5/5, Loss: 0.3973947763442993\n",
            "Step 8796, Epoch 5/5, Loss: 0.29932472482323647\n",
            "Step 8800, Epoch 5/5, Loss: 0.368685781955719\n",
            "Step 8804, Epoch 5/5, Loss: 0.347049243748188\n",
            "Step 8808, Epoch 5/5, Loss: 0.3194505497813225\n",
            "Step 8812, Epoch 5/5, Loss: 0.2761057950556278\n",
            "Step 8816, Epoch 5/5, Loss: 0.38793983310461044\n",
            "Step 8820, Epoch 5/5, Loss: 0.21890157461166382\n",
            "Step 8824, Epoch 5/5, Loss: 0.35960806906223297\n",
            "Step 8828, Epoch 5/5, Loss: 0.3950403705239296\n",
            "Step 8832, Epoch 5/5, Loss: 0.40866848081350327\n",
            "Step 8836, Epoch 5/5, Loss: 0.32100677490234375\n",
            "Step 8840, Epoch 5/5, Loss: 0.37816622853279114\n",
            "Step 8844, Epoch 5/5, Loss: 0.3671826794743538\n",
            "Step 8848, Epoch 5/5, Loss: 0.3254641070961952\n",
            "Step 8852, Epoch 5/5, Loss: 0.4182237610220909\n",
            "Step 8856, Epoch 5/5, Loss: 0.34754224494099617\n",
            "Step 8860, Epoch 5/5, Loss: 0.35617906227707863\n",
            "Step 8864, Epoch 5/5, Loss: 0.3269347995519638\n",
            "Step 8868, Epoch 5/5, Loss: 0.36150530725717545\n",
            "Step 8872, Epoch 5/5, Loss: 0.37044426053762436\n",
            "Step 8876, Epoch 5/5, Loss: 0.35667677223682404\n",
            "Step 8880, Epoch 5/5, Loss: 0.3432849235832691\n",
            "Step 8884, Epoch 5/5, Loss: 0.35006576776504517\n",
            "Step 8888, Epoch 5/5, Loss: 0.3412787914276123\n",
            "Step 8892, Epoch 5/5, Loss: 0.29353418946266174\n",
            "Step 8896, Epoch 5/5, Loss: 0.36698758602142334\n",
            "Step 8900, Epoch 5/5, Loss: 0.2602010406553745\n",
            "Step 8904, Epoch 5/5, Loss: 0.2853795662522316\n",
            "Step 8908, Epoch 5/5, Loss: 0.3472925126552582\n",
            "Step 8912, Epoch 5/5, Loss: 0.33768121898174286\n",
            "Step 8916, Epoch 5/5, Loss: 0.2896801270544529\n",
            "Step 8920, Epoch 5/5, Loss: 0.3139354847371578\n",
            "Step 8924, Epoch 5/5, Loss: 0.3315763622522354\n",
            "Step 8928, Epoch 5/5, Loss: 0.4131774306297302\n",
            "Step 8932, Epoch 5/5, Loss: 0.27503010630607605\n",
            "Step 8936, Epoch 5/5, Loss: 0.29023127630352974\n",
            "Step 8940, Epoch 5/5, Loss: 0.3499053865671158\n",
            "Step 8944, Epoch 5/5, Loss: 0.29840005934238434\n",
            "Step 8948, Epoch 5/5, Loss: 0.4223595932126045\n",
            "Step 8952, Epoch 5/5, Loss: 0.3112630099058151\n",
            "Step 8956, Epoch 5/5, Loss: 0.3172457031905651\n",
            "Step 8960, Epoch 5/5, Loss: 0.2817363142967224\n",
            "Step 8964, Epoch 5/5, Loss: 0.36615948379039764\n",
            "Step 8968, Epoch 5/5, Loss: 0.316654484719038\n",
            "Step 8972, Epoch 5/5, Loss: 0.2992304563522339\n",
            "Step 8976, Epoch 5/5, Loss: 0.29023781418800354\n",
            "Step 8980, Epoch 5/5, Loss: 0.26298531517386436\n",
            "Step 8984, Epoch 5/5, Loss: 0.32195910066366196\n",
            "Step 8988, Epoch 5/5, Loss: 0.36611298471689224\n",
            "Step 8992, Epoch 5/5, Loss: 0.3481411039829254\n",
            "Step 8996, Epoch 5/5, Loss: 0.3337204232811928\n",
            "Step 9000, Epoch 5/5, Loss: 0.3191802576184273\n",
            "Step 9004, Epoch 5/5, Loss: 0.2618044577538967\n",
            "Step 9008, Epoch 5/5, Loss: 0.3054913766682148\n",
            "Step 9012, Epoch 5/5, Loss: 0.35456517711281776\n",
            "Step 9016, Epoch 5/5, Loss: 0.27770788595080376\n",
            "Step 9020, Epoch 5/5, Loss: 0.3224080391228199\n",
            "Step 9024, Epoch 5/5, Loss: 0.28814592212438583\n",
            "Step 9028, Epoch 5/5, Loss: 0.2548725828528404\n",
            "Step 9032, Epoch 5/5, Loss: 0.2534403167665005\n",
            "Step 9036, Epoch 5/5, Loss: 0.37672723084688187\n",
            "Step 9040, Epoch 5/5, Loss: 0.324434295296669\n",
            "Step 9044, Epoch 5/5, Loss: 0.3344838134944439\n",
            "Step 9048, Epoch 5/5, Loss: 0.33306068181991577\n",
            "Step 9052, Epoch 5/5, Loss: 0.31096114963293076\n",
            "Step 9056, Epoch 5/5, Loss: 0.3087407685816288\n",
            "Step 9060, Epoch 5/5, Loss: 0.3856203630566597\n",
            "Step 9064, Epoch 5/5, Loss: 0.357400082051754\n",
            "Step 9068, Epoch 5/5, Loss: 0.35441311448812485\n",
            "Step 9072, Epoch 5/5, Loss: 0.3166968375444412\n",
            "Step 9076, Epoch 5/5, Loss: 0.3738444596529007\n",
            "Step 9080, Epoch 5/5, Loss: 0.3349684551358223\n",
            "Step 9084, Epoch 5/5, Loss: 0.24745893850922585\n",
            "Step 9088, Epoch 5/5, Loss: 0.28602636605501175\n",
            "Step 9092, Epoch 5/5, Loss: 0.3182981088757515\n",
            "Step 9096, Epoch 5/5, Loss: 0.33105194941163063\n",
            "Step 9100, Epoch 5/5, Loss: 0.2989831529557705\n",
            "Step 9104, Epoch 5/5, Loss: 0.3628324568271637\n",
            "Step 9108, Epoch 5/5, Loss: 0.3166476674377918\n",
            "Step 9112, Epoch 5/5, Loss: 0.35145722329616547\n",
            "Step 9116, Epoch 5/5, Loss: 0.3119414485991001\n",
            "Step 9120, Epoch 5/5, Loss: 0.29171213135123253\n",
            "Step 9124, Epoch 5/5, Loss: 0.35013874992728233\n",
            "Step 9128, Epoch 5/5, Loss: 0.31374168395996094\n",
            "Step 9132, Epoch 5/5, Loss: 0.3427920266985893\n",
            "Step 9136, Epoch 5/5, Loss: 0.32916146889328957\n",
            "Step 9140, Epoch 5/5, Loss: 0.2994435541331768\n",
            "Step 9144, Epoch 5/5, Loss: 0.3523348867893219\n",
            "Step 9148, Epoch 5/5, Loss: 0.2637319713830948\n",
            "Step 9152, Epoch 5/5, Loss: 0.30309321358799934\n",
            "Step 9156, Epoch 5/5, Loss: 0.3034318834543228\n",
            "Step 9160, Epoch 5/5, Loss: 0.28535934537649155\n",
            "Step 9164, Epoch 5/5, Loss: 0.3045412711799145\n",
            "Step 9168, Epoch 5/5, Loss: 0.37917401641607285\n",
            "Step 9172, Epoch 5/5, Loss: 0.39483199268579483\n",
            "Step 9176, Epoch 5/5, Loss: 0.28518975153565407\n",
            "Step 9180, Epoch 5/5, Loss: 0.29726574197411537\n",
            "Step 9184, Epoch 5/5, Loss: 0.31637977808713913\n",
            "Step 9188, Epoch 5/5, Loss: 0.25742797926068306\n",
            "Step 9192, Epoch 5/5, Loss: 0.2995154932141304\n",
            "Step 9196, Epoch 5/5, Loss: 0.3043946549296379\n",
            "Step 9200, Epoch 5/5, Loss: 0.3172196075320244\n",
            "Step 9204, Epoch 5/5, Loss: 0.35639509558677673\n",
            "Step 9208, Epoch 5/5, Loss: 0.2820293456315994\n",
            "Step 9212, Epoch 5/5, Loss: 0.2357686683535576\n",
            "Step 9216, Epoch 5/5, Loss: 0.2965185306966305\n",
            "Step 9220, Epoch 5/5, Loss: 0.35992203280329704\n",
            "Step 9224, Epoch 5/5, Loss: 0.32313185930252075\n",
            "Step 9228, Epoch 5/5, Loss: 0.320513304322958\n",
            "Step 9232, Epoch 5/5, Loss: 0.3088916689157486\n",
            "Step 9236, Epoch 5/5, Loss: 0.3798486143350601\n",
            "Step 9240, Epoch 5/5, Loss: 0.3301152437925339\n",
            "Step 9244, Epoch 5/5, Loss: 0.4369576424360275\n",
            "Step 9248, Epoch 5/5, Loss: 0.2425570860505104\n",
            "Step 9252, Epoch 5/5, Loss: 0.3373101130127907\n",
            "Step 9256, Epoch 5/5, Loss: 0.33931708708405495\n",
            "Step 9260, Epoch 5/5, Loss: 0.30979815497994423\n",
            "Step 9264, Epoch 5/5, Loss: 0.365840844810009\n",
            "Step 9268, Epoch 5/5, Loss: 0.2985961213707924\n",
            "Step 9272, Epoch 5/5, Loss: 0.3100103847682476\n",
            "Step 9276, Epoch 5/5, Loss: 0.28520962595939636\n",
            "Step 9280, Epoch 5/5, Loss: 0.2890499234199524\n",
            "Step 9284, Epoch 5/5, Loss: 0.3524796813726425\n",
            "Step 9288, Epoch 5/5, Loss: 0.3977973163127899\n",
            "Step 9292, Epoch 5/5, Loss: 0.33748046308755875\n",
            "Step 9296, Epoch 5/5, Loss: 0.3081444911658764\n",
            "Step 9300, Epoch 5/5, Loss: 0.35735397785902023\n",
            "Step 9304, Epoch 5/5, Loss: 0.2674984596669674\n",
            "Step 9308, Epoch 5/5, Loss: 0.26414354518055916\n",
            "Step 9312, Epoch 5/5, Loss: 0.3601185157895088\n",
            "Step 9316, Epoch 5/5, Loss: 0.4189087823033333\n",
            "Step 9320, Epoch 5/5, Loss: 0.3043351024389267\n",
            "Step 9324, Epoch 5/5, Loss: 0.3495488688349724\n",
            "Step 9328, Epoch 5/5, Loss: 0.34164319187402725\n",
            "Step 9332, Epoch 5/5, Loss: 0.30238335207104683\n",
            "Step 9336, Epoch 5/5, Loss: 0.3763564005494118\n",
            "Step 9340, Epoch 5/5, Loss: 0.34256748110055923\n",
            "Step 9344, Epoch 5/5, Loss: 0.34120166301727295\n",
            "Step 9348, Epoch 5/5, Loss: 0.31520316004753113\n",
            "Step 9352, Epoch 5/5, Loss: 0.31352949142456055\n",
            "Step 9356, Epoch 5/5, Loss: 0.3645826056599617\n",
            "Step 9360, Epoch 5/5, Loss: 0.3314840644598007\n",
            "Step 9364, Epoch 5/5, Loss: 0.3850501626729965\n",
            "Step 9368, Epoch 5/5, Loss: 0.4418710693717003\n",
            "Step 9372, Epoch 5/5, Loss: 0.29036612808704376\n",
            "Step 9376, Epoch 5/5, Loss: 0.34598395973443985\n",
            "Step 9380, Epoch 5/5, Loss: 0.3640620931982994\n",
            "Step 9384, Epoch 5/5, Loss: 0.2949855551123619\n",
            "Step 9388, Epoch 5/5, Loss: 0.3029276989400387\n",
            "Step 9392, Epoch 5/5, Loss: 0.38800665736198425\n",
            "Step 9396, Epoch 5/5, Loss: 0.3225478231906891\n",
            "Step 9400, Epoch 5/5, Loss: 0.3391377404332161\n",
            "Step 9404, Epoch 5/5, Loss: 0.352066770195961\n",
            "Step 9408, Epoch 5/5, Loss: 0.322022020816803\n",
            "Step 9412, Epoch 5/5, Loss: 0.34125541895627975\n",
            "Step 9416, Epoch 5/5, Loss: 0.22869900986552238\n",
            "Step 9420, Epoch 5/5, Loss: 0.2891266942024231\n",
            "Step 9424, Epoch 5/5, Loss: 0.36053523048758507\n",
            "Step 9428, Epoch 5/5, Loss: 0.4301009848713875\n",
            "Step 9432, Epoch 5/5, Loss: 0.3494698628783226\n",
            "Step 9436, Epoch 5/5, Loss: 0.36844684928655624\n",
            "Step 9440, Epoch 5/5, Loss: 0.32157617807388306\n",
            "Step 9444, Epoch 5/5, Loss: 0.26717662811279297\n",
            "Step 9448, Epoch 5/5, Loss: 0.280045822262764\n",
            "Step 9452, Epoch 5/5, Loss: 0.3562719598412514\n",
            "Step 9456, Epoch 5/5, Loss: 0.3517489582300186\n",
            "Step 9460, Epoch 5/5, Loss: 0.29277218133211136\n",
            "Step 9464, Epoch 5/5, Loss: 0.3090195879340172\n",
            "Step 9468, Epoch 5/5, Loss: 0.40336064994335175\n",
            "Step 9472, Epoch 5/5, Loss: 0.3450867235660553\n",
            "Step 9476, Epoch 5/5, Loss: 0.36612194031476974\n",
            "Step 9480, Epoch 5/5, Loss: 0.33146940916776657\n",
            "Step 9484, Epoch 5/5, Loss: 0.33204805105924606\n",
            "Step 9488, Epoch 5/5, Loss: 0.41303836554288864\n",
            "Step 9492, Epoch 5/5, Loss: 0.3039098456501961\n",
            "Step 9496, Epoch 5/5, Loss: 0.22952163964509964\n",
            "Step 9500, Epoch 5/5, Loss: 0.3513314351439476\n",
            "Step 9504, Epoch 5/5, Loss: 0.29387954622507095\n",
            "Step 9508, Epoch 5/5, Loss: 0.28356190770864487\n",
            "Step 9512, Epoch 5/5, Loss: 0.36344001442193985\n",
            "Step 9516, Epoch 5/5, Loss: 0.357275553047657\n",
            "Step 9520, Epoch 5/5, Loss: 0.31409434974193573\n",
            "Step 9524, Epoch 5/5, Loss: 0.3446747362613678\n",
            "Step 9528, Epoch 5/5, Loss: 0.2758898362517357\n",
            "Step 9532, Epoch 5/5, Loss: 0.2712079659104347\n",
            "Step 9536, Epoch 5/5, Loss: 0.40082765370607376\n",
            "Step 9540, Epoch 5/5, Loss: 0.29320894181728363\n",
            "Step 9544, Epoch 5/5, Loss: 0.33024824038147926\n",
            "Step 9548, Epoch 5/5, Loss: 0.3038271479308605\n",
            "Step 9552, Epoch 5/5, Loss: 0.28287724405527115\n",
            "Step 9556, Epoch 5/5, Loss: 0.2679269388318062\n",
            "Step 9560, Epoch 5/5, Loss: 0.2943117208778858\n",
            "Step 9564, Epoch 5/5, Loss: 0.3276289328932762\n",
            "Step 9568, Epoch 5/5, Loss: 0.3389689102768898\n",
            "Step 9572, Epoch 5/5, Loss: 0.3868383690714836\n",
            "Step 9576, Epoch 5/5, Loss: 0.3767918720841408\n",
            "Step 9580, Epoch 5/5, Loss: 0.26692749932408333\n",
            "Step 9584, Epoch 5/5, Loss: 0.3396727703511715\n",
            "Step 9588, Epoch 5/5, Loss: 0.32781681045889854\n",
            "Step 9592, Epoch 5/5, Loss: 0.2880590409040451\n",
            "Step 9596, Epoch 5/5, Loss: 0.3363587558269501\n",
            "Step 9600, Epoch 5/5, Loss: 0.3501322641968727\n",
            "Step 9604, Epoch 5/5, Loss: 0.3239612281322479\n",
            "Step 9608, Epoch 5/5, Loss: 0.30051758140325546\n",
            "Step 9612, Epoch 5/5, Loss: 0.2572319097816944\n",
            "Step 9616, Epoch 5/5, Loss: 0.3994062766432762\n",
            "Step 9620, Epoch 5/5, Loss: 0.2699523791670799\n",
            "Step 9624, Epoch 5/5, Loss: 0.2912948802113533\n",
            "Step 9628, Epoch 5/5, Loss: 0.30635853856801987\n",
            "Step 9632, Epoch 5/5, Loss: 0.3203742578625679\n",
            "Step 9636, Epoch 5/5, Loss: 0.27140000090003014\n",
            "Step 9640, Epoch 5/5, Loss: 0.325199156999588\n",
            "Step 9644, Epoch 5/5, Loss: 0.2892494201660156\n",
            "Step 9648, Epoch 5/5, Loss: 0.3156467042863369\n",
            "Step 9652, Epoch 5/5, Loss: 0.371693916618824\n",
            "Step 9656, Epoch 5/5, Loss: 0.3617340326309204\n",
            "Step 9660, Epoch 5/5, Loss: 0.29475629702210426\n",
            "Step 9664, Epoch 5/5, Loss: 0.38753048330545425\n",
            "Step 9668, Epoch 5/5, Loss: 0.268109492957592\n",
            "Step 9672, Epoch 5/5, Loss: 0.37301646918058395\n",
            "Step 9676, Epoch 5/5, Loss: 0.2945239320397377\n",
            "Step 9680, Epoch 5/5, Loss: 0.3774043619632721\n",
            "Step 9684, Epoch 5/5, Loss: 0.3624655157327652\n",
            "Step 9688, Epoch 5/5, Loss: 0.34884167835116386\n",
            "Step 9692, Epoch 5/5, Loss: 0.2820410206913948\n",
            "Step 9696, Epoch 5/5, Loss: 0.2577655650675297\n",
            "Step 9700, Epoch 5/5, Loss: 0.30952755361795425\n",
            "Step 9704, Epoch 5/5, Loss: 0.2832108624279499\n",
            "Step 9708, Epoch 5/5, Loss: 0.37425485998392105\n",
            "Step 9712, Epoch 5/5, Loss: 0.23887832835316658\n",
            "Step 9716, Epoch 5/5, Loss: 0.28127143159508705\n",
            "Step 9720, Epoch 5/5, Loss: 0.3027656599879265\n",
            "Step 9724, Epoch 5/5, Loss: 0.3090858682990074\n",
            "Step 9728, Epoch 5/5, Loss: 0.3779727444052696\n",
            "Step 9732, Epoch 5/5, Loss: 0.378906212747097\n",
            "Step 9736, Epoch 5/5, Loss: 0.26563766226172447\n",
            "Step 9740, Epoch 5/5, Loss: 0.2855679355561733\n",
            "Step 9744, Epoch 5/5, Loss: 0.3061538487672806\n",
            "Step 9748, Epoch 5/5, Loss: 0.3016356825828552\n",
            "Step 9752, Epoch 5/5, Loss: 0.3916000425815582\n",
            "Step 9756, Epoch 5/5, Loss: 0.37629494071006775\n",
            "Step 9760, Epoch 5/5, Loss: 0.42773906886577606\n",
            "Step 9764, Epoch 5/5, Loss: 0.22621865943074226\n",
            "Step 9768, Epoch 5/5, Loss: 0.3550952970981598\n",
            "Step 9772, Epoch 5/5, Loss: 0.2773202061653137\n",
            "Step 9776, Epoch 5/5, Loss: 0.331665500998497\n",
            "Step 9780, Epoch 5/5, Loss: 0.3000158816576004\n",
            "Step 9784, Epoch 5/5, Loss: 0.2968382090330124\n",
            "Step 9788, Epoch 5/5, Loss: 0.3541310578584671\n",
            "Step 9792, Epoch 5/5, Loss: 0.32897961139678955\n",
            "Step 9796, Epoch 5/5, Loss: 0.33776266872882843\n",
            "Step 9800, Epoch 5/5, Loss: 0.34656964614987373\n",
            "Step 9804, Epoch 5/5, Loss: 0.37904515862464905\n",
            "Step 9808, Epoch 5/5, Loss: 0.3648092821240425\n",
            "Step 9812, Epoch 5/5, Loss: 0.3379384018480778\n",
            "Step 9816, Epoch 5/5, Loss: 0.28531354665756226\n",
            "Step 9820, Epoch 5/5, Loss: 0.3298313245177269\n",
            "Step 9824, Epoch 5/5, Loss: 0.369868740439415\n",
            "Step 9828, Epoch 5/5, Loss: 0.3329496830701828\n",
            "Step 9832, Epoch 5/5, Loss: 0.3060278333723545\n",
            "Step 9836, Epoch 5/5, Loss: 0.3407007083296776\n",
            "Step 9840, Epoch 5/5, Loss: 0.3328765481710434\n",
            "Step 9844, Epoch 5/5, Loss: 0.3449684828519821\n",
            "Step 9848, Epoch 5/5, Loss: 0.31313739344477654\n",
            "Step 9852, Epoch 5/5, Loss: 0.3339768722653389\n",
            "Step 9856, Epoch 5/5, Loss: 0.3457106426358223\n",
            "Step 9860, Epoch 5/5, Loss: 0.3354327529668808\n",
            "Step 9864, Epoch 5/5, Loss: 0.3629818893969059\n",
            "Step 9868, Epoch 5/5, Loss: 0.3199768662452698\n",
            "Step 9872, Epoch 5/5, Loss: 0.36121758073568344\n",
            "Step 9876, Epoch 5/5, Loss: 0.32370907068252563\n",
            "Step 9880, Epoch 5/5, Loss: 0.29966362938284874\n",
            "Step 9884, Epoch 5/5, Loss: 0.2978968247771263\n",
            "Step 9888, Epoch 5/5, Loss: 0.28451360762119293\n",
            "Step 9892, Epoch 5/5, Loss: 0.3775065243244171\n",
            "Step 9896, Epoch 5/5, Loss: 0.297023456543684\n",
            "Step 9900, Epoch 5/5, Loss: 0.27497827261686325\n",
            "Step 9904, Epoch 5/5, Loss: 0.3943575322628021\n",
            "Step 9908, Epoch 5/5, Loss: 0.38901158422231674\n",
            "Step 9912, Epoch 5/5, Loss: 0.23527085036039352\n",
            "Step 9916, Epoch 5/5, Loss: 0.29339423030614853\n",
            "Step 9920, Epoch 5/5, Loss: 0.2903840057551861\n",
            "Step 9924, Epoch 5/5, Loss: 0.38473106920719147\n",
            "Step 9928, Epoch 5/5, Loss: 0.34088241308927536\n",
            "Step 9932, Epoch 5/5, Loss: 0.3235762044787407\n",
            "Step 9936, Epoch 5/5, Loss: 0.34101418405771255\n",
            "Step 9940, Epoch 5/5, Loss: 0.34191469848155975\n",
            "Step 9944, Epoch 5/5, Loss: 0.34815553948283195\n",
            "Step 9948, Epoch 5/5, Loss: 0.31125130876898766\n",
            "Step 9952, Epoch 5/5, Loss: 0.2979870103299618\n",
            "Step 9956, Epoch 5/5, Loss: 0.33115244656801224\n",
            "Step 9960, Epoch 5/5, Loss: 0.3062814176082611\n",
            "Step 9964, Epoch 5/5, Loss: 0.37445930019021034\n",
            "Step 9968, Epoch 5/5, Loss: 0.3271873742341995\n",
            "Step 9972, Epoch 5/5, Loss: 0.31722864508628845\n",
            "Step 9976, Epoch 5/5, Loss: 0.31931988149881363\n",
            "Step 9980, Epoch 5/5, Loss: 0.4148813635110855\n",
            "Step 9984, Epoch 5/5, Loss: 0.2898390218615532\n",
            "Step 9988, Epoch 5/5, Loss: 0.3162526898086071\n",
            "Step 9992, Epoch 5/5, Loss: 0.35016972571611404\n",
            "Step 9996, Epoch 5/5, Loss: 0.309981569647789\n",
            "Step 10000, Epoch 5/5, Loss: 0.3163388706743717\n",
            "Step 10004, Epoch 5/5, Loss: 0.2639501169323921\n",
            "Step 10008, Epoch 5/5, Loss: 0.3622225299477577\n",
            "Step 10012, Epoch 5/5, Loss: 0.4214562103152275\n",
            "Step 10016, Epoch 5/5, Loss: 0.3130456730723381\n",
            "Step 10020, Epoch 5/5, Loss: 0.27659158408641815\n",
            "Step 10024, Epoch 5/5, Loss: 0.34995900094509125\n",
            "Step 10028, Epoch 5/5, Loss: 0.271229799836874\n",
            "Step 10032, Epoch 5/5, Loss: 0.29032372310757637\n",
            "Step 10036, Epoch 5/5, Loss: 0.33890847116708755\n",
            "Step 10040, Epoch 5/5, Loss: 0.3326321579515934\n",
            "Step 10044, Epoch 5/5, Loss: 0.34068039059638977\n",
            "Step 10048, Epoch 5/5, Loss: 0.2942473627626896\n",
            "Step 10052, Epoch 5/5, Loss: 0.3123626708984375\n",
            "Step 10056, Epoch 5/5, Loss: 0.2791764698922634\n",
            "Step 10060, Epoch 5/5, Loss: 0.3366837240755558\n",
            "Step 10064, Epoch 5/5, Loss: 0.32418276369571686\n",
            "Step 10068, Epoch 5/5, Loss: 0.31040626764297485\n",
            "Step 10072, Epoch 5/5, Loss: 0.3324839919805527\n",
            "Step 10076, Epoch 5/5, Loss: 0.2236076518893242\n",
            "Step 10080, Epoch 5/5, Loss: 0.32293545082211494\n",
            "Step 10084, Epoch 5/5, Loss: 0.36698515713214874\n",
            "Step 10088, Epoch 5/5, Loss: 0.40489985048770905\n",
            "Step 10092, Epoch 5/5, Loss: 0.28651290386915207\n",
            "Step 10096, Epoch 5/5, Loss: 0.33046311140060425\n",
            "Step 10100, Epoch 5/5, Loss: 0.27638163045048714\n",
            "Step 10104, Epoch 5/5, Loss: 0.2551587149500847\n",
            "Step 10108, Epoch 5/5, Loss: 0.34223101288080215\n",
            "Step 10112, Epoch 5/5, Loss: 0.2996903285384178\n",
            "Step 10116, Epoch 5/5, Loss: 0.35249654203653336\n",
            "Step 10120, Epoch 5/5, Loss: 0.3496911749243736\n",
            "Step 10124, Epoch 5/5, Loss: 0.3171856291592121\n",
            "Step 10128, Epoch 5/5, Loss: 0.26384076476097107\n",
            "Step 10132, Epoch 5/5, Loss: 0.33295825868844986\n",
            "Step 10136, Epoch 5/5, Loss: 0.3660908378660679\n",
            "Step 10140, Epoch 5/5, Loss: 0.3197709061205387\n",
            "Step 10144, Epoch 5/5, Loss: 0.3667184002697468\n",
            "Step 10148, Epoch 5/5, Loss: 0.40792711824178696\n",
            "Step 10152, Epoch 5/5, Loss: 0.3722670301795006\n",
            "Step 10156, Epoch 5/5, Loss: 0.3410620465874672\n",
            "Step 10160, Epoch 5/5, Loss: 0.34415383636951447\n",
            "Step 10164, Epoch 5/5, Loss: 0.32477231323719025\n",
            "Step 10168, Epoch 5/5, Loss: 0.2974330298602581\n",
            "Step 10172, Epoch 5/5, Loss: 0.3013153225183487\n",
            "Step 10176, Epoch 5/5, Loss: 0.4191422164440155\n",
            "Step 10180, Epoch 5/5, Loss: 0.362159363925457\n",
            "Step 10184, Epoch 5/5, Loss: 0.29569289088249207\n",
            "Step 10188, Epoch 5/5, Loss: 0.334420382976532\n",
            "Step 10192, Epoch 5/5, Loss: 0.3090115524828434\n",
            "Step 10196, Epoch 5/5, Loss: 0.3458767347037792\n",
            "Step 10200, Epoch 5/5, Loss: 0.36560750007629395\n",
            "Step 10204, Epoch 5/5, Loss: 0.3586766794323921\n",
            "Step 10208, Epoch 5/5, Loss: 0.306515134871006\n",
            "Step 10212, Epoch 5/5, Loss: 0.32965780049562454\n",
            "Step 10216, Epoch 5/5, Loss: 0.34309785068035126\n",
            "Step 10220, Epoch 5/5, Loss: 0.2957472987473011\n",
            "Step 10224, Epoch 5/5, Loss: 0.3479676991701126\n",
            "Step 10228, Epoch 5/5, Loss: 0.34303780645132065\n",
            "Step 10232, Epoch 5/5, Loss: 0.21002045646309853\n",
            "Step 10236, Epoch 5/5, Loss: 0.3111969083547592\n",
            "Step 10240, Epoch 5/5, Loss: 0.3796672001481056\n",
            "Step 10244, Epoch 5/5, Loss: 0.3638320714235306\n",
            "Step 10248, Epoch 5/5, Loss: 0.31715185940265656\n",
            "Step 10252, Epoch 5/5, Loss: 0.33288049697875977\n",
            "Step 10256, Epoch 5/5, Loss: 0.32114066183567047\n",
            "Step 10260, Epoch 5/5, Loss: 0.28783632069826126\n",
            "Step 10264, Epoch 5/5, Loss: 0.3644789829850197\n",
            "Step 10268, Epoch 5/5, Loss: 0.29125456884503365\n",
            "Step 10272, Epoch 5/5, Loss: 0.2730710171163082\n",
            "Step 10276, Epoch 5/5, Loss: 0.36201415210962296\n",
            "Step 10280, Epoch 5/5, Loss: 0.3698488511145115\n",
            "Step 10284, Epoch 5/5, Loss: 0.3952145129442215\n",
            "Step 10288, Epoch 5/5, Loss: 0.2797967419028282\n",
            "Step 10292, Epoch 5/5, Loss: 0.2570164129137993\n",
            "Step 10296, Epoch 5/5, Loss: 0.2853505313396454\n",
            "Step 10300, Epoch 5/5, Loss: 0.3289768844842911\n",
            "Step 10304, Epoch 5/5, Loss: 0.3345845378935337\n",
            "Step 10308, Epoch 5/5, Loss: 0.3595607131719589\n",
            "Step 10312, Epoch 5/5, Loss: 0.29555805772542953\n",
            "Step 10316, Epoch 5/5, Loss: 0.3421982154250145\n",
            "Step 10320, Epoch 5/5, Loss: 0.36146609485149384\n",
            "Step 10324, Epoch 5/5, Loss: 0.29263126477599144\n",
            "Step 10328, Epoch 5/5, Loss: 0.32849884778261185\n",
            "Step 10332, Epoch 5/5, Loss: 0.2777177356183529\n",
            "Step 10336, Epoch 5/5, Loss: 0.38168029487133026\n",
            "Step 10340, Epoch 5/5, Loss: 0.2620800510048866\n",
            "Step 10344, Epoch 5/5, Loss: 0.3078366741538048\n",
            "Step 10348, Epoch 5/5, Loss: 0.3680878281593323\n",
            "Step 10352, Epoch 5/5, Loss: 0.3592817634344101\n",
            "Step 10356, Epoch 5/5, Loss: 0.30716947466135025\n",
            "Step 10360, Epoch 5/5, Loss: 0.2775094285607338\n",
            "Step 10364, Epoch 5/5, Loss: 0.3261554539203644\n",
            "Step 10368, Epoch 5/5, Loss: 0.27413033694028854\n",
            "Step 10372, Epoch 5/5, Loss: 0.350541390478611\n",
            "Step 10376, Epoch 5/5, Loss: 0.36856912821531296\n",
            "Step 10380, Epoch 5/5, Loss: 0.31671004369854927\n",
            "Step 10384, Epoch 5/5, Loss: 0.3556809797883034\n",
            "Step 10388, Epoch 5/5, Loss: 0.28182578831911087\n",
            "Step 10392, Epoch 5/5, Loss: 0.3184191659092903\n",
            "Step 10396, Epoch 5/5, Loss: 0.3314117081463337\n",
            "Step 10400, Epoch 5/5, Loss: 0.3667612597346306\n",
            "Step 10404, Epoch 5/5, Loss: 0.2901694029569626\n",
            "Step 10408, Epoch 5/5, Loss: 0.3822173662483692\n",
            "Step 10412, Epoch 5/5, Loss: 0.38354313373565674\n",
            "Step 10416, Epoch 5/5, Loss: 0.3628497049212456\n",
            "Step 10420, Epoch 5/5, Loss: 0.2359408438205719\n",
            "Step 10424, Epoch 5/5, Loss: 0.3154590502381325\n",
            "Step 10428, Epoch 5/5, Loss: 0.329720176756382\n",
            "Step 10432, Epoch 5/5, Loss: 0.27980516850948334\n",
            "Step 10436, Epoch 5/5, Loss: 0.2863232046365738\n",
            "Step 10440, Epoch 5/5, Loss: 0.3641507402062416\n",
            "Step 10444, Epoch 5/5, Loss: 0.3181259334087372\n",
            "Step 10448, Epoch 5/5, Loss: 0.35930532962083817\n",
            "Step 10452, Epoch 5/5, Loss: 0.33681827038526535\n",
            "Step 10456, Epoch 5/5, Loss: 0.29151729494333267\n",
            "Step 10460, Epoch 5/5, Loss: 0.3435165584087372\n",
            "Step 10464, Epoch 5/5, Loss: 0.35720394551754\n",
            "Step 10468, Epoch 5/5, Loss: 0.2906549796462059\n",
            "Step 10472, Epoch 5/5, Loss: 0.3066238537430763\n",
            "Step 10476, Epoch 5/5, Loss: 0.2917872406542301\n",
            "Step 10480, Epoch 5/5, Loss: 0.3532085157930851\n",
            "Step 10484, Epoch 5/5, Loss: 0.39552968740463257\n",
            "Step 10488, Epoch 5/5, Loss: 0.3768659457564354\n",
            "Step 10492, Epoch 5/5, Loss: 0.3358253948390484\n",
            "Step 10496, Epoch 5/5, Loss: 0.30146896466612816\n",
            "Step 10500, Epoch 5/5, Loss: 0.32547855377197266\n",
            "Step 10504, Epoch 5/5, Loss: 0.35948147624731064\n",
            "Step 10508, Epoch 5/5, Loss: 0.31408708170056343\n",
            "Step 10512, Epoch 5/5, Loss: 0.3341211676597595\n",
            "Step 10516, Epoch 5/5, Loss: 0.3769843876361847\n",
            "Step 10520, Epoch 5/5, Loss: 0.34345176070928574\n",
            "Step 10524, Epoch 5/5, Loss: 0.3759636953473091\n",
            "Step 10528, Epoch 5/5, Loss: 0.24377359449863434\n",
            "Step 10532, Epoch 5/5, Loss: 0.3458420932292938\n",
            "Step 10536, Epoch 5/5, Loss: 0.3242008537054062\n",
            "Step 10540, Epoch 5/5, Loss: 0.381743386387825\n",
            "Step 10544, Epoch 5/5, Loss: 0.391154445707798\n",
            "Step 10548, Epoch 5/5, Loss: 0.3348175287246704\n",
            "Step 10552, Epoch 5/5, Loss: 0.32121966406702995\n",
            "Step 10556, Epoch 5/5, Loss: 0.30604569613933563\n",
            "Step 10560, Epoch 5/5, Loss: 0.34672173112630844\n",
            "Step 10564, Epoch 5/5, Loss: 0.2646186761558056\n",
            "Step 10568, Epoch 5/5, Loss: 0.2646161578595638\n",
            "Step 10572, Epoch 5/5, Loss: 0.2926827296614647\n",
            "Step 10576, Epoch 5/5, Loss: 0.35532015934586525\n",
            "Step 10580, Epoch 5/5, Loss: 0.3158302307128906\n",
            "Step 10584, Epoch 5/5, Loss: 0.2817804217338562\n",
            "Step 10588, Epoch 5/5, Loss: 0.4125337675213814\n",
            "Step 10592, Epoch 5/5, Loss: 0.4073418453335762\n",
            "Step 10596, Epoch 5/5, Loss: 0.30318955332040787\n",
            "Step 10600, Epoch 5/5, Loss: 0.33884821832180023\n",
            "Step 10604, Epoch 5/5, Loss: 0.29858970269560814\n",
            "Step 10608, Epoch 5/5, Loss: 0.2815183959901333\n",
            "Step 10612, Epoch 5/5, Loss: 0.338062334805727\n",
            "Step 10616, Epoch 5/5, Loss: 0.2848452627658844\n",
            "Step 10620, Epoch 5/5, Loss: 0.4013886824250221\n",
            "Step 10624, Epoch 5/5, Loss: 0.2755366787314415\n",
            "Step 10628, Epoch 5/5, Loss: 0.23646048083901405\n",
            "Step 10632, Epoch 5/5, Loss: 0.3242524415254593\n",
            "Step 10636, Epoch 5/5, Loss: 0.31959889084100723\n",
            "Step 10640, Epoch 5/5, Loss: 0.3373994752764702\n",
            "Step 10644, Epoch 5/5, Loss: 0.29064612463116646\n",
            "Step 10648, Epoch 5/5, Loss: 0.2872832529246807\n",
            "Step 10652, Epoch 5/5, Loss: 0.37244515866041183\n",
            "Step 10656, Epoch 5/5, Loss: 0.36323266476392746\n",
            "Step 10660, Epoch 5/5, Loss: 0.32100848108530045\n",
            "Step 10664, Epoch 5/5, Loss: 0.2729492671787739\n",
            "Step 10668, Epoch 5/5, Loss: 0.3867264501750469\n",
            "Step 10672, Epoch 5/5, Loss: 0.38065699487924576\n",
            "Step 10676, Epoch 5/5, Loss: 0.30642690509557724\n",
            "Step 10680, Epoch 5/5, Loss: 0.24843506887555122\n",
            "Step 10684, Epoch 5/5, Loss: 0.284171923995018\n",
            "Step 10688, Epoch 5/5, Loss: 0.33455633372068405\n",
            "Step 10692, Epoch 5/5, Loss: 0.33743226528167725\n",
            "Step 10696, Epoch 5/5, Loss: 0.3452746495604515\n",
            "Step 10700, Epoch 5/5, Loss: 0.291805911809206\n",
            "Step 10704, Epoch 5/5, Loss: 0.33092621341347694\n",
            "Step 10708, Epoch 5/5, Loss: 0.27792804688215256\n",
            "Step 10712, Epoch 5/5, Loss: 0.39423974603414536\n",
            "Step 10716, Epoch 5/5, Loss: 0.27478494495153427\n",
            "Step 10720, Epoch 5/5, Loss: 0.3059745207428932\n",
            "Step 10724, Epoch 5/5, Loss: 0.32172010838985443\n",
            "Step 10728, Epoch 5/5, Loss: 0.2468094378709793\n",
            "Step 10732, Epoch 5/5, Loss: 0.32380614429712296\n",
            "Step 10736, Epoch 5/5, Loss: 0.3021203875541687\n",
            "Step 10740, Epoch 5/5, Loss: 0.3278105892241001\n",
            "Step 10744, Epoch 5/5, Loss: 0.31612569093704224\n",
            "Step 10748, Epoch 5/5, Loss: 0.35965055227279663\n",
            "Step 10752, Epoch 5/5, Loss: 0.30175111070275307\n",
            "Step 10756, Epoch 5/5, Loss: 0.2967895045876503\n",
            "Step 10760, Epoch 5/5, Loss: 0.2849804349243641\n",
            "Step 10764, Epoch 5/5, Loss: 0.33864470198750496\n",
            "Step 10768, Epoch 5/5, Loss: 0.25680869817733765\n",
            "Step 10772, Epoch 5/5, Loss: 0.3134467303752899\n",
            "Step 10776, Epoch 5/5, Loss: 0.2513803578913212\n",
            "Step 10780, Epoch 5/5, Loss: 0.2802557423710823\n",
            "Step 10784, Epoch 5/5, Loss: 0.3073391988873482\n",
            "Step 10788, Epoch 5/5, Loss: 0.3563065528869629\n",
            "Step 10792, Epoch 5/5, Loss: 0.3659750372171402\n",
            "Step 10796, Epoch 5/5, Loss: 0.3144962415099144\n",
            "Step 10800, Epoch 5/5, Loss: 0.3709319457411766\n",
            "Step 10804, Epoch 5/5, Loss: 0.30117783322930336\n",
            "Step 10808, Epoch 5/5, Loss: 0.3980996683239937\n",
            "Step 10812, Epoch 5/5, Loss: 0.3478272929787636\n",
            "Step 10816, Epoch 5/5, Loss: 0.36654698103666306\n",
            "Step 10820, Epoch 5/5, Loss: 0.3664313331246376\n",
            "Step 10824, Epoch 5/5, Loss: 0.34551166743040085\n",
            "Step 10828, Epoch 5/5, Loss: 0.32908186689019203\n",
            "Step 10832, Epoch 5/5, Loss: 0.3513505980372429\n",
            "Step 10836, Epoch 5/5, Loss: 0.30581337586045265\n",
            "Step 10840, Epoch 5/5, Loss: 0.35546498000621796\n",
            "Step 10844, Epoch 5/5, Loss: 0.3970010355114937\n",
            "Step 10848, Epoch 5/5, Loss: 0.29167694598436356\n",
            "Step 10852, Epoch 5/5, Loss: 0.3315499685704708\n",
            "Step 10856, Epoch 5/5, Loss: 0.24070541560649872\n",
            "Step 10860, Epoch 5/5, Loss: 0.3294287845492363\n",
            "Step 10864, Epoch 5/5, Loss: 0.35201551020145416\n",
            "Step 10868, Epoch 5/5, Loss: 0.2477887012064457\n",
            "Step 10872, Epoch 5/5, Loss: 0.3330145440995693\n",
            "Step 10876, Epoch 5/5, Loss: 0.29662033170461655\n",
            "Step 10880, Epoch 5/5, Loss: 0.31021474674344063\n",
            "Step 10884, Epoch 5/5, Loss: 0.32213954254984856\n",
            "Step 10888, Epoch 5/5, Loss: 0.3177311196923256\n",
            "Step 10892, Epoch 5/5, Loss: 0.3220803588628769\n",
            "Step 10896, Epoch 5/5, Loss: 0.336231354624033\n",
            "Step 10900, Epoch 5/5, Loss: 0.337692279368639\n",
            "Step 10904, Epoch 5/5, Loss: 0.28363192081451416\n",
            "Step 10908, Epoch 5/5, Loss: 0.34471892565488815\n",
            "Step 10912, Epoch 5/5, Loss: 0.3309975117444992\n",
            "Step 10916, Epoch 5/5, Loss: 0.31639276817440987\n",
            "Step 10920, Epoch 5/5, Loss: 0.29441727697849274\n",
            "Step 10924, Epoch 5/5, Loss: 0.3174804523587227\n",
            "Step 10928, Epoch 5/5, Loss: 0.32643020153045654\n",
            "Step 10932, Epoch 5/5, Loss: 0.37384331971406937\n",
            "Step 10936, Epoch 5/5, Loss: 0.3147107735276222\n",
            "Step 10940, Epoch 5/5, Loss: 0.35458283871412277\n",
            "Step 10944, Epoch 5/5, Loss: 0.27197104692459106\n",
            "Step 10948, Epoch 5/5, Loss: 0.27554308995604515\n",
            "Step 10952, Epoch 5/5, Loss: 0.36510568857192993\n",
            "Step 10956, Epoch 5/5, Loss: 0.284077025949955\n",
            "Step 10960, Epoch 5/5, Loss: 0.38687562942504883\n",
            "Step 10964, Epoch 5/5, Loss: 0.3284359723329544\n",
            "Step 10968, Epoch 5/5, Loss: 0.3241731971502304\n",
            "Step 10972, Epoch 5/5, Loss: 0.3572058007121086\n",
            "Step 10976, Epoch 5/5, Loss: 0.36510445177555084\n",
            "Step 10980, Epoch 5/5, Loss: 0.32376599684357643\n",
            "Step 10984, Epoch 5/5, Loss: 0.3098611980676651\n",
            "Step 10988, Epoch 5/5, Loss: 0.2875809334218502\n",
            "Step 10992, Epoch 5/5, Loss: 0.3194156661629677\n",
            "Step 10996, Epoch 5/5, Loss: 0.27906517684459686\n",
            "Step 11000, Epoch 5/5, Loss: 0.2535393051803112\n",
            "Step 11004, Epoch 5/5, Loss: 0.3743857219815254\n",
            "Step 11008, Epoch 5/5, Loss: 0.27440600097179413\n",
            "Step 11012, Epoch 5/5, Loss: 0.3712749034166336\n",
            "Step 11016, Epoch 5/5, Loss: 0.3343486003577709\n",
            "Step 11020, Epoch 5/5, Loss: 0.3433166891336441\n",
            "Step 11024, Epoch 5/5, Loss: 0.34170980751514435\n",
            "Step 11028, Epoch 5/5, Loss: 0.33536042273044586\n",
            "Step 11032, Epoch 5/5, Loss: 0.3720933496952057\n",
            "Step 11036, Epoch 5/5, Loss: 0.29137155786156654\n",
            "Step 11040, Epoch 5/5, Loss: 0.33798297494649887\n",
            "Step 11044, Epoch 5/5, Loss: 0.33517788350582123\n",
            "Step 11048, Epoch 5/5, Loss: 0.3257095515727997\n",
            "Step 11052, Epoch 5/5, Loss: 0.27559396252036095\n",
            "Step 11056, Epoch 5/5, Loss: 0.3275727480649948\n",
            "Step 11060, Epoch 5/5, Loss: 0.3162216395139694\n",
            "Step 11064, Epoch 5/5, Loss: 0.3926088884472847\n",
            "Step 11068, Epoch 5/5, Loss: 0.3819422572851181\n",
            "Step 11072, Epoch 5/5, Loss: 0.3005651980638504\n",
            "Step 11076, Epoch 5/5, Loss: 0.2268189750611782\n",
            "Step 11080, Epoch 5/5, Loss: 0.38015689700841904\n",
            "Step 11084, Epoch 5/5, Loss: 0.3011673390865326\n",
            "Step 11088, Epoch 5/5, Loss: 0.35186272859573364\n",
            "Step 11092, Epoch 5/5, Loss: 0.2992037385702133\n",
            "Step 11096, Epoch 5/5, Loss: 0.3360859043896198\n",
            "Step 11100, Epoch 5/5, Loss: 0.2730916179716587\n",
            "Step 11104, Epoch 5/5, Loss: 0.3054003491997719\n",
            "Step 11108, Epoch 5/5, Loss: 0.3018547296524048\n",
            "Step 11112, Epoch 5/5, Loss: 0.33582693338394165\n",
            "Step 11116, Epoch 5/5, Loss: 0.2858143225312233\n",
            "Step 11120, Epoch 5/5, Loss: 0.34766998142004013\n",
            "Step 11124, Epoch 5/5, Loss: 0.33546310663223267\n",
            "Step 11128, Epoch 5/5, Loss: 0.3196908086538315\n",
            "Step 11132, Epoch 5/5, Loss: 0.32261375337839127\n",
            "Step 11136, Epoch 5/5, Loss: 0.3163057044148445\n",
            "Step 11140, Epoch 5/5, Loss: 0.3803342171013355\n",
            "Step 11144, Epoch 5/5, Loss: 0.3236697241663933\n",
            "Step 11148, Epoch 5/5, Loss: 0.3098253458738327\n",
            "Step 11152, Epoch 5/5, Loss: 0.34355685114860535\n",
            "Step 11156, Epoch 5/5, Loss: 0.3212827630341053\n",
            "Step 11160, Epoch 5/5, Loss: 0.3898498937487602\n",
            "Step 11164, Epoch 5/5, Loss: 0.29817134141921997\n",
            "Step 11168, Epoch 5/5, Loss: 0.35172761231660843\n",
            "Step 11172, Epoch 5/5, Loss: 0.3381917178630829\n",
            "Step 11176, Epoch 5/5, Loss: 0.26448654383420944\n",
            "Step 11180, Epoch 5/5, Loss: 0.2892422638833523\n",
            "Step 11184, Epoch 5/5, Loss: 0.3199916407465935\n",
            "Step 11188, Epoch 5/5, Loss: 0.28456249460577965\n",
            "Step 11192, Epoch 5/5, Loss: 0.3639465495944023\n",
            "Step 11196, Epoch 5/5, Loss: 0.2900208681821823\n",
            "Step 11200, Epoch 5/5, Loss: 0.3125864453613758\n",
            "Step 11204, Epoch 5/5, Loss: 0.26471732556819916\n",
            "Step 11208, Epoch 5/5, Loss: 0.3309149406850338\n",
            "Step 11212, Epoch 5/5, Loss: 0.3049476407468319\n",
            "Step 11216, Epoch 5/5, Loss: 0.35026997327804565\n",
            "Step 11220, Epoch 5/5, Loss: 0.30786842852830887\n",
            "Step 11224, Epoch 5/5, Loss: 0.3545006886124611\n",
            "Step 11228, Epoch 5/5, Loss: 0.3343678116798401\n",
            "Step 11232, Epoch 5/5, Loss: 0.2843777611851692\n",
            "Step 11236, Epoch 5/5, Loss: 0.3037286512553692\n",
            "Step 11240, Epoch 5/5, Loss: 0.3201489970088005\n",
            "Step 11244, Epoch 5/5, Loss: 0.3088754266500473\n",
            "Step 11248, Epoch 5/5, Loss: 0.3418959006667137\n",
            "Step 11252, Epoch 5/5, Loss: 0.29125654697418213\n",
            "Step 11256, Epoch 5/5, Loss: 0.3779892362654209\n",
            "Step 11260, Epoch 5/5, Loss: 0.3715967833995819\n",
            "Step 11264, Epoch 5/5, Loss: 0.3633279651403427\n",
            "Step 11268, Epoch 5/5, Loss: 0.28605804219841957\n",
            "Step 11272, Epoch 5/5, Loss: 0.3571619242429733\n",
            "Step 11276, Epoch 5/5, Loss: 0.3310582600533962\n",
            "Step 11280, Epoch 5/5, Loss: 0.3403637371957302\n",
            "Step 11284, Epoch 5/5, Loss: 0.35771358013153076\n",
            "Step 11288, Epoch 5/5, Loss: 0.2656823880970478\n",
            "Step 11292, Epoch 5/5, Loss: 0.3159150220453739\n",
            "Step 11296, Epoch 5/5, Loss: 0.28134530037641525\n",
            "Step 11300, Epoch 5/5, Loss: 0.3284011036157608\n",
            "Step 11304, Epoch 5/5, Loss: 0.27639301493763924\n",
            "Step 11308, Epoch 5/5, Loss: 0.29009000584483147\n",
            "Step 11312, Epoch 5/5, Loss: 0.30923712998628616\n",
            "Step 11316, Epoch 5/5, Loss: 0.3589627668261528\n",
            "Step 11320, Epoch 5/5, Loss: 0.25565777346491814\n",
            "Step 11324, Epoch 5/5, Loss: 0.2969176024198532\n",
            "Step 11328, Epoch 5/5, Loss: 0.27651187777519226\n",
            "Step 11332, Epoch 5/5, Loss: 0.3254300579428673\n",
            "Step 11336, Epoch 5/5, Loss: 0.30453943461179733\n",
            "Step 11340, Epoch 5/5, Loss: 0.35544124990701675\n",
            "Step 11344, Epoch 5/5, Loss: 0.3026859164237976\n",
            "Step 11348, Epoch 5/5, Loss: 0.3304496929049492\n",
            "Step 11352, Epoch 5/5, Loss: 0.38508718460798264\n",
            "Step 11356, Epoch 5/5, Loss: 0.3573077842593193\n",
            "Step 11360, Epoch 5/5, Loss: 0.32057710736989975\n",
            "Step 11364, Epoch 5/5, Loss: 0.3247957229614258\n",
            "Step 11368, Epoch 5/5, Loss: 0.33306167274713516\n",
            "Step 11372, Epoch 5/5, Loss: 0.3792426362633705\n",
            "Step 11376, Epoch 5/5, Loss: 0.28226903453469276\n",
            "Step 11380, Epoch 5/5, Loss: 0.3525541424751282\n",
            "Step 11384, Epoch 5/5, Loss: 0.282345425337553\n",
            "Step 11388, Epoch 5/5, Loss: 0.36442678421735764\n",
            "Step 11392, Epoch 5/5, Loss: 0.4222779721021652\n",
            "Step 11396, Epoch 5/5, Loss: 0.30967796221375465\n",
            "Step 11400, Epoch 5/5, Loss: 0.3162233680486679\n",
            "Step 11404, Epoch 5/5, Loss: 0.37090595066547394\n",
            "Step 11408, Epoch 5/5, Loss: 0.2770046591758728\n",
            "Step 11412, Epoch 5/5, Loss: 0.32403627783060074\n",
            "Step 11416, Epoch 5/5, Loss: 0.3520122803747654\n",
            "Step 11420, Epoch 5/5, Loss: 0.36261969804763794\n",
            "Step 11424, Epoch 5/5, Loss: 0.30559927225112915\n",
            "Step 11428, Epoch 5/5, Loss: 0.34862493723630905\n",
            "Step 11432, Epoch 5/5, Loss: 0.3252413533627987\n",
            "Step 11436, Epoch 5/5, Loss: 0.36481545493006706\n",
            "Step 11440, Epoch 5/5, Loss: 0.3260362483561039\n",
            "Step 11444, Epoch 5/5, Loss: 0.3033175654709339\n",
            "Step 11448, Epoch 5/5, Loss: 0.3568905368447304\n",
            "Step 11452, Epoch 5/5, Loss: 0.366092786192894\n",
            "Step 11456, Epoch 5/5, Loss: 0.28893356025218964\n",
            "Step 11460, Epoch 5/5, Loss: 0.3750102072954178\n",
            "Step 11464, Epoch 5/5, Loss: 0.35606711357831955\n",
            "Step 11468, Epoch 5/5, Loss: 0.25390081480145454\n",
            "Step 11472, Epoch 5/5, Loss: 0.37557317316532135\n",
            "Step 11476, Epoch 5/5, Loss: 0.30712316185235977\n",
            "Step 11480, Epoch 5/5, Loss: 0.23238399624824524\n",
            "Step 11484, Epoch 5/5, Loss: 0.35772358253598213\n",
            "Step 11488, Epoch 5/5, Loss: 0.2893882468342781\n",
            "Step 11492, Epoch 5/5, Loss: 0.32319751009345055\n",
            "Step 11496, Epoch 5/5, Loss: 0.33930039405822754\n",
            "Step 11500, Epoch 5/5, Loss: 0.29913241043686867\n",
            "Step 11504, Epoch 5/5, Loss: 0.35979532450437546\n",
            "Step 11508, Epoch 5/5, Loss: 0.4037434011697769\n",
            "Step 11512, Epoch 5/5, Loss: 0.37213896214962006\n",
            "Step 11516, Epoch 5/5, Loss: 0.3764701187610626\n",
            "Step 11520, Epoch 5/5, Loss: 0.3466814309358597\n",
            "Step 11524, Epoch 5/5, Loss: 0.3634466901421547\n",
            "Step 11528, Epoch 5/5, Loss: 0.360565721988678\n",
            "Step 11532, Epoch 5/5, Loss: 0.2690197043120861\n",
            "Step 11536, Epoch 5/5, Loss: 0.31439898535609245\n",
            "Step 11540, Epoch 5/5, Loss: 0.31915193051099777\n",
            "Step 11544, Epoch 5/5, Loss: 0.3868836909532547\n",
            "Step 11548, Epoch 5/5, Loss: 0.36647728085517883\n",
            "Step 11552, Epoch 5/5, Loss: 0.39163850992918015\n",
            "Step 11556, Epoch 5/5, Loss: 0.30482126772403717\n",
            "Step 11560, Epoch 5/5, Loss: 0.30955294147133827\n",
            "Step 11564, Epoch 5/5, Loss: 0.37271352112293243\n",
            "Step 11568, Epoch 5/5, Loss: 0.33705421537160873\n",
            "Step 11572, Epoch 5/5, Loss: 0.3157346621155739\n",
            "Step 11576, Epoch 5/5, Loss: 0.3087656535208225\n",
            "Step 11580, Epoch 5/5, Loss: 0.3197750002145767\n",
            "Step 11584, Epoch 5/5, Loss: 0.30765994638204575\n",
            "Step 11588, Epoch 5/5, Loss: 0.35886064171791077\n",
            "Step 11592, Epoch 5/5, Loss: 0.3851627707481384\n",
            "Step 11596, Epoch 5/5, Loss: 0.31820231303572655\n",
            "Step 11600, Epoch 5/5, Loss: 0.3178665116429329\n",
            "Step 11604, Epoch 5/5, Loss: 0.35040054470300674\n",
            "Step 11608, Epoch 5/5, Loss: 0.32277005165815353\n",
            "Step 11612, Epoch 5/5, Loss: 0.40807273238897324\n",
            "Step 11616, Epoch 5/5, Loss: 0.36036885157227516\n",
            "Step 11620, Epoch 5/5, Loss: 0.2815076559782028\n",
            "Step 11624, Epoch 5/5, Loss: 0.26267148926854134\n",
            "Step 11628, Epoch 5/5, Loss: 0.2973065711557865\n",
            "Step 11632, Epoch 5/5, Loss: 0.3091190420091152\n",
            "Step 11636, Epoch 5/5, Loss: 0.2897167429327965\n",
            "Step 11640, Epoch 5/5, Loss: 0.29910727962851524\n",
            "Step 11644, Epoch 5/5, Loss: 0.3758864030241966\n",
            "Step 11648, Epoch 5/5, Loss: 0.3419375866651535\n",
            "Step 11652, Epoch 5/5, Loss: 0.24068057164549828\n",
            "Step 11656, Epoch 5/5, Loss: 0.3445173054933548\n",
            "Step 11660, Epoch 5/5, Loss: 0.3773570954799652\n",
            "Step 11664, Epoch 5/5, Loss: 0.36934833973646164\n",
            "Step 11668, Epoch 5/5, Loss: 0.3127714768052101\n",
            "Step 11672, Epoch 5/5, Loss: 0.3570651561021805\n",
            "Step 11676, Epoch 5/5, Loss: 0.30475036054849625\n",
            "Step 11680, Epoch 5/5, Loss: 0.3619711771607399\n",
            "Step 11684, Epoch 5/5, Loss: 0.29531068727374077\n",
            "Step 11688, Epoch 5/5, Loss: 0.3547161966562271\n",
            "Step 11692, Epoch 5/5, Loss: 0.32663359493017197\n",
            "Step 11696, Epoch 5/5, Loss: 0.32832564413547516\n",
            "Step 11700, Epoch 5/5, Loss: 0.265494741499424\n",
            "Step 11704, Epoch 5/5, Loss: 0.33082520216703415\n",
            "Step 11708, Epoch 5/5, Loss: 0.34737221524119377\n",
            "Step 11712, Epoch 5/5, Loss: 0.3159122131764889\n",
            "Step 11716, Epoch 5/5, Loss: 0.30703533440828323\n",
            "Step 11720, Epoch 5/5, Loss: 0.36628979444503784\n",
            "Step 11724, Epoch 5/5, Loss: 0.30501193180680275\n",
            "Step 11728, Epoch 5/5, Loss: 0.3370439410209656\n",
            "Step 11732, Epoch 5/5, Loss: 0.3193962424993515\n",
            "Step 11736, Epoch 5/5, Loss: 0.35264863818883896\n",
            "Step 11740, Epoch 5/5, Loss: 0.3143790066242218\n",
            "Step 11744, Epoch 5/5, Loss: 0.3164404481649399\n",
            "Step 11748, Epoch 5/5, Loss: 0.2902948819100857\n",
            "Step 11752, Epoch 5/5, Loss: 0.29836396127939224\n",
            "Step 11756, Epoch 5/5, Loss: 0.2541416883468628\n",
            "Step 11760, Epoch 5/5, Loss: 0.37756868451833725\n",
            "Step 11764, Epoch 5/5, Loss: 0.30269555002450943\n",
            "Step 11768, Epoch 5/5, Loss: 0.3470102548599243\n",
            "Step 11772, Epoch 5/5, Loss: 0.3234676718711853\n",
            "Step 11776, Epoch 5/5, Loss: 0.30582820624113083\n",
            "Step 11780, Epoch 5/5, Loss: 0.3005843125283718\n",
            "Step 11784, Epoch 5/5, Loss: 0.3119356781244278\n",
            "Step 11788, Epoch 5/5, Loss: 0.33657970651984215\n",
            "Step 11792, Epoch 5/5, Loss: 0.2621537148952484\n",
            "Step 11796, Epoch 5/5, Loss: 0.3040205016732216\n",
            "Step 11800, Epoch 5/5, Loss: 0.30963433533906937\n",
            "Step 11804, Epoch 5/5, Loss: 0.25357710942626\n",
            "Step 11808, Epoch 5/5, Loss: 0.29518041759729385\n",
            "Step 11812, Epoch 5/5, Loss: 0.32887786626815796\n",
            "Step 11816, Epoch 5/5, Loss: 0.30006709322333336\n",
            "Step 11820, Epoch 5/5, Loss: 0.29466238245368004\n",
            "Step 11824, Epoch 5/5, Loss: 0.3171996548771858\n",
            "Step 11828, Epoch 5/5, Loss: 0.35134948045015335\n",
            "Step 11832, Epoch 5/5, Loss: 0.3478602021932602\n",
            "Step 11836, Epoch 5/5, Loss: 0.3643585219979286\n",
            "Step 11840, Epoch 5/5, Loss: 0.34826764836907387\n",
            "Step 11844, Epoch 5/5, Loss: 0.3459911644458771\n",
            "Step 11848, Epoch 5/5, Loss: 0.32506202161312103\n",
            "Step 11852, Epoch 5/5, Loss: 0.36526336520910263\n",
            "Step 11856, Epoch 5/5, Loss: 0.3197605274617672\n",
            "Step 11860, Epoch 5/5, Loss: 0.3534146584570408\n",
            "Step 11864, Epoch 5/5, Loss: 0.40325602889060974\n",
            "Step 11868, Epoch 5/5, Loss: 0.3886684626340866\n",
            "Step 11872, Epoch 5/5, Loss: 0.37048835307359695\n",
            "Step 11876, Epoch 5/5, Loss: 0.357363760471344\n",
            "Step 11880, Epoch 5/5, Loss: 0.3646447956562042\n",
            "Step 11884, Epoch 5/5, Loss: 0.35386744886636734\n",
            "Step 11888, Epoch 5/5, Loss: 0.32210545241832733\n",
            "Step 11892, Epoch 5/5, Loss: 0.36151865869760513\n",
            "Step 11896, Epoch 5/5, Loss: 0.39464423805475235\n",
            "Step 11900, Epoch 5/5, Loss: 0.31810203939676285\n",
            "Step 11904, Epoch 5/5, Loss: 0.3010970205068588\n",
            "Step 11908, Epoch 5/5, Loss: 0.3371410146355629\n",
            "Step 11912, Epoch 5/5, Loss: 0.32674527168273926\n",
            "Step 11916, Epoch 5/5, Loss: 0.24182507768273354\n",
            "Step 11920, Epoch 5/5, Loss: 0.34719473123550415\n",
            "Step 11924, Epoch 5/5, Loss: 0.328416895121336\n",
            "Step 11928, Epoch 5/5, Loss: 0.33562588691711426\n",
            "Step 11932, Epoch 5/5, Loss: 0.31768959388136864\n",
            "Step 11936, Epoch 5/5, Loss: 0.3442389704287052\n",
            "Step 11940, Epoch 5/5, Loss: 0.30352695286273956\n",
            "Step 11944, Epoch 5/5, Loss: 0.33226772397756577\n",
            "Step 11948, Epoch 5/5, Loss: 0.34554623067379\n",
            "Step 11952, Epoch 5/5, Loss: 0.25251783803105354\n",
            "Step 11956, Epoch 5/5, Loss: 0.3480831906199455\n",
            "Step 11960, Epoch 5/5, Loss: 0.25878414139151573\n",
            "Step 11964, Epoch 5/5, Loss: 0.3353637456893921\n",
            "Step 11968, Epoch 5/5, Loss: 0.315692700445652\n",
            "Step 11972, Epoch 5/5, Loss: 0.36496879160404205\n",
            "Step 11976, Epoch 5/5, Loss: 0.32437993213534355\n",
            "Step 11980, Epoch 5/5, Loss: 0.3445284813642502\n",
            "Step 11984, Epoch 5/5, Loss: 0.3623972460627556\n",
            "Step 11988, Epoch 5/5, Loss: 0.3386680856347084\n",
            "Step 11992, Epoch 5/5, Loss: 0.4245792180299759\n",
            "Step 11996, Epoch 5/5, Loss: 0.3619357943534851\n",
            "Step 12000, Epoch 5/5, Loss: 0.38240374624729156\n",
            "Step 12004, Epoch 5/5, Loss: 0.24701643362641335\n",
            "Step 12008, Epoch 5/5, Loss: 0.31915126740932465\n",
            "Step 12012, Epoch 5/5, Loss: 0.28371572867035866\n",
            "Step 12016, Epoch 5/5, Loss: 0.3933342546224594\n",
            "Step 12020, Epoch 5/5, Loss: 0.31870440021157265\n",
            "Step 12024, Epoch 5/5, Loss: 0.3642110861837864\n",
            "Step 12028, Epoch 5/5, Loss: 0.38669417053461075\n",
            "Step 12032, Epoch 5/5, Loss: 0.33288291469216347\n",
            "Step 12036, Epoch 5/5, Loss: 0.35415901243686676\n",
            "Step 12040, Epoch 5/5, Loss: 0.31727270781993866\n",
            "Step 12044, Epoch 5/5, Loss: 0.3163302503526211\n",
            "Step 12048, Epoch 5/5, Loss: 0.34936483204364777\n",
            "Step 12052, Epoch 5/5, Loss: 0.30489450693130493\n",
            "Step 12056, Epoch 5/5, Loss: 0.31445175409317017\n",
            "Step 12060, Epoch 5/5, Loss: 0.29843689501285553\n",
            "Step 12064, Epoch 5/5, Loss: 0.4223976731300354\n",
            "Step 12068, Epoch 5/5, Loss: 0.311821348965168\n",
            "Step 12072, Epoch 5/5, Loss: 0.20711053907871246\n",
            "Step 12076, Epoch 5/5, Loss: 0.2699835076928139\n",
            "Step 12080, Epoch 5/5, Loss: 0.3585634231567383\n",
            "Step 12084, Epoch 5/5, Loss: 0.28824087977409363\n",
            "Step 12088, Epoch 5/5, Loss: 0.3786802142858505\n",
            "Step 12092, Epoch 5/5, Loss: 0.297606747597456\n",
            "Step 12096, Epoch 5/5, Loss: 0.2994198426604271\n",
            "Step 12100, Epoch 5/5, Loss: 0.29132596030831337\n",
            "Step 12104, Epoch 5/5, Loss: 0.3309624642133713\n",
            "Step 12108, Epoch 5/5, Loss: 0.3462468758225441\n",
            "Step 12112, Epoch 5/5, Loss: 0.3125323951244354\n",
            "Step 12116, Epoch 5/5, Loss: 0.3022451102733612\n",
            "Step 12120, Epoch 5/5, Loss: 0.28239681199193\n",
            "Step 12124, Epoch 5/5, Loss: 0.3238075487315655\n",
            "Step 12128, Epoch 5/5, Loss: 0.2600441090762615\n",
            "Step 12132, Epoch 5/5, Loss: 0.3169974759221077\n",
            "Step 12136, Epoch 5/5, Loss: 0.3047102838754654\n",
            "Step 12140, Epoch 5/5, Loss: 0.2743627727031708\n",
            "Step 12144, Epoch 5/5, Loss: 0.34074220061302185\n",
            "Step 12148, Epoch 5/5, Loss: 0.3675098568201065\n",
            "Step 12152, Epoch 5/5, Loss: 0.29134704917669296\n",
            "Step 12156, Epoch 5/5, Loss: 0.3002582862973213\n",
            "Step 12160, Epoch 5/5, Loss: 0.34396323561668396\n",
            "Step 12164, Epoch 5/5, Loss: 0.29785777255892754\n",
            "Step 12168, Epoch 5/5, Loss: 0.3264942243695259\n",
            "Step 12172, Epoch 5/5, Loss: 0.30831948667764664\n",
            "Step 12176, Epoch 5/5, Loss: 0.43741949647665024\n",
            "Step 12180, Epoch 5/5, Loss: 0.3771787956357002\n",
            "Step 12184, Epoch 5/5, Loss: 0.3078544922173023\n",
            "Step 12188, Epoch 5/5, Loss: 0.31348517537117004\n",
            "Step 12192, Epoch 5/5, Loss: 0.29173342883586884\n",
            "Step 12196, Epoch 5/5, Loss: 0.2979118935763836\n",
            "Step 12200, Epoch 5/5, Loss: 0.3685968965291977\n",
            "Step 12204, Epoch 5/5, Loss: 0.4047645255923271\n",
            "Step 12208, Epoch 5/5, Loss: 0.39030771702528\n",
            "Step 12212, Epoch 5/5, Loss: 0.3451824449002743\n",
            "Step 12216, Epoch 5/5, Loss: 0.3083069957792759\n",
            "Step 12220, Epoch 5/5, Loss: 0.322849303483963\n",
            "Step 12224, Epoch 5/5, Loss: 0.2853130027651787\n",
            "Step 12228, Epoch 5/5, Loss: 0.3294637054204941\n",
            "Step 12232, Epoch 5/5, Loss: 0.315116498619318\n",
            "Step 12236, Epoch 5/5, Loss: 0.29673250392079353\n",
            "Step 12240, Epoch 5/5, Loss: 0.32637060433626175\n",
            "Step 12244, Epoch 5/5, Loss: 0.3133132942020893\n",
            "Step 12248, Epoch 5/5, Loss: 0.3390347585082054\n",
            "Step 12252, Epoch 5/5, Loss: 0.3370789363980293\n",
            "Step 12256, Epoch 5/5, Loss: 0.2858216129243374\n",
            "Step 12260, Epoch 5/5, Loss: 0.3376682922244072\n",
            "Step 12264, Epoch 5/5, Loss: 0.2811255641281605\n",
            "Step 12268, Epoch 5/5, Loss: 0.31369171664118767\n",
            "Step 12272, Epoch 5/5, Loss: 0.3318120390176773\n",
            "Step 12276, Epoch 5/5, Loss: 0.33913296461105347\n",
            "Step 12280, Epoch 5/5, Loss: 0.3045635260641575\n",
            "Step 12284, Epoch 5/5, Loss: 0.3441280722618103\n",
            "Step 12288, Epoch 5/5, Loss: 0.23429885879158974\n",
            "Step 12292, Epoch 5/5, Loss: 0.31776516884565353\n",
            "Step 12296, Epoch 5/5, Loss: 0.2687423788011074\n",
            "Step 12300, Epoch 5/5, Loss: 0.3497980386018753\n",
            "Step 12304, Epoch 5/5, Loss: 0.4014473259449005\n",
            "Step 12308, Epoch 5/5, Loss: 0.3095238283276558\n",
            "Step 12312, Epoch 5/5, Loss: 0.3040500804781914\n",
            "Step 12316, Epoch 5/5, Loss: 0.4156772568821907\n",
            "Step 12320, Epoch 5/5, Loss: 0.3032931014895439\n",
            "Step 12324, Epoch 5/5, Loss: 0.2905079089105129\n",
            "Step 12328, Epoch 5/5, Loss: 0.3057791069149971\n",
            "Step 12332, Epoch 5/5, Loss: 0.35002318024635315\n",
            "Step 12336, Epoch 5/5, Loss: 0.3359190747141838\n",
            "Step 12340, Epoch 5/5, Loss: 0.3068137355148792\n",
            "Step 12344, Epoch 5/5, Loss: 0.2335883565247059\n",
            "Step 12348, Epoch 5/5, Loss: 0.27277354151010513\n",
            "Step 12352, Epoch 5/5, Loss: 0.23961614072322845\n",
            "Step 12356, Epoch 5/5, Loss: 0.3527892343699932\n",
            "Step 12360, Epoch 5/5, Loss: 0.3327680416405201\n",
            "Step 12364, Epoch 5/5, Loss: 0.30042266100645065\n",
            "Step 12368, Epoch 5/5, Loss: 0.3455430939793587\n",
            "Step 12372, Epoch 5/5, Loss: 0.3941134437918663\n",
            "Step 12376, Epoch 5/5, Loss: 0.3603567108511925\n",
            "Step 12380, Epoch 5/5, Loss: 0.24277837947010994\n",
            "Step 12384, Epoch 5/5, Loss: 0.2696780189871788\n",
            "Step 12388, Epoch 5/5, Loss: 0.37836187332868576\n",
            "Step 12392, Epoch 5/5, Loss: 0.2586895376443863\n",
            "Step 12396, Epoch 5/5, Loss: 0.28845513239502907\n",
            "Step 12400, Epoch 5/5, Loss: 0.38049158453941345\n",
            "Step 12404, Epoch 5/5, Loss: 0.3303196504712105\n",
            "Step 12408, Epoch 5/5, Loss: 0.24110614508390427\n",
            "Step 12412, Epoch 5/5, Loss: 0.3213629089295864\n",
            "Step 12416, Epoch 5/5, Loss: 0.3137929327785969\n",
            "Step 12420, Epoch 5/5, Loss: 0.3110182136297226\n",
            "Step 12424, Epoch 5/5, Loss: 0.23857811838388443\n",
            "Step 12428, Epoch 5/5, Loss: 0.33425406366586685\n",
            "Step 12432, Epoch 5/5, Loss: 0.3964589983224869\n",
            "Step 12436, Epoch 5/5, Loss: 0.2705469988286495\n",
            "Step 12440, Epoch 5/5, Loss: 0.2752988189458847\n",
            "Step 12444, Epoch 5/5, Loss: 0.3734991252422333\n",
            "Step 12448, Epoch 5/5, Loss: 0.2680257745087147\n",
            "Step 12452, Epoch 5/5, Loss: 0.36813338100910187\n",
            "Step 12456, Epoch 5/5, Loss: 0.32699283584952354\n",
            "Step 12460, Epoch 5/5, Loss: 0.37961719930171967\n",
            "Step 12464, Epoch 5/5, Loss: 0.3217737153172493\n",
            "Step 12468, Epoch 5/5, Loss: 0.3865714445710182\n",
            "Step 12472, Epoch 5/5, Loss: 0.31966136768460274\n",
            "Step 12476, Epoch 5/5, Loss: 0.2693863660097122\n",
            "Step 12480, Epoch 5/5, Loss: 0.36415281146764755\n",
            "Step 12484, Epoch 5/5, Loss: 0.3463253229856491\n",
            "Step 12488, Epoch 5/5, Loss: 0.39932534843683243\n",
            "Step 12492, Epoch 5/5, Loss: 0.30459608137607574\n",
            "Step 12496, Epoch 5/5, Loss: 0.3478844314813614\n",
            "Step 12500, Epoch 5/5, Loss: 0.3810710087418556\n",
            "Step 12504, Epoch 5/5, Loss: 0.23553551733493805\n",
            "Step 12508, Epoch 5/5, Loss: 0.3338714726269245\n",
            "Step 12512, Epoch 5/5, Loss: 0.3145340010523796\n",
            "Step 12516, Epoch 5/5, Loss: 0.24400868266820908\n",
            "Step 12520, Epoch 5/5, Loss: 0.3203675001859665\n",
            "Step 12524, Epoch 5/5, Loss: 0.29700782522559166\n",
            "Step 12528, Epoch 5/5, Loss: 0.35496465116739273\n",
            "Step 12532, Epoch 5/5, Loss: 0.3586018830537796\n",
            "Step 12536, Epoch 5/5, Loss: 0.33167024329304695\n",
            "Step 12540, Epoch 5/5, Loss: 0.3325567878782749\n",
            "Step 12544, Epoch 5/5, Loss: 0.38663250207901\n",
            "Step 12548, Epoch 5/5, Loss: 0.25647781789302826\n",
            "Step 12552, Epoch 5/5, Loss: 0.3073897883296013\n",
            "Step 12556, Epoch 5/5, Loss: 0.3731035590171814\n",
            "Step 12560, Epoch 5/5, Loss: 0.3521023616194725\n",
            "Step 12564, Epoch 5/5, Loss: 0.2779015302658081\n",
            "Step 12568, Epoch 5/5, Loss: 0.31844303011894226\n",
            "Step 12572, Epoch 5/5, Loss: 0.3159061521291733\n",
            "Step 12576, Epoch 5/5, Loss: 0.29252463951706886\n",
            "Step 12580, Epoch 5/5, Loss: 0.3458046391606331\n",
            "Step 12584, Epoch 5/5, Loss: 0.3771323934197426\n",
            "Step 12588, Epoch 5/5, Loss: 0.3851083442568779\n",
            "Step 12592, Epoch 5/5, Loss: 0.3768007531762123\n",
            "Step 12596, Epoch 5/5, Loss: 0.2719302922487259\n",
            "Step 12600, Epoch 5/5, Loss: 0.35982654243707657\n",
            "Step 12604, Epoch 5/5, Loss: 0.37025878578424454\n",
            "Step 12608, Epoch 5/5, Loss: 0.35251056030392647\n",
            "Step 12612, Epoch 5/5, Loss: 0.35719694942235947\n",
            "Step 12616, Epoch 5/5, Loss: 0.36609945446252823\n",
            "Step 12620, Epoch 5/5, Loss: 0.40195682644844055\n",
            "Step 12624, Epoch 5/5, Loss: 0.4087173715233803\n",
            "Step 12628, Epoch 5/5, Loss: 0.2783089466392994\n",
            "Step 12632, Epoch 5/5, Loss: 0.3052702620625496\n",
            "Step 12636, Epoch 5/5, Loss: 0.3428202494978905\n",
            "Step 12640, Epoch 5/5, Loss: 0.3156055100262165\n",
            "Step 12644, Epoch 5/5, Loss: 0.39831238985061646\n",
            "Step 12648, Epoch 5/5, Loss: 0.2864529527723789\n",
            "Step 12652, Epoch 5/5, Loss: 0.32411617785692215\n",
            "Step 12656, Epoch 5/5, Loss: 0.2686355747282505\n",
            "Step 12660, Epoch 5/5, Loss: 0.35492855310440063\n",
            "Step 12664, Epoch 5/5, Loss: 0.3374990224838257\n",
            "Step 12668, Epoch 5/5, Loss: 0.3079875595867634\n",
            "Step 12672, Epoch 5/5, Loss: 0.3535134196281433\n",
            "Step 12676, Epoch 5/5, Loss: 0.31462862715125084\n",
            "Step 12680, Epoch 5/5, Loss: 0.31544287502765656\n",
            "Step 12684, Epoch 5/5, Loss: 0.32570844143629074\n",
            "Step 12688, Epoch 5/5, Loss: 0.3391724228858948\n",
            "Step 12692, Epoch 5/5, Loss: 0.2731623575091362\n",
            "Step 12696, Epoch 5/5, Loss: 0.2680089958012104\n",
            "Step 12700, Epoch 5/5, Loss: 0.34595804661512375\n",
            "Step 12704, Epoch 5/5, Loss: 0.36457663029432297\n",
            "Step 12708, Epoch 5/5, Loss: 0.2666744105517864\n",
            "Step 12712, Epoch 5/5, Loss: 0.298955574631691\n",
            "Step 12716, Epoch 5/5, Loss: 0.2232414036989212\n",
            "Step 12720, Epoch 5/5, Loss: 0.33596518635749817\n",
            "Step 12724, Epoch 5/5, Loss: 0.29623379558324814\n",
            "Step 12728, Epoch 5/5, Loss: 0.27004658430814743\n",
            "Step 12732, Epoch 5/5, Loss: 0.3317456468939781\n",
            "Step 12736, Epoch 5/5, Loss: 0.31985389813780785\n",
            "Step 12740, Epoch 5/5, Loss: 0.35624195635318756\n",
            "Step 12744, Epoch 5/5, Loss: 0.24376896396279335\n",
            "Step 12748, Epoch 5/5, Loss: 0.2639416381716728\n",
            "Step 12752, Epoch 5/5, Loss: 0.3035201467573643\n",
            "Step 12756, Epoch 5/5, Loss: 0.28077273443341255\n",
            "Step 12760, Epoch 5/5, Loss: 0.31699249148368835\n",
            "Step 12764, Epoch 5/5, Loss: 0.29027313739061356\n",
            "Step 12768, Epoch 5/5, Loss: 0.31798694282770157\n",
            "Step 12772, Epoch 5/5, Loss: 0.27569886296987534\n",
            "Step 12776, Epoch 5/5, Loss: 0.3163985460996628\n",
            "Step 12780, Epoch 5/5, Loss: 0.3181835785508156\n",
            "Step 12784, Epoch 5/5, Loss: 0.2883826047182083\n",
            "Step 12788, Epoch 5/5, Loss: 0.31899532675743103\n",
            "Step 12792, Epoch 5/5, Loss: 0.3070640601217747\n",
            "Step 12796, Epoch 5/5, Loss: 0.3128647655248642\n",
            "Step 12800, Epoch 5/5, Loss: 0.2891097962856293\n",
            "Step 12804, Epoch 5/5, Loss: 0.24037158116698265\n",
            "Step 12808, Epoch 5/5, Loss: 0.3346126303076744\n",
            "Step 12812, Epoch 5/5, Loss: 0.3324361518025398\n",
            "Step 12816, Epoch 5/5, Loss: 0.3080318160355091\n",
            "Step 12820, Epoch 5/5, Loss: 0.32986031472682953\n",
            "Step 12824, Epoch 5/5, Loss: 0.2705840989947319\n",
            "Step 12828, Epoch 5/5, Loss: 0.3542422875761986\n",
            "Step 12832, Epoch 5/5, Loss: 0.38548190891742706\n",
            "Step 12836, Epoch 5/5, Loss: 0.26743463799357414\n",
            "Step 12840, Epoch 5/5, Loss: 0.3930707052350044\n",
            "Step 12844, Epoch 5/5, Loss: 0.2931983843445778\n",
            "Step 12848, Epoch 5/5, Loss: 0.32110241800546646\n",
            "Step 12852, Epoch 5/5, Loss: 0.29727620631456375\n",
            "Step 12856, Epoch 5/5, Loss: 0.3067435249686241\n",
            "Step 12860, Epoch 5/5, Loss: 0.3540250025689602\n",
            "Step 12864, Epoch 5/5, Loss: 0.36746061593294144\n",
            "Step 12868, Epoch 5/5, Loss: 0.3456648290157318\n",
            "Step 12872, Epoch 5/5, Loss: 0.3696081414818764\n",
            "Step 12876, Epoch 5/5, Loss: 0.4204467236995697\n",
            "Step 12880, Epoch 5/5, Loss: 0.35004156082868576\n",
            "Step 12884, Epoch 5/5, Loss: 0.33035679906606674\n",
            "Step 12888, Epoch 5/5, Loss: 0.39700083434581757\n",
            "Step 12892, Epoch 5/5, Loss: 0.30541525036096573\n",
            "Step 12896, Epoch 5/5, Loss: 0.22727228328585625\n",
            "Step 12900, Epoch 5/5, Loss: 0.25367946177721024\n",
            "Step 12904, Epoch 5/5, Loss: 0.30188068747520447\n",
            "Step 12908, Epoch 5/5, Loss: 0.3118646740913391\n",
            "Step 12912, Epoch 5/5, Loss: 0.3672412261366844\n",
            "Step 12916, Epoch 5/5, Loss: 0.3704909011721611\n",
            "Step 12920, Epoch 5/5, Loss: 0.2541007809340954\n",
            "Step 12924, Epoch 5/5, Loss: 0.29087740927934647\n",
            "Step 12928, Epoch 5/5, Loss: 0.2965533025562763\n",
            "Step 12932, Epoch 5/5, Loss: 0.3394191265106201\n",
            "Step 12936, Epoch 5/5, Loss: 0.4010813608765602\n",
            "Step 12940, Epoch 5/5, Loss: 0.3321203216910362\n",
            "Step 12944, Epoch 5/5, Loss: 0.2762247659265995\n",
            "Step 12948, Epoch 5/5, Loss: 0.35807333141565323\n",
            "Step 12952, Epoch 5/5, Loss: 0.30301788821816444\n",
            "Step 12956, Epoch 5/5, Loss: 0.3156393989920616\n",
            "Step 12960, Epoch 5/5, Loss: 0.31279895454645157\n",
            "Step 12964, Epoch 5/5, Loss: 0.32065102458000183\n",
            "Step 12968, Epoch 5/5, Loss: 0.34148242324590683\n",
            "Step 12972, Epoch 5/5, Loss: 0.27876052260398865\n",
            "Step 12976, Epoch 5/5, Loss: 0.37385714799165726\n",
            "Step 12980, Epoch 5/5, Loss: 0.32616277784109116\n",
            "Step 12984, Epoch 5/5, Loss: 0.2833249792456627\n",
            "Step 12988, Epoch 5/5, Loss: 0.3344900906085968\n",
            "Step 12992, Epoch 5/5, Loss: 0.33891943097114563\n",
            "Step 12996, Epoch 5/5, Loss: 0.3000781051814556\n",
            "Step 13000, Epoch 5/5, Loss: 0.3246310316026211\n",
            "Step 13004, Epoch 5/5, Loss: 0.37236152589321136\n",
            "Step 13008, Epoch 5/5, Loss: 0.34084952622652054\n",
            "Step 13012, Epoch 5/5, Loss: 0.42477625608444214\n",
            "Step 13016, Epoch 5/5, Loss: 0.31968415528535843\n",
            "Step 13020, Epoch 5/5, Loss: 0.30812081322073936\n",
            "Step 13024, Epoch 5/5, Loss: 0.34103524684906006\n",
            "Step 13028, Epoch 5/5, Loss: 0.25894850119948387\n",
            "Step 13032, Epoch 5/5, Loss: 0.2535438686609268\n",
            "Step 13036, Epoch 5/5, Loss: 0.2754860147833824\n",
            "Step 13040, Epoch 5/5, Loss: 0.3248169869184494\n",
            "Step 13044, Epoch 5/5, Loss: 0.3665044829249382\n",
            "Step 13048, Epoch 5/5, Loss: 0.31726692616939545\n",
            "Step 13052, Epoch 5/5, Loss: 0.35086777061223984\n",
            "Step 13056, Epoch 5/5, Loss: 0.38442350924015045\n",
            "Step 13060, Epoch 5/5, Loss: 0.34648747742176056\n",
            "Step 13064, Epoch 5/5, Loss: 0.29959220439195633\n",
            "Step 13068, Epoch 5/5, Loss: 0.33062998950481415\n",
            "Step 13072, Epoch 5/5, Loss: 0.347968190908432\n",
            "Step 13076, Epoch 5/5, Loss: 0.28600823134183884\n",
            "Step 13080, Epoch 5/5, Loss: 0.39436836540699005\n",
            "Step 13084, Epoch 5/5, Loss: 0.33311251178383827\n",
            "Step 13088, Epoch 5/5, Loss: 0.33024323731660843\n",
            "Step 13092, Epoch 5/5, Loss: 0.3317447081208229\n",
            "Step 13096, Epoch 5/5, Loss: 0.2720016911625862\n",
            "Step 13100, Epoch 5/5, Loss: 0.2804526202380657\n",
            "Step 13104, Epoch 5/5, Loss: 0.35109397023916245\n",
            "Step 13108, Epoch 5/5, Loss: 0.35300320759415627\n",
            "Step 13112, Epoch 5/5, Loss: 0.31843892484903336\n",
            "Step 13116, Epoch 5/5, Loss: 0.2361777015030384\n",
            "Step 13120, Epoch 5/5, Loss: 0.3193812817335129\n",
            "Step 13124, Epoch 5/5, Loss: 0.350755512714386\n",
            "Step 13128, Epoch 5/5, Loss: 0.369519654661417\n",
            "Step 13132, Epoch 5/5, Loss: 0.342039804905653\n",
            "Step 13136, Epoch 5/5, Loss: 0.25468606501817703\n",
            "Step 13140, Epoch 5/5, Loss: 0.31411781162023544\n",
            "Step 13144, Epoch 5/5, Loss: 0.3031304255127907\n",
            "Step 13148, Epoch 5/5, Loss: 0.31416383758187294\n",
            "Step 13152, Epoch 5/5, Loss: 0.31786366924643517\n",
            "Step 13156, Epoch 5/5, Loss: 0.2540882043540478\n",
            "Step 13160, Epoch 5/5, Loss: 0.295328501611948\n",
            "Step 13164, Epoch 5/5, Loss: 0.3501046672463417\n",
            "Step 13168, Epoch 5/5, Loss: 0.2920466475188732\n",
            "Step 13172, Epoch 5/5, Loss: 0.3350200802087784\n",
            "Step 13176, Epoch 5/5, Loss: 0.3500209040939808\n",
            "Step 13180, Epoch 5/5, Loss: 0.32695916295051575\n",
            "Step 13184, Epoch 5/5, Loss: 0.3568667620420456\n",
            "Step 13188, Epoch 5/5, Loss: 0.3508494719862938\n",
            "Step 13192, Epoch 5/5, Loss: 0.34160343185067177\n",
            "Step 13196, Epoch 5/5, Loss: 0.41992566734552383\n",
            "Step 13200, Epoch 5/5, Loss: 0.34093329310417175\n",
            "Step 13204, Epoch 5/5, Loss: 0.3336290456354618\n",
            "Step 13208, Epoch 5/5, Loss: 0.3128009960055351\n",
            "Step 13212, Epoch 5/5, Loss: 0.41372300684452057\n",
            "Step 13216, Epoch 5/5, Loss: 0.3150569200515747\n",
            "Step 13220, Epoch 5/5, Loss: 0.37392062693834305\n",
            "Step 13224, Epoch 5/5, Loss: 0.2919408790767193\n",
            "Step 13228, Epoch 5/5, Loss: 0.2765094116330147\n",
            "Step 13232, Epoch 5/5, Loss: 0.34081291407346725\n",
            "Step 13236, Epoch 5/5, Loss: 0.30810172110795975\n",
            "Step 13240, Epoch 5/5, Loss: 0.337680384516716\n",
            "Step 13244, Epoch 5/5, Loss: 0.38898003101348877\n",
            "Step 13248, Epoch 5/5, Loss: 0.3476061336696148\n",
            "Step 13252, Epoch 5/5, Loss: 0.38734403997659683\n",
            "Step 13256, Epoch 5/5, Loss: 0.3278515934944153\n",
            "Step 13260, Epoch 5/5, Loss: 0.34524987637996674\n",
            "Step 13264, Epoch 5/5, Loss: 0.3357098922133446\n",
            "Step 13268, Epoch 5/5, Loss: 0.37008295953273773\n",
            "Step 13272, Epoch 5/5, Loss: 0.30818306654691696\n",
            "Step 13276, Epoch 5/5, Loss: 0.26622458919882774\n",
            "Step 13280, Epoch 5/5, Loss: 0.33425431698560715\n",
            "Step 13284, Epoch 5/5, Loss: 0.4051342085003853\n",
            "Step 13288, Epoch 5/5, Loss: 0.3094717785716057\n",
            "Step 13292, Epoch 5/5, Loss: 0.34464044123888016\n",
            "Step 13296, Epoch 5/5, Loss: 0.2985614612698555\n",
            "Step 13300, Epoch 5/5, Loss: 0.4035787731409073\n",
            "Step 13304, Epoch 5/5, Loss: 0.2544405274093151\n",
            "Step 13308, Epoch 5/5, Loss: 0.35577016323804855\n",
            "Step 13312, Epoch 5/5, Loss: 0.28880010545253754\n",
            "Step 13316, Epoch 5/5, Loss: 0.34272249788045883\n",
            "Step 13320, Epoch 5/5, Loss: 0.30187593400478363\n",
            "Step 13324, Epoch 5/5, Loss: 0.40150730311870575\n",
            "Step 13328, Epoch 5/5, Loss: 0.35394544154405594\n",
            "Step 13332, Epoch 5/5, Loss: 0.31675417721271515\n",
            "Step 13336, Epoch 5/5, Loss: 0.31671592593193054\n",
            "Step 13340, Epoch 5/5, Loss: 0.31577276438474655\n",
            "Step 13344, Epoch 5/5, Loss: 0.33407025039196014\n",
            "Step 13348, Epoch 5/5, Loss: 0.3563282638788223\n",
            "Step 13352, Epoch 5/5, Loss: 0.35880402475595474\n",
            "Step 13356, Epoch 5/5, Loss: 0.27891600131988525\n",
            "Step 13360, Epoch 5/5, Loss: 0.2843434810638428\n",
            "Step 13364, Epoch 5/5, Loss: 0.33869150653481483\n",
            "Step 13368, Epoch 5/5, Loss: 0.34417369961738586\n",
            "Step 13372, Epoch 5/5, Loss: 0.3477693870663643\n",
            "Step 13376, Epoch 5/5, Loss: 0.3255026340484619\n",
            "Step 13380, Epoch 5/5, Loss: 0.32121049985289574\n",
            "Step 13384, Epoch 5/5, Loss: 0.297295443713665\n",
            "Step 13388, Epoch 5/5, Loss: 0.31449492275714874\n",
            "Step 13392, Epoch 5/5, Loss: 0.3507367670536041\n",
            "Step 13396, Epoch 5/5, Loss: 0.36568452417850494\n",
            "Step 13400, Epoch 5/5, Loss: 0.3482107073068619\n",
            "Step 13404, Epoch 5/5, Loss: 0.37871264666318893\n",
            "Step 13408, Epoch 5/5, Loss: 0.3113933466374874\n",
            "Step 13412, Epoch 5/5, Loss: 0.29198019579052925\n",
            "Step 13416, Epoch 5/5, Loss: 0.3951425179839134\n",
            "Step 13420, Epoch 5/5, Loss: 0.30127064138650894\n",
            "Step 13424, Epoch 5/5, Loss: 0.28895271196961403\n",
            "Step 13428, Epoch 5/5, Loss: 0.36894558370113373\n",
            "Step 13432, Epoch 5/5, Loss: 0.3401874490082264\n",
            "Step 13436, Epoch 5/5, Loss: 0.3443698063492775\n",
            "Step 13440, Epoch 5/5, Loss: 0.2619197592139244\n",
            "Step 13444, Epoch 5/5, Loss: 0.3159228079020977\n",
            "Step 13448, Epoch 5/5, Loss: 0.3399406895041466\n",
            "Step 13452, Epoch 5/5, Loss: 0.32169442623853683\n",
            "Step 13456, Epoch 5/5, Loss: 0.284862894564867\n",
            "Step 13460, Epoch 5/5, Loss: 0.2954295538365841\n",
            "Step 13464, Epoch 5/5, Loss: 0.33732593804597855\n",
            "Step 13468, Epoch 5/5, Loss: 0.28327932208776474\n",
            "Step 13472, Epoch 5/5, Loss: 0.2879970036447048\n",
            "Step 13476, Epoch 5/5, Loss: 0.3320336788892746\n",
            "Step 13480, Epoch 5/5, Loss: 0.3434092700481415\n",
            "Step 13484, Epoch 5/5, Loss: 0.26554248481988907\n",
            "Step 13488, Epoch 5/5, Loss: 0.3366618975996971\n",
            "Step 13492, Epoch 5/5, Loss: 0.4077612832188606\n",
            "Step 13496, Epoch 5/5, Loss: 0.3853646069765091\n",
            "Step 13500, Epoch 5/5, Loss: 0.3191561959683895\n",
            "Step 13504, Epoch 5/5, Loss: 0.3477202132344246\n",
            "Step 13508, Epoch 5/5, Loss: 0.29817982763051987\n",
            "Step 13512, Epoch 5/5, Loss: 0.38227181136608124\n",
            "Step 13516, Epoch 5/5, Loss: 0.2969561070203781\n",
            "Step 13520, Epoch 5/5, Loss: 0.31347066909074783\n",
            "Step 13524, Epoch 5/5, Loss: 0.3235292583703995\n",
            "Step 13528, Epoch 5/5, Loss: 0.28396155685186386\n",
            "Step 13532, Epoch 5/5, Loss: 0.32361678034067154\n",
            "Step 13536, Epoch 5/5, Loss: 0.2842302545905113\n",
            "Step 13540, Epoch 5/5, Loss: 0.3547241538763046\n",
            "Step 13544, Epoch 5/5, Loss: 0.3344205692410469\n",
            "Step 13548, Epoch 5/5, Loss: 0.3151639550924301\n",
            "Step 13552, Epoch 5/5, Loss: 0.29385098814964294\n",
            "Step 13556, Epoch 5/5, Loss: 0.3323059380054474\n",
            "Step 13560, Epoch 5/5, Loss: 0.33392953872680664\n",
            "Step 13564, Epoch 5/5, Loss: 0.25539497286081314\n",
            "Step 13568, Epoch 5/5, Loss: 0.2814583331346512\n",
            "Step 13572, Epoch 5/5, Loss: 0.2889786511659622\n",
            "Step 13576, Epoch 5/5, Loss: 0.284820020198822\n",
            "Step 13580, Epoch 5/5, Loss: 0.40158381313085556\n",
            "Step 13584, Epoch 5/5, Loss: 0.2731088399887085\n",
            "Step 13588, Epoch 5/5, Loss: 0.299049012362957\n",
            "Step 13592, Epoch 5/5, Loss: 0.3085048794746399\n",
            "Step 13596, Epoch 5/5, Loss: 0.2621939890086651\n",
            "Step 13600, Epoch 5/5, Loss: 0.30608879774808884\n",
            "Step 13604, Epoch 5/5, Loss: 0.32591086626052856\n",
            "Step 13608, Epoch 5/5, Loss: 0.31750407069921494\n",
            "Step 13612, Epoch 5/5, Loss: 0.3731403015553951\n",
            "Step 13616, Epoch 5/5, Loss: 0.2531742863357067\n",
            "Step 13620, Epoch 5/5, Loss: 0.3309028148651123\n",
            "Step 13624, Epoch 5/5, Loss: 0.343864843249321\n",
            "Step 13628, Epoch 5/5, Loss: 0.34242797270417213\n",
            "Step 13632, Epoch 5/5, Loss: 0.30890922620892525\n",
            "Step 13636, Epoch 5/5, Loss: 0.26520850136876106\n",
            "Step 13640, Epoch 5/5, Loss: 0.3715532124042511\n",
            "Step 13644, Epoch 5/5, Loss: 0.258453905582428\n",
            "Step 13648, Epoch 5/5, Loss: 0.251837819814682\n",
            "Step 13652, Epoch 5/5, Loss: 0.351197712123394\n",
            "Step 13656, Epoch 5/5, Loss: 0.2801431193947792\n",
            "Step 13660, Epoch 5/5, Loss: 0.29476765915751457\n",
            "Step 13664, Epoch 5/5, Loss: 0.34496886283159256\n",
            "Step 13668, Epoch 5/5, Loss: 0.2935728207230568\n",
            "Step 13672, Epoch 5/5, Loss: 0.31931857019662857\n",
            "Step 13676, Epoch 5/5, Loss: 0.3262042924761772\n",
            "Step 13680, Epoch 5/5, Loss: 0.3051634207367897\n",
            "Step 13684, Epoch 5/5, Loss: 0.3631288856267929\n",
            "Step 13688, Epoch 5/5, Loss: 0.34476202726364136\n",
            "Step 13692, Epoch 5/5, Loss: 0.2999427951872349\n",
            "Step 13696, Epoch 5/5, Loss: 0.3284839875996113\n",
            "Step 13700, Epoch 5/5, Loss: 0.33705178648233414\n",
            "Step 13704, Epoch 5/5, Loss: 0.3387172818183899\n",
            "Step 13708, Epoch 5/5, Loss: 0.33990422636270523\n",
            "Step 13712, Epoch 5/5, Loss: 0.35475052148103714\n",
            "Step 13716, Epoch 5/5, Loss: 0.2933220900595188\n",
            "Step 13720, Epoch 5/5, Loss: 0.31610672920942307\n",
            "Step 13724, Epoch 5/5, Loss: 0.25713803246617317\n",
            "Step 13728, Epoch 5/5, Loss: 0.38746847212314606\n",
            "Step 13732, Epoch 5/5, Loss: 0.29121724888682365\n",
            "Step 13736, Epoch 5/5, Loss: 0.31518667563796043\n",
            "Step 13740, Epoch 5/5, Loss: 0.34219618886709213\n",
            "Step 13744, Epoch 5/5, Loss: 0.29556407779455185\n",
            "Step 13748, Epoch 5/5, Loss: 0.35997530817985535\n",
            "Step 13752, Epoch 5/5, Loss: 0.3058158978819847\n",
            "Step 13756, Epoch 5/5, Loss: 0.37142255529761314\n",
            "Step 13760, Epoch 5/5, Loss: 0.40957026928663254\n",
            "Step 13764, Epoch 5/5, Loss: 0.3386579006910324\n",
            "Step 13768, Epoch 5/5, Loss: 0.3558430001139641\n",
            "Step 13772, Epoch 5/5, Loss: 0.3802649676799774\n",
            "Step 13776, Epoch 5/5, Loss: 0.3126094527542591\n",
            "Step 13780, Epoch 5/5, Loss: 0.361033596098423\n",
            "Step 13784, Epoch 5/5, Loss: 0.3017817884683609\n",
            "Step 13788, Epoch 5/5, Loss: 0.366353839635849\n",
            "Step 13792, Epoch 5/5, Loss: 0.3039219342172146\n",
            "Step 13796, Epoch 5/5, Loss: 0.30447686463594437\n",
            "Step 13800, Epoch 5/5, Loss: 0.3938155472278595\n",
            "Step 13804, Epoch 5/5, Loss: 0.29294027388095856\n",
            "Step 13808, Epoch 5/5, Loss: 0.3630567267537117\n",
            "Step 13812, Epoch 5/5, Loss: 0.30968527495861053\n",
            "Step 13816, Epoch 5/5, Loss: 0.22329482436180115\n",
            "Step 13820, Epoch 5/5, Loss: 0.2446543574333191\n",
            "Step 13824, Epoch 5/5, Loss: 0.3586520478129387\n",
            "Step 13828, Epoch 5/5, Loss: 0.40052714198827744\n",
            "Step 13832, Epoch 5/5, Loss: 0.3089475966989994\n",
            "Step 13836, Epoch 5/5, Loss: 0.3501761928200722\n",
            "Step 13840, Epoch 5/5, Loss: 0.27593255043029785\n",
            "Step 13844, Epoch 5/5, Loss: 0.2955629788339138\n",
            "Step 13848, Epoch 5/5, Loss: 0.2871449328958988\n",
            "Step 13852, Epoch 5/5, Loss: 0.33424516022205353\n",
            "Step 13856, Epoch 5/5, Loss: 0.3141380175948143\n",
            "Step 13860, Epoch 5/5, Loss: 0.2987280748784542\n",
            "Step 13864, Epoch 5/5, Loss: 0.37486349791288376\n",
            "Step 13868, Epoch 5/5, Loss: 0.2673941068351269\n",
            "Step 13872, Epoch 5/5, Loss: 0.3507043644785881\n",
            "Step 13876, Epoch 5/5, Loss: 0.30734844133257866\n",
            "Step 13880, Epoch 5/5, Loss: 0.2802582196891308\n",
            "Step 13884, Epoch 5/5, Loss: 0.28951185941696167\n",
            "Step 13888, Epoch 5/5, Loss: 0.3092161938548088\n",
            "Step 13892, Epoch 5/5, Loss: 0.3258039429783821\n",
            "Step 13896, Epoch 5/5, Loss: 0.2692720554769039\n",
            "Step 13900, Epoch 5/5, Loss: 0.2999950014054775\n",
            "Step 13904, Epoch 5/5, Loss: 0.25337478145956993\n",
            "Step 13908, Epoch 5/5, Loss: 0.24378741905093193\n",
            "Step 13912, Epoch 5/5, Loss: 0.3354720324277878\n",
            "Step 13916, Epoch 5/5, Loss: 0.3107679560780525\n",
            "Step 13920, Epoch 5/5, Loss: 0.34865453466773033\n",
            "Step 13924, Epoch 5/5, Loss: 0.3562606945633888\n",
            "Step 13928, Epoch 5/5, Loss: 0.266925685107708\n",
            "Step 13932, Epoch 5/5, Loss: 0.3316168710589409\n",
            "Step 13936, Epoch 5/5, Loss: 0.3251231722533703\n",
            "Step 13940, Epoch 5/5, Loss: 0.3761146254837513\n",
            "Step 13944, Epoch 5/5, Loss: 0.33489249646663666\n",
            "Step 13948, Epoch 5/5, Loss: 0.2881905324757099\n",
            "Step 13952, Epoch 5/5, Loss: 0.26703694835305214\n",
            "Step 13956, Epoch 5/5, Loss: 0.3381373733282089\n",
            "Step 13960, Epoch 5/5, Loss: 0.3357911817729473\n",
            "Step 13964, Epoch 5/5, Loss: 0.3515855148434639\n",
            "Step 13968, Epoch 5/5, Loss: 0.2763481177389622\n",
            "Step 13972, Epoch 5/5, Loss: 0.31427034363150597\n",
            "Step 13976, Epoch 5/5, Loss: 0.27799638733267784\n",
            "Step 13980, Epoch 5/5, Loss: 0.345668189227581\n",
            "Step 13984, Epoch 5/5, Loss: 0.29398638755083084\n",
            "Step 13988, Epoch 5/5, Loss: 0.35312458500266075\n",
            "Step 13992, Epoch 5/5, Loss: 0.31705233454704285\n",
            "Step 13996, Epoch 5/5, Loss: 0.30818265303969383\n",
            "Step 14000, Epoch 5/5, Loss: 0.2547127604484558\n",
            "Step 14004, Epoch 5/5, Loss: 0.30572575330734253\n",
            "Step 14008, Epoch 5/5, Loss: 0.36286965012550354\n",
            "Step 14012, Epoch 5/5, Loss: 0.31445615738630295\n",
            "Step 14016, Epoch 5/5, Loss: 0.3939650133252144\n",
            "Step 14020, Epoch 5/5, Loss: 0.39688025414943695\n",
            "Step 14024, Epoch 5/5, Loss: 0.3495120219886303\n",
            "Step 14028, Epoch 5/5, Loss: 0.28146566823124886\n",
            "Step 14032, Epoch 5/5, Loss: 0.3655958026647568\n",
            "Step 14036, Epoch 5/5, Loss: 0.3741604685783386\n",
            "Step 14040, Epoch 5/5, Loss: 0.29679282009601593\n",
            "Step 14044, Epoch 5/5, Loss: 0.3082251027226448\n",
            "Step 14048, Epoch 5/5, Loss: 0.34988638013601303\n",
            "Step 14052, Epoch 5/5, Loss: 0.26663023233413696\n",
            "Step 14056, Epoch 5/5, Loss: 0.3352595455944538\n",
            "Step 14060, Epoch 5/5, Loss: 0.335477065294981\n",
            "Step 14064, Epoch 5/5, Loss: 0.29077933728694916\n",
            "Step 14068, Epoch 5/5, Loss: 0.33040057867765427\n",
            "Step 14072, Epoch 5/5, Loss: 0.3349495902657509\n",
            "Step 14076, Epoch 5/5, Loss: 0.374329037964344\n",
            "Step 14080, Epoch 5/5, Loss: 0.3675960898399353\n",
            "Step 14084, Epoch 5/5, Loss: 0.27957428991794586\n",
            "Step 14088, Epoch 5/5, Loss: 0.27028366550803185\n",
            "Step 14092, Epoch 5/5, Loss: 0.3644455708563328\n",
            "Step 14096, Epoch 5/5, Loss: 0.25313232839107513\n",
            "Step 14100, Epoch 5/5, Loss: 0.3610076382756233\n",
            "Step 14104, Epoch 5/5, Loss: 0.3281223326921463\n",
            "Step 14108, Epoch 5/5, Loss: 0.30706827715039253\n",
            "Step 14112, Epoch 5/5, Loss: 0.3236991986632347\n",
            "Step 14116, Epoch 5/5, Loss: 0.302290715277195\n",
            "Step 14120, Epoch 5/5, Loss: 0.38729970157146454\n",
            "Step 14124, Epoch 5/5, Loss: 0.3439032509922981\n",
            "Step 14128, Epoch 5/5, Loss: 0.31914281845092773\n",
            "Step 14132, Epoch 5/5, Loss: 0.32262588292360306\n",
            "Step 14136, Epoch 5/5, Loss: 0.33320649713277817\n",
            "Step 14140, Epoch 5/5, Loss: 0.36812907457351685\n",
            "Step 14144, Epoch 5/5, Loss: 0.3698023781180382\n",
            "Step 14148, Epoch 5/5, Loss: 0.32636086642742157\n",
            "Step 14152, Epoch 5/5, Loss: 0.30209875479340553\n",
            "Step 14156, Epoch 5/5, Loss: 0.37081605941057205\n",
            "Step 14160, Epoch 5/5, Loss: 0.299167413264513\n",
            "Step 14164, Epoch 5/5, Loss: 0.27476273477077484\n",
            "Step 14168, Epoch 5/5, Loss: 0.37074367702007294\n",
            "Step 14172, Epoch 5/5, Loss: 0.24161050468683243\n",
            "Step 14176, Epoch 5/5, Loss: 0.3155040815472603\n",
            "Step 14180, Epoch 5/5, Loss: 0.3384229801595211\n",
            "Step 14184, Epoch 5/5, Loss: 0.3566821366548538\n",
            "Step 14188, Epoch 5/5, Loss: 0.31257933378219604\n",
            "Step 14192, Epoch 5/5, Loss: 0.3622559681534767\n",
            "Step 14196, Epoch 5/5, Loss: 0.3099280260503292\n",
            "Step 14200, Epoch 5/5, Loss: 0.3509804606437683\n",
            "Step 14204, Epoch 5/5, Loss: 0.3603876158595085\n",
            "Step 14208, Epoch 5/5, Loss: 0.3282295987010002\n",
            "Step 14212, Epoch 5/5, Loss: 0.3959643319249153\n",
            "Step 14216, Epoch 5/5, Loss: 0.295973040163517\n",
            "Step 14220, Epoch 5/5, Loss: 0.2614414356648922\n",
            "Step 14224, Epoch 5/5, Loss: 0.2708032727241516\n",
            "Step 14228, Epoch 5/5, Loss: 0.3277209401130676\n",
            "Step 14232, Epoch 5/5, Loss: 0.301791250705719\n",
            "Step 14236, Epoch 5/5, Loss: 0.3038834109902382\n",
            "Step 14240, Epoch 5/5, Loss: 0.2913413867354393\n",
            "Step 14244, Epoch 5/5, Loss: 0.3289754316210747\n",
            "Step 14248, Epoch 5/5, Loss: 0.2499171979725361\n",
            "Step 14252, Epoch 5/5, Loss: 0.3830297961831093\n",
            "Step 14256, Epoch 5/5, Loss: 0.28801263496279716\n",
            "Step 14260, Epoch 5/5, Loss: 0.37539634481072426\n",
            "Step 14264, Epoch 5/5, Loss: 0.3456602729856968\n",
            "Step 14268, Epoch 5/5, Loss: 0.3062879294157028\n",
            "Step 14272, Epoch 5/5, Loss: 0.36825786530971527\n",
            "Step 14276, Epoch 5/5, Loss: 0.30205411091446877\n",
            "Step 14280, Epoch 5/5, Loss: 0.373409416526556\n",
            "Step 14284, Epoch 5/5, Loss: 0.2781701013445854\n",
            "Step 14288, Epoch 5/5, Loss: 0.29093892872333527\n",
            "Step 14292, Epoch 5/5, Loss: 0.2688811235129833\n",
            "Step 14296, Epoch 5/5, Loss: 0.28888433426618576\n",
            "Step 14300, Epoch 5/5, Loss: 0.37294797599315643\n",
            "Step 14304, Epoch 5/5, Loss: 0.2184501327574253\n",
            "Step 14308, Epoch 5/5, Loss: 0.3032609112560749\n",
            "Step 14312, Epoch 5/5, Loss: 0.3238278478384018\n",
            "Step 14316, Epoch 5/5, Loss: 0.3527364730834961\n",
            "Step 14320, Epoch 5/5, Loss: 0.29852912575006485\n",
            "Step 14324, Epoch 5/5, Loss: 0.28578314557671547\n",
            "Step 14328, Epoch 5/5, Loss: 0.2807187996804714\n",
            "Step 14332, Epoch 5/5, Loss: 0.3310932517051697\n",
            "Step 14336, Epoch 5/5, Loss: 0.3321759030222893\n",
            "Step 14340, Epoch 5/5, Loss: 0.3321887217462063\n",
            "Step 14344, Epoch 5/5, Loss: 0.3219420164823532\n",
            "Step 14348, Epoch 5/5, Loss: 0.3067084886133671\n",
            "Step 14352, Epoch 5/5, Loss: 0.2896595597267151\n",
            "Step 14356, Epoch 5/5, Loss: 0.3289821855723858\n",
            "Step 14360, Epoch 5/5, Loss: 0.3577641099691391\n",
            "Step 14364, Epoch 5/5, Loss: 0.31457508355379105\n",
            "Step 14368, Epoch 5/5, Loss: 0.3896947205066681\n",
            "Step 14372, Epoch 5/5, Loss: 0.3495441675186157\n",
            "Step 14376, Epoch 5/5, Loss: 0.3038240261375904\n",
            "Step 14380, Epoch 5/5, Loss: 0.2586243189871311\n",
            "Step 14384, Epoch 5/5, Loss: 0.38915058225393295\n",
            "Step 14388, Epoch 5/5, Loss: 0.32521289587020874\n",
            "Step 14392, Epoch 5/5, Loss: 0.3678232282400131\n",
            "Step 14396, Epoch 5/5, Loss: 0.3378012925386429\n",
            "Step 14400, Epoch 5/5, Loss: 0.3150390163064003\n",
            "Step 14404, Epoch 5/5, Loss: 0.3748054653406143\n",
            "Step 14408, Epoch 5/5, Loss: 0.2850305661559105\n",
            "Step 14412, Epoch 5/5, Loss: 0.3438671603798866\n",
            "Step 14416, Epoch 5/5, Loss: 0.3396889567375183\n",
            "Step 14420, Epoch 5/5, Loss: 0.2915958911180496\n",
            "Step 14424, Epoch 5/5, Loss: 0.33802739530801773\n",
            "Step 14428, Epoch 5/5, Loss: 0.3145940750837326\n",
            "Step 14432, Epoch 5/5, Loss: 0.31630026549100876\n",
            "Step 14436, Epoch 5/5, Loss: 0.2912793941795826\n",
            "Step 14440, Epoch 5/5, Loss: 0.33352523297071457\n",
            "Step 14444, Epoch 5/5, Loss: 0.31068120896816254\n",
            "Step 14448, Epoch 5/5, Loss: 0.2858099788427353\n",
            "Step 14452, Epoch 5/5, Loss: 0.35205140709877014\n",
            "Step 14456, Epoch 5/5, Loss: 0.36700401455163956\n",
            "Step 14460, Epoch 5/5, Loss: 0.2892274297773838\n",
            "Step 14464, Epoch 5/5, Loss: 0.30634599924087524\n",
            "Step 14468, Epoch 5/5, Loss: 0.3626694157719612\n",
            "Step 14472, Epoch 5/5, Loss: 0.3133943974971771\n",
            "Step 14476, Epoch 5/5, Loss: 0.363255575299263\n",
            "Step 14480, Epoch 5/5, Loss: 0.2797364257276058\n",
            "Step 14484, Epoch 5/5, Loss: 0.35908573865890503\n",
            "Step 14488, Epoch 5/5, Loss: 0.26302701607346535\n",
            "Step 14492, Epoch 5/5, Loss: 0.2561023645102978\n",
            "Step 14496, Epoch 5/5, Loss: 0.3579779639840126\n",
            "Step 14500, Epoch 5/5, Loss: 0.3491223305463791\n",
            "Step 14504, Epoch 5/5, Loss: 0.33230527490377426\n",
            "Step 14508, Epoch 5/5, Loss: 0.3851875811815262\n",
            "Step 14512, Epoch 5/5, Loss: 0.37641366571187973\n",
            "Step 14516, Epoch 5/5, Loss: 0.2428138218820095\n",
            "Step 14520, Epoch 5/5, Loss: 0.3459511175751686\n",
            "Step 14524, Epoch 5/5, Loss: 0.35317809879779816\n",
            "Step 14528, Epoch 5/5, Loss: 0.2857929430902004\n",
            "Step 14532, Epoch 5/5, Loss: 0.3174491599202156\n",
            "Step 14536, Epoch 5/5, Loss: 0.2675749957561493\n",
            "Step 14540, Epoch 5/5, Loss: 0.25736650079488754\n",
            "Step 14544, Epoch 5/5, Loss: 0.35247956961393356\n",
            "Step 14548, Epoch 5/5, Loss: 0.2756294161081314\n",
            "Step 14552, Epoch 5/5, Loss: 0.2620520517230034\n",
            "Step 14556, Epoch 5/5, Loss: 0.2922278866171837\n",
            "Step 14560, Epoch 5/5, Loss: 0.310632660984993\n",
            "Step 14564, Epoch 5/5, Loss: 0.3783749230206013\n",
            "Step 14568, Epoch 5/5, Loss: 0.3016895726323128\n",
            "Step 14572, Epoch 5/5, Loss: 0.29510490968823433\n",
            "Step 14576, Epoch 5/5, Loss: 0.27442578971385956\n",
            "Step 14580, Epoch 5/5, Loss: 0.32607395201921463\n",
            "Step 14584, Epoch 5/5, Loss: 0.2965712249279022\n",
            "Step 14588, Epoch 5/5, Loss: 0.3782120943069458\n",
            "Step 14592, Epoch 5/5, Loss: 0.25784827023744583\n",
            "Step 14596, Epoch 5/5, Loss: 0.345513753592968\n",
            "Step 14600, Epoch 5/5, Loss: 0.29722460731863976\n",
            "Step 14604, Epoch 5/5, Loss: 0.3089633285999298\n",
            "Step 14608, Epoch 5/5, Loss: 0.2544328272342682\n",
            "Step 14612, Epoch 5/5, Loss: 0.25353752449154854\n",
            "Step 14616, Epoch 5/5, Loss: 0.37621545046567917\n",
            "Step 14620, Epoch 5/5, Loss: 0.39884717762470245\n",
            "Step 14624, Epoch 5/5, Loss: 0.3127206116914749\n",
            "Step 14628, Epoch 5/5, Loss: 0.34708741679787636\n",
            "Step 14632, Epoch 5/5, Loss: 0.3746332675218582\n",
            "Step 14636, Epoch 5/5, Loss: 0.3054628297686577\n",
            "Step 14640, Epoch 5/5, Loss: 0.29093582928180695\n",
            "Step 14644, Epoch 5/5, Loss: 0.30246496945619583\n",
            "Step 14648, Epoch 5/5, Loss: 0.3042769469320774\n",
            "Step 14652, Epoch 5/5, Loss: 0.2640729621052742\n",
            "Step 14656, Epoch 5/5, Loss: 0.2908002696931362\n",
            "Step 14660, Epoch 5/5, Loss: 0.37483979761600494\n",
            "Step 14664, Epoch 5/5, Loss: 0.24028874188661575\n",
            "Step 14668, Epoch 5/5, Loss: 0.30255813524127007\n",
            "Step 14672, Epoch 5/5, Loss: 0.3772505298256874\n",
            "Step 14676, Epoch 5/5, Loss: 0.3505144938826561\n",
            "Step 14680, Epoch 5/5, Loss: 0.32355114817619324\n",
            "Step 14684, Epoch 5/5, Loss: 0.38228996098041534\n",
            "Step 14688, Epoch 5/5, Loss: 0.29260531440377235\n",
            "Step 14692, Epoch 5/5, Loss: 0.23851408809423447\n",
            "Step 14696, Epoch 5/5, Loss: 0.3359173759818077\n",
            "Step 14700, Epoch 5/5, Loss: 0.29881373420357704\n",
            "Step 14704, Epoch 5/5, Loss: 0.35297519713640213\n",
            "Step 14708, Epoch 5/5, Loss: 0.35054681822657585\n",
            "Step 14712, Epoch 5/5, Loss: 0.27714427933096886\n",
            "Step 14716, Epoch 5/5, Loss: 0.32243701815605164\n",
            "Step 14720, Epoch 5/5, Loss: 0.2421589493751526\n",
            "Step 14724, Epoch 5/5, Loss: 0.4183240383863449\n",
            "Step 14728, Epoch 5/5, Loss: 0.3088451474905014\n",
            "Step 14732, Epoch 5/5, Loss: 0.33900831267237663\n",
            "Step 14736, Epoch 5/5, Loss: 0.32762161642313004\n",
            "Step 14740, Epoch 5/5, Loss: 0.3158683814108372\n",
            "Step 14744, Epoch 5/5, Loss: 0.34376928955316544\n",
            "Step 14748, Epoch 5/5, Loss: 0.3469271659851074\n",
            "Step 14752, Epoch 5/5, Loss: 0.34341632574796677\n",
            "Step 14756, Epoch 5/5, Loss: 0.30333539843559265\n",
            "Step 14760, Epoch 5/5, Loss: 0.3961675316095352\n",
            "Step 14764, Epoch 5/5, Loss: 0.2590547278523445\n",
            "Step 14768, Epoch 5/5, Loss: 0.32997894287109375\n",
            "Step 14772, Epoch 5/5, Loss: 0.32039774954319\n",
            "Step 14776, Epoch 5/5, Loss: 0.25958992540836334\n",
            "Step 14780, Epoch 5/5, Loss: 0.3178587630391121\n",
            "Step 14784, Epoch 5/5, Loss: 0.3472617268562317\n",
            "Step 14788, Epoch 5/5, Loss: 0.3016776442527771\n",
            "Step 14792, Epoch 5/5, Loss: 0.29449690133333206\n",
            "Step 14796, Epoch 5/5, Loss: 0.3645011931657791\n",
            "Step 14800, Epoch 5/5, Loss: 0.31896642595529556\n",
            "Step 14804, Epoch 5/5, Loss: 0.35145943611860275\n",
            "Step 14808, Epoch 5/5, Loss: 0.33997301012277603\n",
            "Step 14812, Epoch 5/5, Loss: 0.37036726623773575\n",
            "Step 14816, Epoch 5/5, Loss: 0.3092600405216217\n",
            "Step 14820, Epoch 5/5, Loss: 0.352911364287138\n",
            "Step 14824, Epoch 5/5, Loss: 0.303261861205101\n",
            "Step 14828, Epoch 5/5, Loss: 0.38870617747306824\n",
            "Step 14832, Epoch 5/5, Loss: 0.31284254789352417\n",
            "Step 14836, Epoch 5/5, Loss: 0.37137020379304886\n",
            "Step 14840, Epoch 5/5, Loss: 0.31207912787795067\n",
            "Step 14844, Epoch 5/5, Loss: 0.3249570466578007\n",
            "Step 14848, Epoch 5/5, Loss: 0.22642970457673073\n",
            "Step 14852, Epoch 5/5, Loss: 0.3930545523762703\n",
            "Step 14856, Epoch 5/5, Loss: 0.32348809391260147\n",
            "Step 14860, Epoch 5/5, Loss: 0.38352859765291214\n",
            "Step 14864, Epoch 5/5, Loss: 0.30237092077732086\n",
            "Step 14868, Epoch 5/5, Loss: 0.2800549566745758\n",
            "Step 14872, Epoch 5/5, Loss: 0.352000929415226\n",
            "Step 14876, Epoch 5/5, Loss: 0.42129871249198914\n",
            "Step 14880, Epoch 5/5, Loss: 0.3821592628955841\n",
            "Step 14884, Epoch 5/5, Loss: 0.35628068447113037\n",
            "Step 14888, Epoch 5/5, Loss: 0.3232278600335121\n",
            "Step 14892, Epoch 5/5, Loss: 0.3116803392767906\n",
            "Step 14896, Epoch 5/5, Loss: 0.35110902041196823\n",
            "Step 14900, Epoch 5/5, Loss: 0.35814063996076584\n",
            "Step 14904, Epoch 5/5, Loss: 0.36207328736782074\n",
            "Step 14908, Epoch 5/5, Loss: 0.2801598906517029\n",
            "Step 14912, Epoch 5/5, Loss: 0.30402712151408195\n",
            "Step 14916, Epoch 5/5, Loss: 0.335563026368618\n",
            "Step 14920, Epoch 5/5, Loss: 0.2981176786124706\n",
            "Step 14924, Epoch 5/5, Loss: 0.27696726843714714\n",
            "Step 14928, Epoch 5/5, Loss: 0.2865029312670231\n",
            "Step 14932, Epoch 5/5, Loss: 0.25709930807352066\n",
            "Step 14936, Epoch 5/5, Loss: 0.2518022246658802\n",
            "Step 14940, Epoch 5/5, Loss: 0.2531939148902893\n",
            "Step 14944, Epoch 5/5, Loss: 0.2942802608013153\n",
            "Step 14948, Epoch 5/5, Loss: 0.37358295172452927\n",
            "Step 14952, Epoch 5/5, Loss: 0.33613845705986023\n",
            "Step 14956, Epoch 5/5, Loss: 0.28747017681598663\n",
            "Step 14960, Epoch 5/5, Loss: 0.3704284578561783\n",
            "Step 14964, Epoch 5/5, Loss: 0.29039110988378525\n",
            "Step 14968, Epoch 5/5, Loss: 0.3759932965040207\n",
            "Step 14972, Epoch 5/5, Loss: 0.32773107290267944\n",
            "Step 14976, Epoch 5/5, Loss: 0.33902398496866226\n",
            "Step 14980, Epoch 5/5, Loss: 0.3049033656716347\n",
            "Step 14984, Epoch 5/5, Loss: 0.32884277403354645\n",
            "Step 14988, Epoch 5/5, Loss: 0.3145032376050949\n",
            "Step 14992, Epoch 5/5, Loss: 0.3291392885148525\n",
            "Step 14996, Epoch 5/5, Loss: 0.25370699912309647\n",
            "Step 15000, Epoch 5/5, Loss: 0.3218612000346184\n",
            "Step 15004, Epoch 5/5, Loss: 0.3092494085431099\n",
            "Step 15008, Epoch 5/5, Loss: 0.31039029359817505\n",
            "Step 15012, Epoch 5/5, Loss: 0.3492586687207222\n",
            "Step 15016, Epoch 5/5, Loss: 0.31589964032173157\n",
            "Step 15020, Epoch 5/5, Loss: 0.3029951900243759\n",
            "Step 15024, Epoch 5/5, Loss: 0.29350367560982704\n",
            "Step 15028, Epoch 5/5, Loss: 0.3553095608949661\n",
            "Step 15032, Epoch 5/5, Loss: 0.3041532561182976\n",
            "Step 15036, Epoch 5/5, Loss: 0.36577291041612625\n",
            "Step 15040, Epoch 5/5, Loss: 0.2500218078494072\n",
            "Step 15044, Epoch 5/5, Loss: 0.29052167758345604\n",
            "Step 15048, Epoch 5/5, Loss: 0.33556506037712097\n",
            "Step 15052, Epoch 5/5, Loss: 0.3679468259215355\n",
            "Step 15056, Epoch 5/5, Loss: 0.3668895810842514\n",
            "Step 15060, Epoch 5/5, Loss: 0.3027058616280556\n",
            "Step 15064, Epoch 5/5, Loss: 0.34870056062936783\n",
            "Step 15068, Epoch 5/5, Loss: 0.33670514076948166\n",
            "Step 15072, Epoch 5/5, Loss: 0.344806432723999\n",
            "Step 15076, Epoch 5/5, Loss: 0.34576433151960373\n",
            "Step 15080, Epoch 5/5, Loss: 0.32093293592333794\n",
            "Step 15084, Epoch 5/5, Loss: 0.2455606423318386\n",
            "Step 15088, Epoch 5/5, Loss: 0.28642934188246727\n",
            "Step 15092, Epoch 5/5, Loss: 0.3608395531773567\n",
            "Step 15096, Epoch 5/5, Loss: 0.30649419873952866\n",
            "Step 15100, Epoch 5/5, Loss: 0.33615363389253616\n",
            "Step 15104, Epoch 5/5, Loss: 0.39698460325598717\n",
            "Step 15108, Epoch 5/5, Loss: 0.32693203538656235\n",
            "Step 15112, Epoch 5/5, Loss: 0.2962449640035629\n",
            "Step 15116, Epoch 5/5, Loss: 0.3011986054480076\n",
            "Step 15120, Epoch 5/5, Loss: 0.23345302417874336\n",
            "Step 15124, Epoch 5/5, Loss: 0.30483145639300346\n",
            "Step 15128, Epoch 5/5, Loss: 0.3101302795112133\n",
            "Step 15132, Epoch 5/5, Loss: 0.34197838604450226\n",
            "Step 15136, Epoch 5/5, Loss: 0.27935151010751724\n",
            "Step 15140, Epoch 5/5, Loss: 0.27642756700515747\n",
            "Step 15144, Epoch 5/5, Loss: 0.40418804436922073\n",
            "Step 15148, Epoch 5/5, Loss: 0.3285074532032013\n",
            "Step 15152, Epoch 5/5, Loss: 0.3169442303478718\n",
            "Step 15156, Epoch 5/5, Loss: 0.34766846150159836\n",
            "Step 15160, Epoch 5/5, Loss: 0.2575305998325348\n",
            "Step 15164, Epoch 5/5, Loss: 0.4228261038661003\n",
            "Step 15168, Epoch 5/5, Loss: 0.34388697519898415\n",
            "Step 15172, Epoch 5/5, Loss: 0.3725240156054497\n",
            "Step 15176, Epoch 5/5, Loss: 0.29647091403603554\n",
            "Step 15180, Epoch 5/5, Loss: 0.3677334152162075\n",
            "Step 15184, Epoch 5/5, Loss: 0.3799031041562557\n",
            "Step 15188, Epoch 5/5, Loss: 0.3267255127429962\n",
            "Step 15192, Epoch 5/5, Loss: 0.39189744740724564\n",
            "Step 15196, Epoch 5/5, Loss: 0.3420969620347023\n",
            "Step 15200, Epoch 5/5, Loss: 0.2979615665972233\n",
            "Step 15204, Epoch 5/5, Loss: 0.302155751734972\n",
            "Step 15208, Epoch 5/5, Loss: 0.31625212728977203\n",
            "Step 15212, Epoch 5/5, Loss: 0.36675766110420227\n",
            "Step 15216, Epoch 5/5, Loss: 0.31322476267814636\n",
            "Step 15220, Epoch 5/5, Loss: 0.36165159195661545\n",
            "Step 15224, Epoch 5/5, Loss: 0.34972307831048965\n",
            "Step 15228, Epoch 5/5, Loss: 0.3364523947238922\n",
            "Step 15232, Epoch 5/5, Loss: 0.33573298901319504\n",
            "Step 15236, Epoch 5/5, Loss: 0.30662157014012337\n",
            "Step 15240, Epoch 5/5, Loss: 0.3452407382428646\n",
            "Step 15244, Epoch 5/5, Loss: 0.3222901001572609\n",
            "Step 15248, Epoch 5/5, Loss: 0.43287376314401627\n",
            "Step 15252, Epoch 5/5, Loss: 0.3267940580844879\n",
            "Step 15256, Epoch 5/5, Loss: 0.34807760640978813\n",
            "Step 15260, Epoch 5/5, Loss: 0.29284030571579933\n",
            "Step 15264, Epoch 5/5, Loss: 0.2900674156844616\n",
            "Step 15268, Epoch 5/5, Loss: 0.31212814897298813\n",
            "Step 15272, Epoch 5/5, Loss: 0.28838157281279564\n",
            "Step 15276, Epoch 5/5, Loss: 0.30695945769548416\n",
            "Step 15280, Epoch 5/5, Loss: 0.3744301050901413\n",
            "Step 15284, Epoch 5/5, Loss: 0.3774738535284996\n",
            "Step 15288, Epoch 5/5, Loss: 0.32868094742298126\n",
            "Step 15292, Epoch 5/5, Loss: 0.3986624777317047\n",
            "Step 15296, Epoch 5/5, Loss: 0.3318774625658989\n",
            "Step 15300, Epoch 5/5, Loss: 0.34447503089904785\n",
            "Step 15304, Epoch 5/5, Loss: 0.3212813064455986\n",
            "Step 15308, Epoch 5/5, Loss: 0.2928081750869751\n",
            "Step 15312, Epoch 5/5, Loss: 0.28916947916150093\n",
            "Step 15316, Epoch 5/5, Loss: 0.3594227358698845\n",
            "Step 15320, Epoch 5/5, Loss: 0.373208723962307\n",
            "Step 15324, Epoch 5/5, Loss: 0.2990090921521187\n",
            "Step 15328, Epoch 5/5, Loss: 0.3647650480270386\n",
            "Step 15332, Epoch 5/5, Loss: 0.32311034202575684\n",
            "Step 15336, Epoch 5/5, Loss: 0.30543408915400505\n",
            "Step 15340, Epoch 5/5, Loss: 0.3240046352148056\n",
            "Step 15344, Epoch 5/5, Loss: 0.2557602487504482\n",
            "Step 15348, Epoch 5/5, Loss: 0.26807184517383575\n",
            "Step 15352, Epoch 5/5, Loss: 0.28976933658123016\n",
            "Step 15356, Epoch 5/5, Loss: 0.2899077795445919\n",
            "Step 15360, Epoch 5/5, Loss: 0.26879027113318443\n",
            "Step 15364, Epoch 5/5, Loss: 0.3292698487639427\n",
            "Step 15368, Epoch 5/5, Loss: 0.3388374596834183\n",
            "Step 15372, Epoch 5/5, Loss: 0.3859524801373482\n",
            "Step 15376, Epoch 5/5, Loss: 0.33775100484490395\n",
            "Step 15380, Epoch 5/5, Loss: 0.35453104972839355\n",
            "Step 15384, Epoch 5/5, Loss: 0.27037203684449196\n",
            "Step 15388, Epoch 5/5, Loss: 0.28307559713721275\n",
            "Step 15392, Epoch 5/5, Loss: 0.35268137603998184\n",
            "Step 15396, Epoch 5/5, Loss: 0.3054578825831413\n",
            "Step 15400, Epoch 5/5, Loss: 0.33594194427132607\n",
            "Step 15404, Epoch 5/5, Loss: 0.4038653075695038\n",
            "Step 15408, Epoch 5/5, Loss: 0.2551732286810875\n",
            "Step 15412, Epoch 5/5, Loss: 0.25983118638396263\n",
            "Step 15416, Epoch 5/5, Loss: 0.3308095969259739\n",
            "Step 15420, Epoch 5/5, Loss: 0.32272326201200485\n",
            "Step 15424, Epoch 5/5, Loss: 0.3065279684960842\n",
            "Step 15428, Epoch 5/5, Loss: 0.3353865146636963\n",
            "Step 15432, Epoch 5/5, Loss: 0.29514551162719727\n",
            "Step 15436, Epoch 5/5, Loss: 0.314706988632679\n",
            "Step 15440, Epoch 5/5, Loss: 0.30838991329073906\n",
            "Step 15444, Epoch 5/5, Loss: 0.3409375473856926\n",
            "Step 15448, Epoch 5/5, Loss: 0.2113354317843914\n",
            "Step 15452, Epoch 5/5, Loss: 0.29296888783574104\n",
            "Step 15456, Epoch 5/5, Loss: 0.36021269112825394\n",
            "Step 15460, Epoch 5/5, Loss: 0.38189519196748734\n",
            "Step 15464, Epoch 5/5, Loss: 0.29405299574136734\n",
            "Step 15468, Epoch 5/5, Loss: 0.3496325686573982\n",
            "Step 15472, Epoch 5/5, Loss: 0.2542940452694893\n",
            "Step 15476, Epoch 5/5, Loss: 0.3911198228597641\n",
            "Step 15480, Epoch 5/5, Loss: 0.3451654016971588\n",
            "Step 15484, Epoch 5/5, Loss: 0.32005902752280235\n",
            "Step 15488, Epoch 5/5, Loss: 0.3458305597305298\n",
            "Step 15492, Epoch 5/5, Loss: 0.3325803726911545\n",
            "Step 15496, Epoch 5/5, Loss: 0.280729778110981\n",
            "Step 15500, Epoch 5/5, Loss: 0.29596467316150665\n",
            "Step 15504, Epoch 5/5, Loss: 0.32433150336146355\n",
            "Step 15508, Epoch 5/5, Loss: 0.365664541721344\n",
            "Step 15512, Epoch 5/5, Loss: 0.38627246767282486\n",
            "Step 15516, Epoch 5/5, Loss: 0.3353128209710121\n",
            "Step 15520, Epoch 5/5, Loss: 0.33263228088617325\n",
            "Step 15524, Epoch 5/5, Loss: 0.2910589165985584\n",
            "Step 15528, Epoch 5/5, Loss: 0.2622433342039585\n",
            "Step 15532, Epoch 5/5, Loss: 0.2843134477734566\n",
            "Step 15536, Epoch 5/5, Loss: 0.25871771574020386\n",
            "Step 15540, Epoch 5/5, Loss: 0.34661417081952095\n",
            "Step 15544, Epoch 5/5, Loss: 0.34331628680229187\n",
            "Step 15548, Epoch 5/5, Loss: 0.3715788945555687\n",
            "Step 15552, Epoch 5/5, Loss: 0.30864982679486275\n",
            "Step 15556, Epoch 5/5, Loss: 0.26882147043943405\n",
            "Step 15560, Epoch 5/5, Loss: 0.39801519364118576\n",
            "Step 15564, Epoch 5/5, Loss: 0.31372878700494766\n",
            "Step 15568, Epoch 5/5, Loss: 0.256719384342432\n",
            "Step 15572, Epoch 5/5, Loss: 0.3442646414041519\n",
            "Step 15576, Epoch 5/5, Loss: 0.236761674284935\n",
            "Step 15580, Epoch 5/5, Loss: 0.3792864829301834\n",
            "Step 15584, Epoch 5/5, Loss: 0.33779724314808846\n",
            "Step 15588, Epoch 5/5, Loss: 0.33286094665527344\n",
            "Step 15592, Epoch 5/5, Loss: 0.29892998933792114\n",
            "Step 15596, Epoch 5/5, Loss: 0.32852526009082794\n",
            "Step 15600, Epoch 5/5, Loss: 0.336805559694767\n",
            "Step 15604, Epoch 5/5, Loss: 0.4012603126466274\n",
            "Step 15608, Epoch 5/5, Loss: 0.33459939807653427\n",
            "Step 15612, Epoch 5/5, Loss: 0.28534868732094765\n",
            "Step 15616, Epoch 5/5, Loss: 0.41493042558431625\n",
            "Step 15620, Epoch 5/5, Loss: 0.29559217765927315\n",
            "Step 15624, Epoch 5/5, Loss: 0.3739551529288292\n",
            "Step 15628, Epoch 5/5, Loss: 0.29214958101511\n",
            "Step 15632, Epoch 5/5, Loss: 0.35424596816301346\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Ingredient_base_QA_model.pt')\n",
        "print(\"Model saved successfully\")"
      ],
      "metadata": {
        "id": "4axKJQWfd0fN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4203c907-cdd9-42b4-92c7-ca825860bb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "\n",
        "class BasedNameModel():\n",
        "    def __init__(self):\n",
        "        # 특수 토큰 정의\n",
        "        self.Q_TKN = \"<usr>\"\n",
        "        self.A_TKN = \"<sys>\"\n",
        "        self.BOS = '</s>'\n",
        "        self.EOS = '</s>'\n",
        "        self.MASK = '<unused0>'\n",
        "        self.SENT = '<unused1>'\n",
        "        self.PAD = '<pad>'\n",
        "\n",
        "        self.tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2',\n",
        "                                                                 bos_token=self.BOS,\n",
        "                                                                 eos_token=self.EOS,\n",
        "                                                                 unk_token=\"<unk>\",\n",
        "                                                                 pad_token=self.PAD,\n",
        "                                                                 mask_token=self.MASK)\n",
        "        self.model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        state_dict = torch.load('/content/drive/MyDrive/Ingredient_base_QA_model.pt', map_location=self.device)\n",
        "        self.model.load_state_dict(state_dict)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def predict(self, user_text):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "          a = ''\n",
        "          while True:\n",
        "            input_ids = torch.LongTensor(self.tokenizer.encode(self.Q_TKN + user_text + self.SENT + self.A_TKN + a,\n",
        "                                                               add_special_tokens=True)).unsqueeze(dim=0)\n",
        "            input_ids = input_ids.to(self.device)\n",
        "            outputs = self.model(input_ids)\n",
        "\n",
        "            logits = outputs.logits\n",
        "\n",
        "            pred = torch.argmax(logits, dim=-1)\n",
        "            gen_token = self.tokenizer.convert_ids_to_tokens(pred[0].cpu().numpy().tolist())[-1]\n",
        "            if gen_token == self.EOS:\n",
        "              break\n",
        "            a += gen_token.replace(\"▁\", \" \")\n",
        "\n",
        "        return a.strip()"
      ],
      "metadata": {
        "id": "DxPAF3VN7rdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용 예시\n",
        "model = BasedNameModel()\n",
        "while True:\n",
        "  user_text = input('사용자: ')\n",
        "  if user_text == 'quit':\n",
        "    break\n",
        "  print('챗봇:', model.predict(user_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8z6MqIYX040",
        "outputId": "83cb603a-fbb3-4266-b3df-9e325ac619dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용자: 돼지고기로 만들 수 있는 맛있는 요리를 추천\n",
            "챗봇: 재료가 가장 많이 포함된 요리: 돼지고기겨자채보쌈  제육보쌈  양장피냉채\n",
            "사용자: 돼지고기, 고추장\n",
            "챗봇: 모든 재료가 포함된 요리: 돼지고기겨자채보쌈  제육보쌈\n",
            "사용자: 돼지고기, 고추장으로 만들 수 있는 요리 추천\n",
            "챗봇: 재료가 가장 많이 포함된 요리: 제육보쌈  돼지고기김치볶음  사천식자장면\n",
            "사용자:  돼지고기, 고추장으로 만들 수 있는 요리 추천해줘\n",
            "챗봇: 재료가 가장 많이 포함된 요리: 제육보쌈  돼지고기김치볶음  사천식자장면\n",
            "사용자:  돼지고기, 고추장이 들어가는 요리 추천해줄래/\n",
            "챗봇: 모든 재료가 포함된 요리: 돼지고기김치볶음  제육보쌈\n",
            "사용자: 새우가 들어가는 요리 추천해줘\n",
            "챗봇: 모든 재료가 포함된 요리: 사천식 알배추찜  두부새우젓국찌개  새우튀김우동\n",
            "사용자: 새우, 양파, 마늘, 오징어가 포함된 요리추천\n",
            "챗봇: 모든 재료가 포함된 요리: 오징어섞어찌개  삼색밀쌈  새우튀김우동\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04XBm8SYX5xa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c40899e4d2c42a5af3f53d13d8d5d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26f32f4c1ca1469fa178292654036cba",
              "IPY_MODEL_3d9b5e70677a44fc8eb2ea55429d2ba2",
              "IPY_MODEL_de59ec42e26f4dfb8143c88be7943b09"
            ],
            "layout": "IPY_MODEL_4583632a9fb844c3b40545d61475e1a2"
          }
        },
        "26f32f4c1ca1469fa178292654036cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c0c4e4c9574b3093717f185d32ebed",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a460d1bcd847d5aa06da526198f43b",
            "value": "tokenizer.json: 100%"
          }
        },
        "3d9b5e70677a44fc8eb2ea55429d2ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dad0ae1f0894e7888a42b587d02c37e",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dec93d175be2428c8aab75f1c2eb35f5",
            "value": 2825034
          }
        },
        "de59ec42e26f4dfb8143c88be7943b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75e9e74f14b34e3292d56e4c5225a055",
            "placeholder": "​",
            "style": "IPY_MODEL_7a22c9e4ca154fc984b4caf27558c80e",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 34.3MB/s]"
          }
        },
        "4583632a9fb844c3b40545d61475e1a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c0c4e4c9574b3093717f185d32ebed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a460d1bcd847d5aa06da526198f43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dad0ae1f0894e7888a42b587d02c37e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec93d175be2428c8aab75f1c2eb35f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75e9e74f14b34e3292d56e4c5225a055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a22c9e4ca154fc984b4caf27558c80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b801cc95a804e31a3bdf840e0a634a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a379456b7af43959c8c47dc84edbb64",
              "IPY_MODEL_fbe22e2d45ee4640a90f708a4f23686a",
              "IPY_MODEL_aeee0a8c7b58486c9ebd02f86342986d"
            ],
            "layout": "IPY_MODEL_80e9721513304e02b2f992709483f160"
          }
        },
        "6a379456b7af43959c8c47dc84edbb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5911210f9a9747aa8dfa7d8a3047c305",
            "placeholder": "​",
            "style": "IPY_MODEL_391305c082c44104b626e00d97aa7f18",
            "value": "config.json: 100%"
          }
        },
        "fbe22e2d45ee4640a90f708a4f23686a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f7fbc09ffa74e68adef644acd44117a",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd9a5cbdc0614c1a8d360581d1a05e26",
            "value": 1000
          }
        },
        "aeee0a8c7b58486c9ebd02f86342986d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48eaf3cc2544462aaffb13e3462f80fe",
            "placeholder": "​",
            "style": "IPY_MODEL_b0671ca9ec5c48238bfc7786253bbe0e",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 24.1kB/s]"
          }
        },
        "80e9721513304e02b2f992709483f160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5911210f9a9747aa8dfa7d8a3047c305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391305c082c44104b626e00d97aa7f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f7fbc09ffa74e68adef644acd44117a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd9a5cbdc0614c1a8d360581d1a05e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48eaf3cc2544462aaffb13e3462f80fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0671ca9ec5c48238bfc7786253bbe0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}